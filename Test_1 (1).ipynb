{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tDTLQBNuSbxU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "412ewHWRnyvd"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cPF1fCYNs-lK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Robert Cohn was a member, through his father, ...\n",
       "1       The divorce was arranged and Robert Cohn went ...\n",
       "2       By that time, though, he had other things to w...\n",
       "3       The lady who had him, her name was Frances, fo...\n",
       "4       I first became aware of his lady’s attitude to...\n",
       "                              ...                        \n",
       "1068    I was on the point of asking him what that wor...\n",
       "1069      1. Knowledge of Literature.--Nil.\\n  2.     ...\n",
       "1070    I see that I have alluded above to his powers ...\n",
       "1071    During the first week or so we had no callers,...\n",
       "1072    It was upon the 4th of March, as I have good r...\n",
       "Name: v2, Length: 1073, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path_to_text = '/content/drive/MyDrive/datasets-spam.csv'\n",
    "#path_to_text = 'datasets-spam.csv'\n",
    "path_to_text = 'books_and_authors'\n",
    "data = pd.read_csv(path_to_text, names=['v1', 'v2'])\n",
    "\n",
    "# Creating the feature set and label set\n",
    "label = data['v1']\n",
    "text = data['v2']\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IkzbchTWXMEQ"
   },
   "source": [
    "Прво целосно прочистен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kQMEPwLuVos_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /home/kicho/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/kicho/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/kicho/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/kicho/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/kicho/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords_ = stopwords.words('english')\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "G4TuGNFyVFld"
   },
   "outputs": [],
   "source": [
    "text_preprocessed = []\n",
    "for sentence in text:\n",
    "    #sentence lower\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    #string punct\n",
    "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "    #tokenize\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    \n",
    "    # stop-words\n",
    "    tokens_stop_words = []\n",
    "    \n",
    "    for token in tokens:\n",
    "          if token not in stopwords_:\n",
    "                tokens_stop_words.append(token)\n",
    "                \n",
    "    # Lemmatization\n",
    "    tokens_lemma = []\n",
    "    for token in tokens_stop_words:\n",
    "          tokens_lemma.append(wnl.lemmatize(token, get_wordnet_pos(nltk.pos_tag([token])[0][1])))\n",
    "            \n",
    "    final = ' '.join(tokens_lemma)\n",
    "    \n",
    "    text_preprocessed.append(final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UCSyKfMSXUV-"
   },
   "source": [
    "Без процесирање, само мали букви и токенизација."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "S1lVUTtWS2sW"
   },
   "outputs": [],
   "source": [
    "text_preprocessed_1 = []\n",
    "for sentence in text:\n",
    "    #sentence lower\n",
    "    sentence = sentence.lower()\n",
    "    #tokenize\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    \n",
    "    text_preprocessed_1.append(' '.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ToIgCuOZtlb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1073, 1073, 1073)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_preprocessed_1),len(text_preprocessed), len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yf-0K8WSt-Vq"
   },
   "source": [
    "Count Vecotrizer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qV50_5d7t9Pe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(751, 322, 751, 322)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ratio = .7\n",
    "train_index= int(len(text)*train_ratio)\n",
    "\n",
    "trainX, testX = text_preprocessed[:train_index], text_preprocessed[train_index:]\n",
    "trainY, testY = label[:train_index], label[train_index:]\n",
    "\n",
    "len(trainX), len(testX) ,len(trainY), len(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qRaf0P1JuHBa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encode lables (0-ham, 1-spam)\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "trainY= le.fit_transform(trainY)\n",
    "testY = le.fit_transform(testY)\n",
    "trainY.shape,testY.shape\n",
    "trainY[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "g8Y0uHPguNI1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(322, 5000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Count Vectors as features\n",
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(max_features=5000)\n",
    "count_vect.fit(text_preprocessed)\n",
    "\n",
    "# transform the training and test data using count vectorizer object\n",
    "trainX_vec = count_vect.transform(trainX)\n",
    "testX_vec = count_vect.transform(testX)\n",
    "trainX_vec.shape,\n",
    "testX_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "h2wb9TqQuYZE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        98\n",
      "           1       0.78      0.26      0.39       224\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.18       322\n",
      "   macro avg       0.10      0.03      0.05       322\n",
      "weighted avg       0.55      0.18      0.27       322\n",
      "\n",
      "[[ 0 16 33  1  0  9 35  4]\n",
      " [ 4 58 32  1 10  8 65 46]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0]]\n",
      "Accuracy: 0.18012422360248448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kicho/anaconda3/envs/DataScience/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kicho/anaconda3/envs/DataScience/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kicho/anaconda3/envs/DataScience/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "\n",
    "#create an instance of the model\n",
    "lr_model = LogisticRegression(random_state=7)\n",
    "#train the model\n",
    "lr_model.fit(trainX_vec, trainY)\n",
    "\n",
    "#predict test data\n",
    "pred_test = lr_model.predict(testX_vec)\n",
    "\n",
    "#print evaluation metrics \n",
    "print(classification_report(testY,pred_test))\n",
    "print(confusion_matrix(testY,pred_test))\n",
    "print(\"Accuracy:\",accuracy_score(testY, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4KSr1-hn4aY"
   },
   "source": [
    "Вториот модел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TxSTEdkbx9sZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(751, 322, 751, 322)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1_ratio = .7\n",
    "train_1_index= int(len(text)*train_1_ratio)\n",
    "\n",
    "trainX_1, testX_1 =text_preprocessed_1[:train_index], text_preprocessed_1[train_index:]\n",
    "trainY_1, testY_1 =label[:train_1_index], label[train_1_index:]\n",
    "\n",
    "len(trainX_1), len(testX_1) ,len(trainY_1), len(testY_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "WO-aOegA1S4k"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "trainY_1= le.fit_transform(trainY_1)\n",
    "testY_1 = le.fit_transform(testY_1)\n",
    "trainY_1.shape,testY_1.shape\n",
    "trainY_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "CT0m5SOw1sOL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(322, 5000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect_1 = CountVectorizer(max_features=5000)\n",
    "count_vect_1.fit(text_preprocessed_1)\n",
    "\n",
    "# transform the training and test data using count vectorizer object\n",
    "trainX_1_vec = count_vect.transform(trainX_1)\n",
    "testX_1_vec = count_vect.transform(testX_1)\n",
    "trainX_1_vec.shape,\n",
    "testX_1_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "T1bUVcdYo-iF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.05      0.08        98\n",
      "           1       0.81      0.29      0.42       224\n",
      "           2       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.21       322\n",
      "   macro avg       0.14      0.05      0.07       322\n",
      "weighted avg       0.61      0.21      0.32       322\n",
      "\n",
      "[[ 5 15 46  0  8 20  4]\n",
      " [25 64 35 16 15 38 31]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]]\n",
      "Accuracy: 0.21428571428571427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kicho/anaconda3/envs/DataScience/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/kicho/anaconda3/envs/DataScience/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kicho/anaconda3/envs/DataScience/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kicho/anaconda3/envs/DataScience/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "lr_model_1 = LogisticRegression(random_state=0)\n",
    "lr_model_1.fit(trainX_1_vec, trainY_1)\n",
    "\n",
    "pred_test_1 = lr_model_1.predict(testX_1_vec)\n",
    "\n",
    "#print evaluation metrics \n",
    "print(classification_report(testY_1,pred_test_1))\n",
    "print(confusion_matrix(testY_1,pred_test_1))\n",
    "print(\"Accuracy:\",accuracy_score(testY_1, pred_test_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "mYdUrcYmS5wt"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "IDLweyMdqpwX"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '‘' (U+2018) (2586729214.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_172526/2586729214.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    tfidf = TfidfVectorizer(max_features=5000, stop_words={‘english’}, ngram_range=(1, 2))\u001b[0m\n\u001b[0m                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '‘' (U+2018)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(max_features=5000, stop_words={‘english’}, ngram_range=(1, 2)) \n",
    "tfidf.fit(text)\n",
    "\n",
    "X_train_tfidf = tfidf.transform(trainX)\n",
    "X_test_tfidf = tfidf.transform(testX)\n",
    "\n",
    "X_train_tfidf.shape, X_test_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RfPZHh8lxw1z"
   },
   "outputs": [],
   "source": [
    "lr_model_tf = LogisticRegression(random_state=0)\n",
    "lr_model_tf.fit(X_train_tfidf, trainY)\n",
    "pred_test_tf = lr_model_tf.predict(X_test_tfidf)\n",
    "\n",
    "#print evaluation metrics \n",
    "print(classification_report(testY,pred_test_tf))\n",
    "print(confusion_matrix(testY,pred_test_tf))\n",
    "print(\"Accuracy:\",accuracy_score(testY, pred_test_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xx9-wnpTrHeg"
   },
   "outputs": [],
   "source": [
    "lr_model_tf = LogisticRegression(random_state=0)\n",
    "lr_model_tf.fit(X_train_tfidf, trainY)\n",
    "pred_test_tf = lr_model_tf.predict(X_test_tfidf)\n",
    "\n",
    "#print evaluation metrics \n",
    "print(classification_report(testY,pred_test_tf))\n",
    "print(confusion_matrix(testY,pred_test_tf))\n",
    "print(\"Accuracy:\",accuracy_score(testY, pred_test_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z71kI5VOo3dA"
   },
   "outputs": [],
   "source": [
    "#Language processing\n",
    "text.concordance(\"word\") - колку пати се појавува зборот\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w1FzP0f1S9N3"
   },
   "outputs": [],
   "source": [
    "# mutlinomial NB, Random Forest, SVM(kernel='linear', probability=True) bi gi probala\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HzUSRQfOZylr"
   },
   "outputs": [],
   "source": [
    "# embeddings \n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import Phrases\n",
    "\n",
    "bigramer = Phrases(sentences)\n",
    "model = Word2Vec(bigramer[sentences], size=100, window=5, min_count=10, workers=4)\n",
    "\n",
    "# unload memory\n",
    "model.init_sims(replace=True) \n",
    "\n",
    "# Storing a model\n",
    "model.save(\"author\")\n",
    "# new_model = gensim.models.Word2Vec.load('author')\n",
    "\n",
    "# Switch to KeyedVectors instance  \n",
    "w2v = {w: vec for w,vec in zip(model.wv.indx2word, model.wv.syn0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dvXe3ijQehQm"
   },
   "outputs": [],
   "source": [
    "model.most_similar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nae2IGVjicsO"
   },
   "outputs": [],
   "source": [
    "class EmbeddingVectorizer(object):\n",
    "    # If word2vec were passed in during initialization, use those\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = 100\n",
    "    \n",
    "    # learning word2weight\n",
    "    def fit(self, X, y):\n",
    "        vect = TfidfVectorizer(min_df=5, ngram_range=(1,3))\n",
    "        vect.fit(X)\n",
    "        max_idf = max(vect.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "        lambda: max_idf, [(w, vect.idf_[i]) for w, i in vect.vocabulary_.items()]\n",
    "        )\n",
    "        return self\n",
    "    \n",
    "    # Use learned word2weight\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([\n",
    "                self.word2vec[w]*self.word2weight[w] \n",
    "                for w in words if w in self.word2vec] or \n",
    "                [np.zeros(self.dim)], axis=0) \n",
    "            for words in X\n",
    "        ])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8QH12lzY_W_Z"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer #similar to the CountVectorizer and TfIDF from sci-kit\n",
    "\n",
    "#The word embedding layer expects input sequences to be comprised of integers.\n",
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(text_preprocessed)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(text_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0NcZoThSAAR3"
   },
   "outputs": [],
   "source": [
    "len(sequences[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y3ES4MU5_0jI"
   },
   "outputs": [],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hTxuijiE_-yM"
   },
   "outputs": [],
   "source": [
    "sequences = np.array(sequences)\n",
    "\n",
    "train_part= int(len(text)*0.7)\n",
    "train_X, test_X =sequences[:train_part], sequences[train_part:]\n",
    "\n",
    "train_X.shape,test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E3ykWyt8AQHn"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_len = 30\n",
    "#transforms a list (of length num_samples) of sequences (lists of integers) \n",
    "#into a 2D Numpy array of shape (num_samples, num_timesteps) num_timesteps is the maxlen argument.\n",
    "train_X_pad = pad_sequences(train_X, maxlen=max_len)\n",
    "test_X_pad = pad_sequences(test_X, maxlen=max_len)\n",
    "print(train_X_pad.shape)\n",
    "print(test_X_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ePA_jmq1Ah-3"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "luSRMsQ7AX-7"
   },
   "outputs": [],
   "source": [
    "# create the model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,Embedding,LSTM,Dense\n",
    "\n",
    "def generate_model(vocab_size, max_len, embedding_size):\n",
    "\n",
    "  _input = Input(max_len)\n",
    "\n",
    "  x = Embedding(input_dim = vocab_size, output_dim = embedding_size) (_input)\n",
    "\n",
    "  x = LSTM(100)(x)\n",
    "\n",
    "  output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "  model = Model(inputs= [_input], outputs = [output])\n",
    "\n",
    "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J3WapLTSAcxF"
   },
   "outputs": [],
   "source": [
    "model = generate_model(vocab_size,max_len,embedding_size=50)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P9xrX7gwAmZV"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_X_pad, trainY, epochs=10, batch_size=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wMmTww8hAqC0"
   },
   "outputs": [],
   "source": [
    "pred_test = model.predict(test_X_pad)\n",
    "#pred_test = np.argmax(pred_test,axis=1)\n",
    "pred_test = pred_test.round()\n",
    "\n",
    "#print evaluation metrics \n",
    "print(classification_report(testY,pred_test))\n",
    "print(confusion_matrix(testY,pred_test))\n",
    "print(\"Accuracy:\",accuracy_score(testY, pred_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Test 1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
