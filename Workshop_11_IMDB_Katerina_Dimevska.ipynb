{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zzy_jPAa9PLa"
   },
   "source": [
    "# IMDB - sentiment analysis\n",
    "The problem is IMDB movie review sentiment classification. Each movie review is a variable sequence of words and the sentiment of each movie review must be classified.\n",
    "\n",
    "The IMDB Dataset (http://ai.stanford.edu/~amaas/data/sentiment/) contains 25,000 movie reviews (good or bad) for training and the same amount again for testing. The problem is to determine whether a given movie review has a positive or negative sentiment (binary classification).\n",
    "\n",
    "The dataset is already split on train and test sequences and it can be found in the same folder with the notebook file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "etuEcmGxLw61"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-wXgE6m9X_p"
   },
   "source": [
    "## Read the data\n",
    "Each files ('xTrain_yTrain.pkl' and 'xTest_yTest.pkl')contains two lists of data. The first list contains sentences/reviews and the second list contains the labels.\n",
    "\n",
    "The files can be read using pickle:\n",
    "\n",
    "my_file = open('xTrain_yTrain.pkl', \"rb\")\n",
    "\n",
    "X, Y = pickle.load(my_file)\n",
    "\n",
    "my_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lNwVQXH5LbLN",
    "outputId": "d4fc6cd4-d201-44f8-a519-94e4907062cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "I_btQUrhNQ9K"
   },
   "outputs": [],
   "source": [
    "path_to_text = '/content/drive/MyDrive/my_file/xTrain_yTrain.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "n1XoAefqLFc3"
   },
   "outputs": [],
   "source": [
    "my_file = open(path_to_text, \"rb\")\n",
    "\n",
    "Xtrain, ytrain = pickle.load(my_file)\n",
    "\n",
    "my_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TDj_uMrPN4hw"
   },
   "outputs": [],
   "source": [
    "path_to_text_2 = '/content/drive/MyDrive/my_file/xTest_yTest.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zqgVqUChN7AX"
   },
   "outputs": [],
   "source": [
    "my_file_2 = open(path_to_text_2, \"rb\")\n",
    "\n",
    "Xtest, Ytest = pickle.load(my_file_2)\n",
    "\n",
    "my_file_2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SI3jhyV49T4x"
   },
   "source": [
    "## Inspect the data\n",
    "\n",
    "  - Print several train and test examples with their labels\n",
    "  - Plot the distribution of the labels both in the train and in the test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Kjb5nJ15O2zu"
   },
   "outputs": [],
   "source": [
    "text = Xtrain\n",
    "label = ytrain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0KnhZWbXQIOT",
    "outputId": "263f5f84-7f24-457e-9c05-954016208f57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vER43FN7QL1J",
    "outputId": "7003a178-be9b-43b2-fa68-64be3170e20c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room titillate it so heart shows to years of every never going villaronga help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but pratfalls to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other tricky in of seen over landed for anyone of gilmore's br show's to whether from than out themselves history he name half some br of 'n odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "IJ_-DunmQiyE",
    "outputId": "38d2c83f-59cd-4ac4-ded0-342f26527145"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f258705d290>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(label).hist()\n",
    "# label.hist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQdgw_DRsWl7"
   },
   "source": [
    "## Preprocess the data\n",
    "\n",
    "- covert to lower letters\n",
    "- remove punctuation\n",
    "- tokenization\n",
    "- stop-words removal \n",
    "- lemmatization (use also Part of Speech tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2lb9i5y4RO-g",
    "outputId": "793b9fda-b65c-48cc-82da-ec6cdf62907b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "nltk.download('stopwords')\n",
    "stopwords_ = stopwords.words('english')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "id": "bWvHrSXFReYe",
    "outputId": "761f5e90-82e3-4b12-9edf-76b69ffec764"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room titillate it so heart shows to years of every never going villaronga help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but pratfalls to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other tricky in of seen over landed for anyone of gilmore's br show's to whether from than out themselves history he name half some br of 'n odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "9KsuDHdMRibt"
   },
   "outputs": [],
   "source": [
    "text_preprocessed = []\n",
    "for sentence in text:\n",
    "    #sentence lower\n",
    "    sentence = sentence.lower()\n",
    "    #string punct\n",
    "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "    #tokenize\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    # stop-words\n",
    "    tokens_stop_words = []\n",
    "    for token in tokens:\n",
    "      if token not in stopwords_:\n",
    "        tokens_stop_words.append(token)\n",
    "    # Lemmatization\n",
    "    tokens_lemma = []\n",
    "    for token in tokens_stop_words:\n",
    "      tokens_lemma.append(wnl.lemmatize(token, get_wordnet_pos(nltk.pos_tag([token])[0][1])))\n",
    "    final = ' '.join(tokens_lemma)\n",
    "    text_preprocessed.append(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "id": "b1y5lsGJR2gE",
    "outputId": "c0289ed1-23eb-411c-a769-b4a43131c0ae"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"the clear fact entertaining there life back br is safely show of performance stars br actors film him many should movie reasons to mikey reading blended are in of scenes jada carbon of safely out compared not boss yes to sentiment show its disappointed fact raw to it justice by br of where clear fact many your way jada with city nice are is along wrong not as it way she but this anything up haven't been by who of choices br of you to as this i'd it mcdoakes who of shot you'll to love for updated of you it is sequels of little quest are seen watched front chemistry to simply alive of chris being it is say easy reservation cry in chemistry but voodoo all it maybe this is wing film job live of objects relief aneta level names lifelong dunne to be stops serial 1948 watch is men go this of wing american from russo moving is accepted put this of jerry for places so work moby watch holodeck lot br that from sometimes wondered make department introduced to wondered from action at turns in low that in gay i'm of chemistry bible i i simply alive it is time done inspector to watching look world named for more tells up many fans are that movie music her get grasp but seems in people film that if explain in why for jada find of where br if carlo movie throughout if irritable of you best look red startling to recently in successfully much unfortunately going dan colman's stuck is him sequences but of you of enough for its br that beautiful put reasons of chris chemistry wing proposal for of you red time trivia to as companion payoff of chris less br of subplots torture in low alive in gay some br of wing if time actual in also side any if name takes for of friendship it of 10 for had grande great to as you students for movie of going proposal for bad well best had at woman br musical when it caused of gripping to as gem in updated for jada look end gene in at world aliens of you it meet but is quite br western ideas of chris little of films he an time done this were right too to of enough for of ending become family beautiful are make right being it time much bit especially craig for of you parts bond who of here parts at due given movie of once give find actor to recently in at world dolls loved jada it is video him fact you to by br of where br of grown fight culture leads\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "id": "Ug6iCOA_R4ow",
    "outputId": "952dd6c9-2d1b-43a3-d96b-8f324db8822a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'clear fact entertain life back br safely show performance star br actor film many movie reason mikey reading blend scene jada carbon safely compare bos yes sentiment show disappointed fact raw justice br clear fact many way jada city nice along wrong way anything havent choice br id mcdoakes shot youll love update sequel little quest see watch front chemistry simply alive chris say easy reservation cry chemistry voodoo maybe wing film job live object relief aneta level name lifelong dunne stop serial 1948 watch men go wing american russo move accepted put jerry place work moby watch holodeck lot br sometimes wonder make department introduce wonder action turn low gay im chemistry bible simply alive time do inspector watch look world name tell many fan movie music get grasp seem people film explain jada find br carlo movie throughout irritable best look red startle recently successfully much unfortunately go dan colmans stuck sequence enough br beautiful put reason chris chemistry wing proposal red time trivia companion payoff chris less br subplots torture low alive gay br wing time actual also side name take friendship 10 grande great student movie go proposal bad well best woman br musical cause grip gem update jada look end gene world alien meet quite br western idea chris little film time do right enough end become family beautiful make right time much bit especially craig part bond part due give movie give find actor recently world doll love jada video fact br br grown fight culture lead'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocessed[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "atc1vf1jR7Es",
    "outputId": "cef559e5-e1d5-4fd0-a6c6-932122821d56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_preprocessed),len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlvMaVDssWmG"
   },
   "source": [
    "## Count Vector model\n",
    "\n",
    "- use Count Vectorizer to create the feature vectors\n",
    "- Train two models: Logistic Regression and a simple Feed forward Network\n",
    "- Evaluate the model on the test data (calculate: accuracy, precision, recall and F1-score for each class, and the confusion matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WH9eRiBWTqpO",
    "outputId": "8b9d30dd-c8e7-4d80-c5c7-9a8bb6da87e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17500, 7500, 17500, 7500)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ratio = .7\n",
    "train_index= int(len(text)*train_ratio)\n",
    "\n",
    "trainX, testX =text_preprocessed[:train_index], text_preprocessed[train_index:]\n",
    "trainY, testY =label[:train_index], label[train_index:]\n",
    "\n",
    "len(trainX), len(testX) ,len(trainY), len(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jBV2vYRHTxaL",
    "outputId": "b0352517-7089-4109-c730-12244b13c702"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encode lables (0-ham, 1-spam)\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "trainY= le.fit_transform(trainY)\n",
    "testY = le.fit_transform(testY)\n",
    "trainY.shape,testY.shape\n",
    "trainY[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "t11a_R3OT7fZ",
    "outputId": "41ca9a2f-9757-48c0-c754-07659e95f033"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f257fa4bb90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQXUlEQVR4nO3df4xlZX3H8fdHVhRXCyjthCy0S+PadpU0kgliTOwoBlZsWJKqwWBdzKabWGqtJW2x/YNGJZG0SJX4o1uhoKECUtPdFFtCgIlpU1ZBLAiUMgWE3aKoC9uuRO3ab/+4z9Ip3WXu7Ny5l/F5v5LNnvOc55zzfGd2P+fMc8+9k6pCktSH5016AJKk8TH0Jakjhr4kdcTQl6SOGPqS1JFVkx7AsznmmGNq7dq1h7z/97//fVavXj26AT3H9VYvWHMvrHlx7rjjju9W1U8faNtzOvTXrl3L7bfffsj7z87OMjMzM7oBPcf1Vi9Ycy+seXGSfPNg25zekaSOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjjyn35ErSZO09oIbJnbuKzcsz8dOeKcvSR35ib7Tv3vXHs6dwJX64Y+8ZeznlKRheKcvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4MFfpJ3p/kniTfSPL5JC9MckKSHUnmklyb5PDW9wVtfa5tXzvvOB9o7fcnOX15SpIkHcyCoZ9kDfDbwHRVvQo4DDgbuBi4tKpeDjwBbG67bAaeaO2Xtn4kWd/2eyWwAfhkksNGW44k6dkMO72zCjgiySrgRcBjwBuB69v2q4Cz2vLGtk7bfmqStPZrquqHVfUQMAecvPQSJEnDWjD0q2oX8KfAIwzCfg9wB/BkVe1r3XYCa9ryGuDRtu++1v9l89sPsI8kaQwW/CUqSY5mcJd+AvAk8AUG0zPLIskWYAvA1NQUs7Ozh3ysqSPg/BP3LdxxxJYy5qXYu3fvxM49Kdbch0nVPIn82G+5ah7mN2e9CXioqr4DkOSLwOuAo5KsanfzxwG7Wv9dwPHAzjYddCTwvXnt+83f52lVtRXYCjA9PV0zMzOHUNbAZVdv45K7x//LwR4+Z2bs54TBxWYpX6+VyJr7MKmaJ/Gb9/a7csPqZal5mDn9R4BTkryozc2fCtwL3Aq8tfXZBGxry9vbOm37LVVVrf3s9nTPCcA64CujKUOSNIwFb4OrakeS64GvAfuAOxncid8AXJPkw63t8rbL5cDnkswBuxk8sUNV3ZPkOgYXjH3AeVX14xHXI0l6FkPNfVTVhcCFz2h+kAM8fVNVPwDedpDjXARctMgxSpJGxHfkSlJHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SODBX6SY5Kcn2Sf0lyX5LXJnlpkpuSPND+Prr1TZKPJ5lLcleSk+YdZ1Pr/0CSTctVlCTpwIa90/8Y8PdV9YvALwP3ARcAN1fVOuDmtg7wZmBd+7MF+BRAkpcCFwKvAU4GLtx/oZAkjceCoZ/kSOD1wOUAVfWjqnoS2Ahc1bpdBZzVljcCn62B24CjkhwLnA7cVFW7q+oJ4CZgw0irkSQ9q2Hu9E8AvgP8ZZI7k3wmyWpgqqoea32+BUy15TXAo/P239naDtYuSRqTVUP2OQl4b1XtSPIx/ncqB4CqqiQ1igEl2cJgWoipqSlmZ2cP+VhTR8D5J+4bxbAWZSljXoq9e/dO7NyTYs19mFTNk8iP/Zar5mFCfyews6p2tPXrGYT+t5McW1WPtembx9v2XcDx8/Y/rrXtAmae0T77zJNV1VZgK8D09HTNzMw8s8vQLrt6G5fcPUyJo/XwOTNjPycMLjZL+XqtRNbch0nVfO4FN4z9nPtduWH1stS84PROVX0LeDTJL7SmU4F7ge3A/idwNgHb2vJ24F3tKZ5TgD1tGuhG4LQkR7cXcE9rbZKkMRn2Nvi9wNVJDgceBN7N4IJxXZLNwDeBt7e+XwLOAOaAp1pfqmp3kg8BX239PlhVu0dShSRpKEOFflV9HZg+wKZTD9C3gPMOcpwrgCsWM0BJ0uj4jlxJ6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6MnToJzksyZ1J/ratn5BkR5K5JNcmOby1v6Ctz7Xta+cd4wOt/f4kp4+6GEnSs1vMnf77gPvmrV8MXFpVLweeADa39s3AE6390taPJOuBs4FXAhuATyY5bGnDlyQtxlChn+Q44C3AZ9p6gDcC17cuVwFnteWNbZ22/dTWfyNwTVX9sKoeAuaAk0dRhCRpOKuG7PdnwO8DL2nrLwOerKp9bX0nsKYtrwEeBaiqfUn2tP5rgNvmHXP+Pk9LsgXYAjA1NcXs7Oywtfw/U0fA+SfuW7jjiC1lzEuxd+/eiZ17Uqy5D5OqeRL5sd9y1bxg6Cf5VeDxqrojyczIR/AMVbUV2AowPT1dMzOHfsrLrt7GJXcPe10bnYfPmRn7OWFwsVnK12slsuY+TKrmcy+4Yezn3O/KDauXpeZhEvF1wJlJzgBeCPwU8DHgqCSr2t3+ccCu1n8XcDywM8kq4Ejge/Pa95u/jyRpDBac06+qD1TVcVW1lsELsbdU1TnArcBbW7dNwLa2vL2t07bfUlXV2s9uT/ecAKwDvjKySiRJC1rK3McfANck+TBwJ3B5a78c+FySOWA3gwsFVXVPkuuAe4F9wHlV9eMlnF+StEiLCv2qmgVm2/KDHODpm6r6AfC2g+x/EXDRYgcpSRoN35ErSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjqyYOgnOT7JrUnuTXJPkve19pcmuSnJA+3vo1t7knw8yVySu5KcNO9Ym1r/B5JsWr6yJEkHMsyd/j7g/KpaD5wCnJdkPXABcHNVrQNubusAbwbWtT9bgE/B4CIBXAi8BjgZuHD/hUKSNB4Lhn5VPVZVX2vL/wncB6wBNgJXtW5XAWe15Y3AZ2vgNuCoJMcCpwM3VdXuqnoCuAnYMNJqJEnPatViOidZC7wa2AFMVdVjbdO3gKm2vAZ4dN5uO1vbwdqfeY4tDH5CYGpqitnZ2cUM8f+YOgLOP3HfIe9/qJYy5qXYu3fvxM49Kdbch0nVPIn82G+5ah469JO8GPhr4Heq6j+SPL2tqipJjWJAVbUV2AowPT1dMzMzh3ysy67exiV3L+q6NhIPnzMz9nPC4GKzlK/XSmTNfZhUzedecMPYz7nflRtWL0vNQz29k+T5DAL/6qr6Ymv+dpu2of39eGvfBRw/b/fjWtvB2iVJYzLM0zsBLgfuq6qPztu0Hdj/BM4mYNu89ne1p3hOAfa0aaAbgdOSHN1ewD2ttUmSxmSYuY/XAb8O3J3k663tD4GPANcl2Qx8E3h72/Yl4AxgDngKeDdAVe1O8iHgq63fB6tq90iqkCQNZcHQr6p/AHKQzaceoH8B5x3kWFcAVyxmgJKk0fEduZLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI2MP/SQbktyfZC7JBeM+vyT1bKyhn+Qw4BPAm4H1wDuSrB/nGCSpZ+O+0z8ZmKuqB6vqR8A1wMYxj0GSurVqzOdbAzw6b30n8Jr5HZJsAba01b1J7l/C+Y4BvruE/Q9JLh73GZ82kXonzJr70F3Nb7h4STX/3ME2jDv0F1RVW4GtozhWkturanoUx1oJeqsXrLkX1jw6457e2QUcP2/9uNYmSRqDcYf+V4F1SU5IcjhwNrB9zGOQpG6NdXqnqvYl+S3gRuAw4IqqumcZTzmSaaIVpLd6wZp7Yc0jkqpajuNKkp6DfEeuJHXE0Jekjqz40F/oYx2SvCDJtW37jiRrxz/K0Rqi5t9Ncm+Su5LcnOSgz+yuFMN+fEeSX0tSSVb8433D1Jzk7e17fU+Svxr3GEdtiH/bP5vk1iR3tn/fZ0xinKOS5Iokjyf5xkG2J8nH29fjriQnLfmkVbVi/zB4MfjfgJ8HDgf+GVj/jD6/CXy6LZ8NXDvpcY+h5jcAL2rL7+mh5tbvJcCXgduA6UmPewzf53XAncDRbf1nJj3uMdS8FXhPW14PPDzpcS+x5tcDJwHfOMj2M4C/AwKcAuxY6jlX+p3+MB/rsBG4qi1fD5yaJGMc46gtWHNV3VpVT7XV2xi8H2IlG/bjOz4EXAz8YJyDWybD1PwbwCeq6gmAqnp8zGMctWFqLuCn2vKRwL+PcXwjV1VfBnY/S5eNwGdr4DbgqCTHLuWcKz30D/SxDmsO1qeq9gF7gJeNZXTLY5ia59vM4E5hJVuw5vZj7/FVdcM4B7aMhvk+vwJ4RZJ/THJbkg1jG93yGKbmPwbemWQn8CXgveMZ2sQs9v/7gp5zH8Og0UnyTmAa+JVJj2U5JXke8FHg3AkPZdxWMZjimWHw09yXk5xYVU9OdFTL6x3AlVV1SZLXAp9L8qqq+u9JD2ylWOl3+sN8rMPTfZKsYvAj4ffGMrrlMdRHWSR5E/BHwJlV9cMxjW25LFTzS4BXAbNJHmYw97l9hb+YO8z3eSewvar+q6oeAv6VwUVgpRqm5s3AdQBV9U/ACxl8GNtPqpF/dM1KD/1hPtZhO7CpLb8VuKXaKyQr1II1J3k18OcMAn+lz/PCAjVX1Z6qOqaq1lbVWgavY5xZVbdPZrgjMcy/7b9hcJdPkmMYTPc8OM5BjtgwNT8CnAqQ5JcYhP53xjrK8doOvKs9xXMKsKeqHlvKAVf09E4d5GMdknwQuL2qtgOXM/gRcI7BCyZnT27ESzdkzX8CvBj4QnvN+pGqOnNig16iIWv+iTJkzTcCpyW5F/gx8HtVtWJ/ih2y5vOBv0jyfgYv6p67km/iknyewYX7mPY6xYXA8wGq6tMMXrc4A5gDngLeveRzruCvlyRpkVb69I4kaREMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktSR/wH7HtRw9oOIZAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(trainY).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zXMwc7LTUGy-",
    "outputId": "af35f519-fb4b-4ef8-db24-8cd2b0c4bddb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500, 10000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Count Vectors as features\n",
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(max_features=10000)\n",
    "count_vect.fit(text_preprocessed)\n",
    "\n",
    "# transform the training and test data using count vectorizer object\n",
    "trainX_vec = count_vect.transform(trainX)\n",
    "testX_vec = count_vect.transform(testX)\n",
    "trainX_vec.shape,\n",
    "testX_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BRHWqlH7UNsV",
    "outputId": "b429e7ea-e01a-4192-ce96-2c58c4a9d178"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.85      3800\n",
      "           1       0.85      0.86      0.85      3700\n",
      "\n",
      "    accuracy                           0.85      7500\n",
      "   macro avg       0.85      0.85      0.85      7500\n",
      "weighted avg       0.85      0.85      0.85      7500\n",
      "\n",
      "[[3220  580]\n",
      " [ 535 3165]]\n",
      "Accuracy: 0.8513333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "\n",
    "#create an instance of the model\n",
    "lr_model = LogisticRegression(random_state=0, solver='lbfgs', max_iter= 10000)\n",
    "#train the model\n",
    "lr_model.fit(trainX_vec, trainY)\n",
    "\n",
    "#predict test data\n",
    "pred_test = lr_model.predict(testX_vec)\n",
    "\n",
    "#print evaluation metrics \n",
    "print(classification_report(testY,pred_test))\n",
    "print(confusion_matrix(testY,pred_test))\n",
    "print(\"Accuracy:\",accuracy_score(testY, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "2qKqYAkz7Cdm"
   },
   "outputs": [],
   "source": [
    "acc_lr_model = accuracy_score(testY, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "_ya4N9EwcM4v"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation, Input, Dropout, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "# model_ff = Sequential()\n",
    "\n",
    "\n",
    "max_tokens = 10000\n",
    "inputs = Input(shape=(max_tokens,))\n",
    "x = Dense(256, activation=\"relu\")(inputs)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model_ff = Model(inputs, outputs)\n",
    "model_ff.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gQjGlvQPdWv3",
    "outputId": "f3c6872c-3fb8-4b47-d6d3-b46702eb3205"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 10000)]           0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               2560256   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,560,513\n",
      "Trainable params: 2,560,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_ff.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "m2A3MWOwdzlz"
   },
   "outputs": [],
   "source": [
    "from pandas.core.algorithms import mode\n",
    "from keras import callbacks\n",
    "callback1 = ModelCheckpoint('best_model.pt', monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "callback2 = EarlyStopping(patience=20)\n",
    "\n",
    "callbacks=[callback1,callback2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pm_hVtVMd23G",
    "outputId": "fe3a4555-b135-40d1-c583-92ed67a09bfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_1/dense_2/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_1/dense_2/embedding_lookup_sparse/Reshape:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_1/dense_2/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272/274 [============================>.] - ETA: 0s - loss: 0.3977 - accuracy: 0.8278INFO:tensorflow:Assets written to: best_model.pt/assets\n",
      "274/274 [==============================] - 9s 18ms/step - loss: 0.3973 - accuracy: 0.8280 - val_loss: 0.3188 - val_accuracy: 0.8712\n",
      "Epoch 2/100\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 0.2157 - accuracy: 0.9154 - val_loss: 0.3291 - val_accuracy: 0.8680\n",
      "Epoch 3/100\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 0.1287 - accuracy: 0.9553 - val_loss: 0.3614 - val_accuracy: 0.8664\n",
      "Epoch 4/100\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 0.0736 - accuracy: 0.9791 - val_loss: 0.4293 - val_accuracy: 0.8671\n",
      "Epoch 5/100\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 0.0390 - accuracy: 0.9911 - val_loss: 0.4780 - val_accuracy: 0.8623\n",
      "Epoch 6/100\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0216 - accuracy: 0.9963 - val_loss: 0.5145 - val_accuracy: 0.8664\n",
      "Epoch 7/100\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 0.0121 - accuracy: 0.9989 - val_loss: 0.5770 - val_accuracy: 0.8655\n",
      "Epoch 8/100\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0090 - accuracy: 0.9989 - val_loss: 0.6502 - val_accuracy: 0.8588\n",
      "Epoch 9/100\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0076 - accuracy: 0.9991 - val_loss: 0.6564 - val_accuracy: 0.8613\n",
      "Epoch 10/100\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0046 - accuracy: 0.9998 - val_loss: 0.6850 - val_accuracy: 0.8625\n",
      "Epoch 11/100\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0044 - accuracy: 0.9998 - val_loss: 0.7078 - val_accuracy: 0.8629\n",
      "Epoch 12/100\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.7319 - val_accuracy: 0.8620\n",
      "Epoch 13/100\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.7413 - val_accuracy: 0.8580\n",
      "Epoch 14/100\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 0.7662 - val_accuracy: 0.8603\n",
      "Epoch 15/100\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 0.8336 - val_accuracy: 0.8515\n",
      "Epoch 16/100\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0176 - accuracy: 0.9951 - val_loss: 0.7284 - val_accuracy: 0.8577\n",
      "Epoch 17/100\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0108 - accuracy: 0.9973 - val_loss: 0.7627 - val_accuracy: 0.8597\n",
      "Epoch 18/100\n",
      "274/274 [==============================] - 4s 15ms/step - loss: 0.0044 - accuracy: 0.9993 - val_loss: 0.8486 - val_accuracy: 0.8564\n",
      "Epoch 19/100\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.8194 - val_accuracy: 0.8579\n",
      "Epoch 20/100\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.8653 - val_accuracy: 0.8619\n",
      "Epoch 21/100\n",
      "274/274 [==============================] - 4s 14ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.8828 - val_accuracy: 0.8615\n"
     ]
    }
   ],
   "source": [
    "train_history = model_ff.fit(trainX_vec, trainY, epochs=100, callbacks=callbacks, \n",
    "          validation_data=(testX_vec, testY), batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "RwCw38EmkOzl"
   },
   "outputs": [],
   "source": [
    "pred_test = model_ff.predict(testX_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r5fMgB-Iirzc",
    "outputId": "16990b86-5e96-44a9-fe51-e09997f57896"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.977426]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(pred_test[0])\n",
    "print(testY[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27S_VSfHjccc",
    "outputId": "a5a052f2-0585-4e66-bb8e-d60e96fa4544"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(len(testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dwyaiv4JjfKx",
    "outputId": "84303a90-8dd8-49be-89fd-8cde3b3221bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_y = np.zeros(len(testY))\n",
    "pred_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "VR6rBwrHjIZ1"
   },
   "outputs": [],
   "source": [
    "new_test_y[pred_test.reshape(7500) > 0.5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CBUwuVyRdRMp",
    "outputId": "333c5b85-efd6-4dae-f099-37291de815f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86      3800\n",
      "           1       0.86      0.86      0.86      3700\n",
      "\n",
      "    accuracy                           0.86      7500\n",
      "   macro avg       0.86      0.86      0.86      7500\n",
      "weighted avg       0.86      0.86      0.86      7500\n",
      "\n",
      "[[3291  509]\n",
      " [ 530 3170]]\n",
      "Accuracy: 0.8614666666666667\n"
     ]
    }
   ],
   "source": [
    "#print evaluation metrics \n",
    "print(classification_report(testY,new_test_y))\n",
    "print(confusion_matrix(testY,new_test_y))\n",
    "print(\"Accuracy:\",accuracy_score(testY, new_test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "gwKZTTEg7aLv"
   },
   "outputs": [],
   "source": [
    "acc_model_ff = accuracy_score(testY, new_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Am3YE4qCVJIl"
   },
   "source": [
    "So zgolemuvanje na brojot na iteracii se zgolemuva accuracy, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zW6WwYIQsWmO"
   },
   "source": [
    "## TF-IDF \n",
    "\n",
    "- use TfidfVectorizer to create the feature vectors\n",
    "- Use ngram_range=(1,2)\n",
    "- Train two models: Logistic Regression and a simple Feed Forward Network\n",
    "- Check if n-grams improve the results and use the best models for the final evaluation\n",
    "- Evaluate the model on the test data (calculate: accuracy, precision, recall and F1-score for each class, and the confusion matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bClgO07WiWB",
    "outputId": "cefcd0ad-ae81-45ca-ed7b-9499e238450d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17500, 10000), (7500, 10000))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2),max_features=10000) \n",
    "tfidf.fit(text)\n",
    "\n",
    "X_train_tfidf = tfidf.transform(trainX)\n",
    "X_test_tfidf = tfidf.transform(testX)\n",
    "\n",
    "X_train_tfidf.shape, X_test_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BAQloY82Wrq5",
    "outputId": "c6688cd8-5653-4c22-b134-c95434b7fa09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87      3800\n",
      "           1       0.86      0.87      0.87      3700\n",
      "\n",
      "    accuracy                           0.87      7500\n",
      "   macro avg       0.87      0.87      0.87      7500\n",
      "weighted avg       0.87      0.87      0.87      7500\n",
      "\n",
      "[[3263  537]\n",
      " [ 464 3236]]\n",
      "Accuracy: 0.8665333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model_tf = LogisticRegression(random_state=0)\n",
    "lr_model_tf.fit(X_train_tfidf, trainY)\n",
    "pred_test_tf = lr_model_tf.predict(X_test_tfidf)\n",
    "\n",
    "#print evaluation metrics \n",
    "print(classification_report(testY,pred_test_tf))\n",
    "print(confusion_matrix(testY,pred_test_tf))\n",
    "print(\"Accuracy:\",accuracy_score(testY, pred_test_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "Ga1MNW_l70Fo"
   },
   "outputs": [],
   "source": [
    "acc_tf = accuracy_score(testY, pred_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "nfZ0lijVs0xL"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation, Input, Dropout, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "max_tokens = 10000\n",
    "inputs = Input(shape=(max_tokens,))\n",
    "x = Dense(256, activation=\"relu\")(inputs)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model_ff_tf = Model(inputs, outputs)\n",
    "model_ff_tf.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ajcEyzpBx5d-",
    "outputId": "040808d4-1df0-45e4-da46-c159824da1df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 10000)]           0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 256)               2560256   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,560,513\n",
      "Trainable params: 2,560,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_ff_tf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "hkr7SR0kyCXm"
   },
   "outputs": [],
   "source": [
    "from pandas.core.algorithms import mode\n",
    "from keras import callbacks\n",
    "callback1 = ModelCheckpoint('best_model.pt', monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "callback2 = EarlyStopping(patience=20)\n",
    "\n",
    "callbacks=[callback1,callback2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "nhCR8qq341jk"
   },
   "outputs": [],
   "source": [
    "#t1 = X_test_tfidf.todense() ne saka ni so ova, probav i bez validation data, ne mi uspea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "F03Pd_tGyOpc"
   },
   "outputs": [],
   "source": [
    "#train_history_tf = model_ff_tf.fit(X_train_tfidf, trainY,epochs=50, callbacks=callbacks,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53X7mFLh-qr9"
   },
   "source": [
    "## WordEmbeddings model\n",
    "\n",
    "In addition to the previous pre-processing steps:\n",
    "\n",
    "- Truncate and pad the input sequences so that they are all the same length for modeling, size = 30 (use sequence.pad_sequences)\n",
    "- Train two Keras Sequential model with: \n",
    "\n",
    "  * Embedding layer (20 units), LSTM layer (20 units), Dense layer (1 unit). \n",
    "  * Embedding layer (50 units), LSTM layer (20 units), Dense layer (1 unit). \n",
    "- Try the models with other sequenc sizes ( 30, 50,  100)\n",
    "- Use the best 2 models for the final evaluation\n",
    "- Evaluate the models on the test data (calculate: accuracy, precision, recall and F1-score for each class, and the confusion matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "CFhDS9ULW5OQ"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer #similar to the CountVectorizer and TfIDF from sci-kit\n",
    "\n",
    "#The word embedding layer expects input sequences to be comprised of integers.\n",
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(text_preprocessed)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(text_preprocessed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "FsYvZzktXBcA",
    "outputId": "105ed684-7311-4d79-fde5-a17a64b2fb22"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'powerful let love becomes reach journalist lot anyone atmosphere never room titillate heart show year every never go villaronga help moment every chest visual movie except several enough current film mine potentially unfortunately get camp movie sometimes movie scary pratfall story wonderful see character 70 musician heart shadow serious critic isnt one tricky see land anyone gilmores br show whether history name half br n odd two mean 1 boat thought frog script history heart real barrel one bit two script nobody wasnt arm act watch heartfelt film want'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocessed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-fmfV6jcXBme",
    "outputId": "47bfa2b7-2a70-4bc1-cea1-b7761178d904"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[843,\n",
       " 158,\n",
       " 37,\n",
       " 381,\n",
       " 926,\n",
       " 2966,\n",
       " 67,\n",
       " 179,\n",
       " 704,\n",
       " 50,\n",
       " 490,\n",
       " 10681,\n",
       " 356,\n",
       " 20,\n",
       " 46,\n",
       " 92,\n",
       " 50,\n",
       " 14,\n",
       " 16411,\n",
       " 163,\n",
       " 164,\n",
       " 92,\n",
       " 3747,\n",
       " 977,\n",
       " 2,\n",
       " 446,\n",
       " 366,\n",
       " 112,\n",
       " 1749,\n",
       " 3,\n",
       " 1490,\n",
       " 3997,\n",
       " 387,\n",
       " 8,\n",
       " 949,\n",
       " 2,\n",
       " 426,\n",
       " 2,\n",
       " 523,\n",
       " 12150,\n",
       " 16,\n",
       " 312,\n",
       " 7,\n",
       " 12,\n",
       " 716,\n",
       " 2689,\n",
       " 356,\n",
       " 1505,\n",
       " 521,\n",
       " 984,\n",
       " 130,\n",
       " 4,\n",
       " 8562,\n",
       " 7,\n",
       " 888,\n",
       " 179,\n",
       " 23531,\n",
       " 1,\n",
       " 20,\n",
       " 616,\n",
       " 392,\n",
       " 159,\n",
       " 232,\n",
       " 1,\n",
       " 2077,\n",
       " 872,\n",
       " 42,\n",
       " 188,\n",
       " 213,\n",
       " 1683,\n",
       " 106,\n",
       " 5054,\n",
       " 119,\n",
       " 392,\n",
       " 356,\n",
       " 65,\n",
       " 4163,\n",
       " 4,\n",
       " 121,\n",
       " 42,\n",
       " 119,\n",
       " 1104,\n",
       " 200,\n",
       " 1197,\n",
       " 34,\n",
       " 13,\n",
       " 4648,\n",
       " 3,\n",
       " 49]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OjEZPIClXHpz",
    "outputId": "318cf937-5173-47b9-be9f-5298e2d70fe5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wzu2QUEaXKpC",
    "outputId": "53717bb3-f690-4d95-e475-17d5fffcd1d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'br': 1,\n",
       " 'movie': 2,\n",
       " 'film': 3,\n",
       " 'one': 4,\n",
       " 'make': 5,\n",
       " 'like': 6,\n",
       " 'see': 7,\n",
       " 'get': 8,\n",
       " 'time': 9,\n",
       " 'well': 10,\n",
       " 'good': 11,\n",
       " 'character': 12,\n",
       " 'watch': 13,\n",
       " 'go': 14,\n",
       " 'bad': 15,\n",
       " 'story': 16,\n",
       " 'even': 17,\n",
       " 'would': 18,\n",
       " 'really': 19,\n",
       " 'show': 20,\n",
       " 'scene': 21,\n",
       " 'much': 22,\n",
       " 'look': 23,\n",
       " 'great': 24,\n",
       " 'end': 25,\n",
       " 'say': 26,\n",
       " 'people': 27,\n",
       " 'think': 28,\n",
       " 'also': 29,\n",
       " 'way': 30,\n",
       " 'first': 31,\n",
       " 'dont': 32,\n",
       " 'give': 33,\n",
       " 'act': 34,\n",
       " 'take': 35,\n",
       " 'know': 36,\n",
       " 'love': 37,\n",
       " 'come': 38,\n",
       " 'thing': 39,\n",
       " 'life': 40,\n",
       " 'could': 41,\n",
       " 'two': 42,\n",
       " 'seem': 43,\n",
       " 'work': 44,\n",
       " 'plot': 45,\n",
       " 'year': 46,\n",
       " 'actor': 47,\n",
       " 'many': 48,\n",
       " 'want': 49,\n",
       " 'never': 50,\n",
       " 'little': 51,\n",
       " 'best': 52,\n",
       " 'try': 53,\n",
       " 'ever': 54,\n",
       " 'man': 55,\n",
       " 'play': 56,\n",
       " 'still': 57,\n",
       " 'find': 58,\n",
       " 'old': 59,\n",
       " 'part': 60,\n",
       " 'something': 61,\n",
       " 'director': 62,\n",
       " 'back': 63,\n",
       " 'im': 64,\n",
       " 'real': 65,\n",
       " 'feel': 66,\n",
       " 'lot': 67,\n",
       " 'performance': 68,\n",
       " 'cast': 69,\n",
       " 'woman': 70,\n",
       " 'though': 71,\n",
       " 'doesnt': 72,\n",
       " 'star': 73,\n",
       " '10': 74,\n",
       " 'use': 75,\n",
       " 'u': 76,\n",
       " 'guy': 77,\n",
       " 'didnt': 78,\n",
       " 'another': 79,\n",
       " 'new': 80,\n",
       " 'big': 81,\n",
       " 'nothing': 82,\n",
       " 'role': 83,\n",
       " 'funny': 84,\n",
       " 'actually': 85,\n",
       " 'interest': 86,\n",
       " 'young': 87,\n",
       " 'point': 88,\n",
       " 'write': 89,\n",
       " 'start': 90,\n",
       " 'girl': 91,\n",
       " 'every': 92,\n",
       " 'day': 93,\n",
       " 'world': 94,\n",
       " 'set': 95,\n",
       " 'quite': 96,\n",
       " 'turn': 97,\n",
       " 'thats': 98,\n",
       " 'cant': 99,\n",
       " 'fact': 100,\n",
       " 'horror': 101,\n",
       " 'minute': 102,\n",
       " 'comedy': 103,\n",
       " 'pretty': 104,\n",
       " 'action': 105,\n",
       " 'thought': 106,\n",
       " 'around': 107,\n",
       " 'however': 108,\n",
       " 'kill': 109,\n",
       " 'long': 110,\n",
       " 'right': 111,\n",
       " 'enough': 112,\n",
       " 'line': 113,\n",
       " 'family': 114,\n",
       " 'original': 115,\n",
       " 'series': 116,\n",
       " 'fan': 117,\n",
       " 'may': 118,\n",
       " 'script': 119,\n",
       " 'need': 120,\n",
       " 'bit': 121,\n",
       " 'ive': 122,\n",
       " 'always': 123,\n",
       " 'without': 124,\n",
       " 'begin': 125,\n",
       " 'friend': 126,\n",
       " 'enjoy': 127,\n",
       " 'tell': 128,\n",
       " 'must': 129,\n",
       " 'isnt': 130,\n",
       " 'saw': 131,\n",
       " 'almost': 132,\n",
       " 'last': 133,\n",
       " 'least': 134,\n",
       " 'kid': 135,\n",
       " 'put': 136,\n",
       " 'do': 137,\n",
       " 'there': 138,\n",
       " 'believe': 139,\n",
       " 'music': 140,\n",
       " 'whole': 141,\n",
       " 'place': 142,\n",
       " 'kind': 143,\n",
       " 'far': 144,\n",
       " 'lead': 145,\n",
       " 'shot': 146,\n",
       " 'reason': 147,\n",
       " 'book': 148,\n",
       " 'anything': 149,\n",
       " 'might': 150,\n",
       " 'since': 151,\n",
       " 'laugh': 152,\n",
       " 'he': 153,\n",
       " '2': 154,\n",
       " 'probably': 155,\n",
       " 'effect': 156,\n",
       " 'away': 157,\n",
       " 'let': 158,\n",
       " 'name': 159,\n",
       " 'tv': 160,\n",
       " 'screen': 161,\n",
       " 'call': 162,\n",
       " 'help': 163,\n",
       " 'moment': 164,\n",
       " 'yet': 165,\n",
       " 'rather': 166,\n",
       " 'fun': 167,\n",
       " 'run': 168,\n",
       " 'sure': 169,\n",
       " 'audience': 170,\n",
       " 'hard': 171,\n",
       " 'child': 172,\n",
       " 'found': 173,\n",
       " 'played': 174,\n",
       " 'idea': 175,\n",
       " 'american': 176,\n",
       " 'episode': 177,\n",
       " 'become': 178,\n",
       " 'anyone': 179,\n",
       " 'high': 180,\n",
       " 'although': 181,\n",
       " 'especially': 182,\n",
       " 'course': 183,\n",
       " 'expect': 184,\n",
       " 'keep': 185,\n",
       " 'happen': 186,\n",
       " 'job': 187,\n",
       " 'mean': 188,\n",
       " 'move': 189,\n",
       " 'dvd': 190,\n",
       " 'version': 191,\n",
       " 'war': 192,\n",
       " 'different': 193,\n",
       " 'money': 194,\n",
       " 'someone': 195,\n",
       " 'mind': 196,\n",
       " 'maybe': 197,\n",
       " 'sense': 198,\n",
       " 'problem': 199,\n",
       " 'wasnt': 200,\n",
       " 'true': 201,\n",
       " 'three': 202,\n",
       " 'second': 203,\n",
       " 'everything': 204,\n",
       " 'house': 205,\n",
       " 'worth': 206,\n",
       " 'night': 207,\n",
       " 'face': 208,\n",
       " 'wife': 209,\n",
       " 'main': 210,\n",
       " 'together': 211,\n",
       " 'sound': 212,\n",
       " '1': 213,\n",
       " 'john': 214,\n",
       " 'follow': 215,\n",
       " 'father': 216,\n",
       " 'waste': 217,\n",
       " 'direct': 218,\n",
       " 'later': 219,\n",
       " 'beautiful': 220,\n",
       " 'recommend': 221,\n",
       " 'instead': 222,\n",
       " 'boy': 223,\n",
       " 'fall': 224,\n",
       " 'hour': 225,\n",
       " 'miss': 226,\n",
       " 'special': 227,\n",
       " 'black': 228,\n",
       " 'talk': 229,\n",
       " 'everyone': 230,\n",
       " 'left': 231,\n",
       " 'half': 232,\n",
       " 'low': 233,\n",
       " 'lose': 234,\n",
       " 'death': 235,\n",
       " 'view': 236,\n",
       " 'excellent': 237,\n",
       " 'hand': 238,\n",
       " 'read': 239,\n",
       " 'eye': 240,\n",
       " 'classic': 241,\n",
       " 'head': 242,\n",
       " 'viewer': 243,\n",
       " 'nice': 244,\n",
       " 'fight': 245,\n",
       " 'less': 246,\n",
       " 'remember': 247,\n",
       " 'short': 248,\n",
       " 'change': 249,\n",
       " 'include': 250,\n",
       " 'simply': 251,\n",
       " 'piece': 252,\n",
       " 'production': 253,\n",
       " 'appear': 254,\n",
       " 'picture': 255,\n",
       " 'live': 256,\n",
       " 'else': 257,\n",
       " 'youre': 258,\n",
       " 'home': 259,\n",
       " 'top': 260,\n",
       " 'budget': 261,\n",
       " 'understand': 262,\n",
       " 'attempt': 263,\n",
       " 'men': 264,\n",
       " 'poor': 265,\n",
       " 'suppose': 266,\n",
       " 'song': 267,\n",
       " 'release': 268,\n",
       " 'human': 269,\n",
       " 'hollywood': 270,\n",
       " '3': 271,\n",
       " 'feature': 272,\n",
       " 'care': 273,\n",
       " 'couple': 274,\n",
       " 'completely': 275,\n",
       " 'camera': 276,\n",
       " 'dead': 277,\n",
       " 'video': 278,\n",
       " 'either': 279,\n",
       " 'wrong': 280,\n",
       " 'entertain': 281,\n",
       " 'rest': 282,\n",
       " 'lack': 283,\n",
       " 'word': 284,\n",
       " 'boring': 285,\n",
       " 'writer': 286,\n",
       " 'title': 287,\n",
       " 'full': 288,\n",
       " 'small': 289,\n",
       " 'along': 290,\n",
       " 'murder': 291,\n",
       " 'truly': 292,\n",
       " 'awful': 293,\n",
       " 'add': 294,\n",
       " 'style': 295,\n",
       " 'school': 296,\n",
       " 'hope': 297,\n",
       " 'next': 298,\n",
       " 'sex': 299,\n",
       " 'save': 300,\n",
       " 'killer': 301,\n",
       " 'age': 302,\n",
       " 'stupid': 303,\n",
       " 'case': 304,\n",
       " 'mr': 305,\n",
       " 'perhaps': 306,\n",
       " 'sort': 307,\n",
       " 'person': 308,\n",
       " 'review': 309,\n",
       " 'others': 310,\n",
       " 'brother': 311,\n",
       " 'wonderful': 312,\n",
       " 'dialogue': 313,\n",
       " 'game': 314,\n",
       " 'wonder': 315,\n",
       " 'base': 316,\n",
       " 'early': 317,\n",
       " 'terrible': 318,\n",
       " 'involve': 319,\n",
       " 'perfect': 320,\n",
       " 'die': 321,\n",
       " 'flick': 322,\n",
       " 'often': 323,\n",
       " 'sequence': 324,\n",
       " 'fine': 325,\n",
       " 'mother': 326,\n",
       " 'art': 327,\n",
       " 'joke': 328,\n",
       " 'comment': 329,\n",
       " 'leave': 330,\n",
       " 'definitely': 331,\n",
       " 'actress': 332,\n",
       " 'guess': 333,\n",
       " 'white': 334,\n",
       " 'drama': 335,\n",
       " 'example': 336,\n",
       " 'cinema': 337,\n",
       " 'stop': 338,\n",
       " 'mention': 339,\n",
       " 'consider': 340,\n",
       " 'light': 341,\n",
       " 'yes': 342,\n",
       " 'finally': 343,\n",
       " 'felt': 344,\n",
       " 'amaze': 345,\n",
       " 'couldnt': 346,\n",
       " 'cut': 347,\n",
       " 'force': 348,\n",
       " 'quality': 349,\n",
       " 'absolutely': 350,\n",
       " 'hit': 351,\n",
       " 'son': 352,\n",
       " 'car': 353,\n",
       " 'side': 354,\n",
       " 'direction': 355,\n",
       " 'heart': 356,\n",
       " 'evil': 357,\n",
       " 'certainly': 358,\n",
       " 'shes': 359,\n",
       " 'entire': 360,\n",
       " 'stand': 361,\n",
       " 'oh': 362,\n",
       " 'overall': 363,\n",
       " 'create': 364,\n",
       " 'favorite': 365,\n",
       " 'several': 366,\n",
       " 'close': 367,\n",
       " 'late': 368,\n",
       " 'id': 369,\n",
       " 'number': 370,\n",
       " 'support': 371,\n",
       " 'dance': 372,\n",
       " '5': 373,\n",
       " 'type': 374,\n",
       " 'wait': 375,\n",
       " 'voice': 376,\n",
       " 'hero': 377,\n",
       " 'dark': 378,\n",
       " 'matter': 379,\n",
       " 'already': 380,\n",
       " 'becomes': 381,\n",
       " '4': 382,\n",
       " 'genre': 383,\n",
       " 'michael': 384,\n",
       " 'despite': 385,\n",
       " 'throughout': 386,\n",
       " 'unfortunately': 387,\n",
       " 'walk': 388,\n",
       " 'final': 389,\n",
       " '\\x96': 390,\n",
       " 'meet': 391,\n",
       " 'history': 392,\n",
       " 'relationship': 393,\n",
       " 'humor': 394,\n",
       " 'town': 395,\n",
       " 'daughter': 396,\n",
       " 'experience': 397,\n",
       " 'totally': 398,\n",
       " 'present': 399,\n",
       " 'power': 400,\n",
       " 'wont': 401,\n",
       " 'strong': 402,\n",
       " 'b': 403,\n",
       " 'youll': 404,\n",
       " 'theme': 405,\n",
       " 'wish': 406,\n",
       " 'city': 407,\n",
       " 'event': 408,\n",
       " 'credit': 409,\n",
       " 'touch': 410,\n",
       " 'behind': 411,\n",
       " 'today': 412,\n",
       " 'ill': 413,\n",
       " 'past': 414,\n",
       " 'god': 415,\n",
       " 'able': 416,\n",
       " 'twist': 417,\n",
       " 'rent': 418,\n",
       " 'zombie': 419,\n",
       " 'blood': 420,\n",
       " 'theyre': 421,\n",
       " 'deal': 422,\n",
       " 'decide': 423,\n",
       " 'question': 424,\n",
       " 'soon': 425,\n",
       " 'sometimes': 426,\n",
       " 'slow': 427,\n",
       " 'etc': 428,\n",
       " 'self': 429,\n",
       " 'level': 430,\n",
       " 'horrible': 431,\n",
       " 'score': 432,\n",
       " 'chance': 433,\n",
       " 'talent': 434,\n",
       " 'brilliant': 435,\n",
       " 'body': 436,\n",
       " 'stuff': 437,\n",
       " 'element': 438,\n",
       " 'dream': 439,\n",
       " 'obviously': 440,\n",
       " 'return': 441,\n",
       " 'musical': 442,\n",
       " 'figure': 443,\n",
       " 'ask': 444,\n",
       " 'decent': 445,\n",
       " 'except': 446,\n",
       " 'sit': 447,\n",
       " 'order': 448,\n",
       " 'pace': 449,\n",
       " 'situation': 450,\n",
       " 'highly': 451,\n",
       " 'hell': 452,\n",
       " 'learn': 453,\n",
       " 'group': 454,\n",
       " 'lady': 455,\n",
       " 'novel': 456,\n",
       " 'anyway': 457,\n",
       " 'complete': 458,\n",
       " 'career': 459,\n",
       " 'please': 460,\n",
       " 'heard': 461,\n",
       " 'police': 462,\n",
       " 'edit': 463,\n",
       " 'husband': 464,\n",
       " 'break': 465,\n",
       " 'rating': 466,\n",
       " 'violence': 467,\n",
       " 'bring': 468,\n",
       " 'robert': 469,\n",
       " 'country': 470,\n",
       " 'happens': 471,\n",
       " 'particularly': 472,\n",
       " 'shoot': 473,\n",
       " 'open': 474,\n",
       " 'stay': 475,\n",
       " 'obvious': 476,\n",
       " 'extremely': 477,\n",
       " 'documentary': 478,\n",
       " 'realize': 479,\n",
       " 'james': 480,\n",
       " 'wouldnt': 481,\n",
       " 'told': 482,\n",
       " 'living': 483,\n",
       " 'alone': 484,\n",
       " 'season': 485,\n",
       " 'theater': 486,\n",
       " 'crap': 487,\n",
       " 'hold': 488,\n",
       " 'gore': 489,\n",
       " 'room': 490,\n",
       " 'state': 491,\n",
       " 'reality': 492,\n",
       " 'effort': 493,\n",
       " 'opinion': 494,\n",
       " 'thriller': 495,\n",
       " 'cause': 496,\n",
       " 'annoy': 497,\n",
       " 'result': 498,\n",
       " 'sequel': 499,\n",
       " 'rock': 500,\n",
       " 'ago': 501,\n",
       " 'king': 502,\n",
       " 'comic': 503,\n",
       " 'none': 504,\n",
       " 'ok': 505,\n",
       " 'female': 506,\n",
       " 'note': 507,\n",
       " 'david': 508,\n",
       " 'sister': 509,\n",
       " 'simple': 510,\n",
       " 'oscar': 511,\n",
       " 'class': 512,\n",
       " 'value': 513,\n",
       " 'focus': 514,\n",
       " 'seriously': 515,\n",
       " 'win': 516,\n",
       " 'possible': 517,\n",
       " 'exactly': 518,\n",
       " 'spoiler': 519,\n",
       " 'sad': 520,\n",
       " 'serious': 521,\n",
       " 'compare': 522,\n",
       " 'scary': 523,\n",
       " 'english': 524,\n",
       " 'whose': 525,\n",
       " 'opening': 526,\n",
       " 'cinematography': 527,\n",
       " 'usually': 528,\n",
       " 'shock': 529,\n",
       " 'provide': 530,\n",
       " 'across': 531,\n",
       " 'cool': 532,\n",
       " 'message': 533,\n",
       " 'hilarious': 534,\n",
       " 'middle': 535,\n",
       " 'street': 536,\n",
       " 'usual': 537,\n",
       " 'happy': 538,\n",
       " 'somewhat': 539,\n",
       " 'charm': 540,\n",
       " 'ridiculous': 541,\n",
       " 'easy': 542,\n",
       " 'mystery': 543,\n",
       " 'cop': 544,\n",
       " 'tale': 545,\n",
       " 'form': 546,\n",
       " 'single': 547,\n",
       " 'local': 548,\n",
       " 'major': 549,\n",
       " 'produce': 550,\n",
       " 'huge': 551,\n",
       " 'mostly': 552,\n",
       " 'check': 553,\n",
       " 'important': 554,\n",
       " 'team': 555,\n",
       " 'five': 556,\n",
       " 'jack': 557,\n",
       " 'avoid': 558,\n",
       " 'monster': 559,\n",
       " 'modern': 560,\n",
       " 'attention': 561,\n",
       " 'george': 562,\n",
       " 'earth': 563,\n",
       " 'speak': 564,\n",
       " 'cover': 565,\n",
       " 'producer': 566,\n",
       " 'strange': 567,\n",
       " 'due': 568,\n",
       " 'apparently': 569,\n",
       " 'pull': 570,\n",
       " 'disappointed': 571,\n",
       " 'four': 572,\n",
       " 'surprise': 573,\n",
       " 'offer': 574,\n",
       " 'fill': 575,\n",
       " 'dialog': 576,\n",
       " 'future': 577,\n",
       " 'fast': 578,\n",
       " '7': 579,\n",
       " 'television': 580,\n",
       " 'basically': 581,\n",
       " 'subject': 582,\n",
       " 'imagine': 583,\n",
       " 'clearly': 584,\n",
       " 'filmmaker': 585,\n",
       " 'paul': 586,\n",
       " 'pay': 587,\n",
       " 'knew': 588,\n",
       " 'british': 589,\n",
       " '80': 590,\n",
       " 'non': 591,\n",
       " 'parent': 592,\n",
       " 'dog': 593,\n",
       " 'crime': 594,\n",
       " 'entertainment': 595,\n",
       " '8': 596,\n",
       " 'hate': 597,\n",
       " 'cheap': 598,\n",
       " 'easily': 599,\n",
       " 'arent': 600,\n",
       " 'silly': 601,\n",
       " 'adult': 602,\n",
       " 'fail': 603,\n",
       " 'villain': 604,\n",
       " 'date': 605,\n",
       " 'member': 606,\n",
       " 'fire': 607,\n",
       " 'near': 608,\n",
       " 'gun': 609,\n",
       " 'drive': 610,\n",
       " 'animation': 611,\n",
       " 'escape': 612,\n",
       " 'beyond': 613,\n",
       " 'straight': 614,\n",
       " 'upon': 615,\n",
       " 'whether': 616,\n",
       " 'romantic': 617,\n",
       " 'whats': 618,\n",
       " 'doubt': 619,\n",
       " 'predictable': 620,\n",
       " 'weak': 621,\n",
       " 'ten': 622,\n",
       " 'image': 623,\n",
       " 'peter': 624,\n",
       " 'similar': 625,\n",
       " 'aspect': 626,\n",
       " 'capture': 627,\n",
       " 'explain': 628,\n",
       " 'richard': 629,\n",
       " 'enjoyable': 630,\n",
       " 'within': 631,\n",
       " 'air': 632,\n",
       " 'red': 633,\n",
       " 'chase': 634,\n",
       " 'dull': 635,\n",
       " 'buy': 636,\n",
       " 'storyline': 637,\n",
       " 'attack': 638,\n",
       " 'carry': 639,\n",
       " 'nearly': 640,\n",
       " 'bunch': 641,\n",
       " 'lee': 642,\n",
       " 'match': 643,\n",
       " 'period': 644,\n",
       " 'york': 645,\n",
       " 'clear': 646,\n",
       " 'havent': 647,\n",
       " 'mess': 648,\n",
       " 'standard': 649,\n",
       " 'finish': 650,\n",
       " 'surprised': 651,\n",
       " 'space': 652,\n",
       " 'fantastic': 653,\n",
       " 'actual': 654,\n",
       " 'steal': 655,\n",
       " 'sing': 656,\n",
       " 'victim': 657,\n",
       " 'material': 658,\n",
       " 'de': 659,\n",
       " 'french': 660,\n",
       " '9': 661,\n",
       " 'tom': 662,\n",
       " 'mark': 663,\n",
       " 'confuse': 664,\n",
       " 'emotion': 665,\n",
       " 'general': 666,\n",
       " 'stage': 667,\n",
       " 'among': 668,\n",
       " 'typical': 669,\n",
       " 'soundtrack': 670,\n",
       " 'spirit': 671,\n",
       " 'detail': 672,\n",
       " 'third': 673,\n",
       " 'soldier': 674,\n",
       " 'famous': 675,\n",
       " 'sorry': 676,\n",
       " 'baby': 677,\n",
       " 'grow': 678,\n",
       " 'drug': 679,\n",
       " 'forget': 680,\n",
       " 'western': 681,\n",
       " 'lame': 682,\n",
       " 'certain': 683,\n",
       " 'cry': 684,\n",
       " 'romance': 685,\n",
       " 'excite': 686,\n",
       " 'allow': 687,\n",
       " 'somehow': 688,\n",
       " 'realistic': 689,\n",
       " 'disney': 690,\n",
       " 'battle': 691,\n",
       " 'cartoon': 692,\n",
       " 'student': 693,\n",
       " 'kept': 694,\n",
       " 'truth': 695,\n",
       " 'animal': 696,\n",
       " 'suck': 697,\n",
       " 'bill': 698,\n",
       " 'premise': 699,\n",
       " 'list': 700,\n",
       " 'appeal': 701,\n",
       " 'suspense': 702,\n",
       " 'pick': 703,\n",
       " 'atmosphere': 704,\n",
       " 'bore': 705,\n",
       " 'throw': 706,\n",
       " 'hear': 707,\n",
       " 'particular': 708,\n",
       " 'manage': 709,\n",
       " 'brought': 710,\n",
       " 'america': 711,\n",
       " 'large': 712,\n",
       " 'screenplay': 713,\n",
       " 'whatever': 714,\n",
       " 'who': 715,\n",
       " '70': 716,\n",
       " 'plan': 717,\n",
       " 'fear': 718,\n",
       " 'average': 719,\n",
       " 'issue': 720,\n",
       " 'nature': 721,\n",
       " 'male': 722,\n",
       " 'treat': 723,\n",
       " 'indeed': 724,\n",
       " '20': 725,\n",
       " 'fantasy': 726,\n",
       " 'copy': 727,\n",
       " 'secret': 728,\n",
       " 'fit': 729,\n",
       " 'background': 730,\n",
       " 'forward': 731,\n",
       " 'appreciate': 732,\n",
       " 'eventually': 733,\n",
       " 'adventure': 734,\n",
       " 'free': 735,\n",
       " 'poorly': 736,\n",
       " 'japanese': 737,\n",
       " 'sexual': 738,\n",
       " 'okay': 739,\n",
       " 'award': 740,\n",
       " 'believable': 741,\n",
       " 'youve': 742,\n",
       " 'possibly': 743,\n",
       " 'notice': 744,\n",
       " 'struggle': 745,\n",
       " 'society': 746,\n",
       " 'reading': 747,\n",
       " 'rate': 748,\n",
       " 'leaf': 749,\n",
       " 'rat': 750,\n",
       " 'accent': 751,\n",
       " 'water': 752,\n",
       " 'dr': 753,\n",
       " 'choice': 754,\n",
       " '30': 755,\n",
       " 'difficult': 756,\n",
       " 'masterpiece': 757,\n",
       " 'doctor': 758,\n",
       " 'studio': 759,\n",
       " 'fly': 760,\n",
       " 'hot': 761,\n",
       " 'admit': 762,\n",
       " 'girlfriend': 763,\n",
       " 'scream': 764,\n",
       " 'lover': 765,\n",
       " 'remake': 766,\n",
       " 'control': 767,\n",
       " 'agree': 768,\n",
       " 'costume': 769,\n",
       " 'development': 770,\n",
       " 'beauty': 771,\n",
       " 'project': 772,\n",
       " 'weird': 773,\n",
       " 'vampire': 774,\n",
       " 'wear': 775,\n",
       " 'unless': 776,\n",
       " 'shame': 777,\n",
       " 'box': 778,\n",
       " 'superb': 779,\n",
       " 'wood': 780,\n",
       " 'imdb': 781,\n",
       " 'otherwise': 782,\n",
       " 'crazy': 783,\n",
       " 'hop': 784,\n",
       " 'dramatic': 785,\n",
       " 'memorable': 786,\n",
       " 'deliver': 787,\n",
       " 'ghost': 788,\n",
       " 'joe': 789,\n",
       " 'earlier': 790,\n",
       " 'color': 791,\n",
       " 'party': 792,\n",
       " 'badly': 793,\n",
       " 'week': 794,\n",
       " 'flaw': 795,\n",
       " 'sci': 796,\n",
       " 'emotional': 797,\n",
       " 'respect': 798,\n",
       " 'fi': 799,\n",
       " 'footage': 800,\n",
       " 'maker': 801,\n",
       " 'cat': 802,\n",
       " 'deep': 803,\n",
       " 'bother': 804,\n",
       " 'plus': 805,\n",
       " 'interested': 806,\n",
       " 'stick': 807,\n",
       " 'gay': 808,\n",
       " 'deserve': 809,\n",
       " 'era': 810,\n",
       " 'e': 811,\n",
       " 'catch': 812,\n",
       " 'business': 813,\n",
       " 'design': 814,\n",
       " 'eat': 815,\n",
       " 'warn': 816,\n",
       " 'quickly': 817,\n",
       " 'towards': 818,\n",
       " 'creepy': 819,\n",
       " 'total': 820,\n",
       " 'perfectly': 821,\n",
       " 'cheesy': 822,\n",
       " 'roll': 823,\n",
       " 'unique': 824,\n",
       " '90': 825,\n",
       " 'dress': 826,\n",
       " 'mistake': 827,\n",
       " 'plenty': 828,\n",
       " 'co': 829,\n",
       " 'previous': 830,\n",
       " 'lie': 831,\n",
       " 'brings': 832,\n",
       " 'personal': 833,\n",
       " 'continue': 834,\n",
       " 'christmas': 835,\n",
       " 'rise': 836,\n",
       " 'incredibly': 837,\n",
       " 'answer': 838,\n",
       " 'apart': 839,\n",
       " 'band': 840,\n",
       " 'trouble': 841,\n",
       " 'front': 842,\n",
       " 'powerful': 843,\n",
       " 'hat': 844,\n",
       " 'meant': 845,\n",
       " 'amuse': 846,\n",
       " 'ben': 847,\n",
       " 'term': 848,\n",
       " 'potential': 849,\n",
       " 'success': 850,\n",
       " 'hardly': 851,\n",
       " 'rich': 852,\n",
       " 'political': 853,\n",
       " 'german': 854,\n",
       " 'la': 855,\n",
       " 'dumb': 856,\n",
       " 'inside': 857,\n",
       " 'law': 858,\n",
       " 'discover': 859,\n",
       " 'various': 860,\n",
       " 'fails': 861,\n",
       " 'portrayed': 862,\n",
       " 'jane': 863,\n",
       " 'brain': 864,\n",
       " 'outside': 865,\n",
       " 'location': 866,\n",
       " 'tone': 867,\n",
       " 'nudity': 868,\n",
       " 'store': 869,\n",
       " 'company': 870,\n",
       " 'amount': 871,\n",
       " 'odd': 872,\n",
       " 'post': 873,\n",
       " '50': 874,\n",
       " 'sweet': 875,\n",
       " 'married': 876,\n",
       " 'deserves': 877,\n",
       " 'flat': 878,\n",
       " 'office': 879,\n",
       " 'appearance': 880,\n",
       " 'fairly': 881,\n",
       " 'kick': 882,\n",
       " 'scott': 883,\n",
       " 'talented': 884,\n",
       " 'concept': 885,\n",
       " 'social': 886,\n",
       " 'player': 887,\n",
       " 'land': 888,\n",
       " 'plain': 889,\n",
       " 'memory': 890,\n",
       " 'share': 891,\n",
       " 'william': 892,\n",
       " 'cute': 893,\n",
       " 'crew': 894,\n",
       " 'unlike': 895,\n",
       " 'step': 896,\n",
       " 'manages': 897,\n",
       " 'mary': 898,\n",
       " 'recently': 899,\n",
       " 'master': 900,\n",
       " 'century': 901,\n",
       " 'prove': 902,\n",
       " 'suffer': 903,\n",
       " 'track': 904,\n",
       " 'portrayal': 905,\n",
       " 'sadly': 906,\n",
       " 'tension': 907,\n",
       " 'sell': 908,\n",
       " 'island': 909,\n",
       " 'spot': 910,\n",
       " 'depth': 911,\n",
       " 'cold': 912,\n",
       " 'alien': 913,\n",
       " 'language': 914,\n",
       " 'reveal': 915,\n",
       " 'sleep': 916,\n",
       " 'public': 917,\n",
       " 'culture': 918,\n",
       " 'incredible': 919,\n",
       " 'ruin': 920,\n",
       " 'pure': 921,\n",
       " 'train': 922,\n",
       " 'italian': 923,\n",
       " 'ability': 924,\n",
       " 'listen': 925,\n",
       " 'reach': 926,\n",
       " 'door': 927,\n",
       " 'science': 928,\n",
       " 'trash': 929,\n",
       " 'caught': 930,\n",
       " 'revenge': 931,\n",
       " 'creature': 932,\n",
       " 'popular': 933,\n",
       " 'remind': 934,\n",
       " 'us': 935,\n",
       " 'intrigue': 936,\n",
       " 'basic': 937,\n",
       " 'positive': 938,\n",
       " 'approach': 939,\n",
       " 'inspire': 940,\n",
       " 'decides': 941,\n",
       " 'channel': 942,\n",
       " 'suit': 943,\n",
       " 'trip': 944,\n",
       " 'record': 945,\n",
       " 'extra': 946,\n",
       " 'hole': 947,\n",
       " 'slightly': 948,\n",
       " 'camp': 949,\n",
       " 'million': 950,\n",
       " 'soul': 951,\n",
       " 'convincing': 952,\n",
       " 'slasher': 953,\n",
       " 'teen': 954,\n",
       " 'familiar': 955,\n",
       " 'v': 956,\n",
       " '6': 957,\n",
       " 'neither': 958,\n",
       " 'suddenly': 959,\n",
       " 'spent': 960,\n",
       " 'computer': 961,\n",
       " 'animate': 962,\n",
       " 'intelligent': 963,\n",
       " 'planet': 964,\n",
       " 'adaptation': 965,\n",
       " 'conclusion': 966,\n",
       " 'clever': 967,\n",
       " 'fake': 968,\n",
       " 'travel': 969,\n",
       " 'entirely': 970,\n",
       " 'blue': 971,\n",
       " 'taste': 972,\n",
       " 'indian': 973,\n",
       " 'detective': 974,\n",
       " 'fashion': 975,\n",
       " 'purpose': 976,\n",
       " 'visual': 977,\n",
       " 'successful': 978,\n",
       " '15': 979,\n",
       " 'drop': 980,\n",
       " 'ring': 981,\n",
       " 'violent': 982,\n",
       " 'drag': 983,\n",
       " 'critic': 984,\n",
       " 'ultimately': 985,\n",
       " 'hair': 986,\n",
       " 'disappoint': 987,\n",
       " 'suspect': 988,\n",
       " 'search': 989,\n",
       " 'edge': 990,\n",
       " 'handle': 991,\n",
       " 'haunt': 992,\n",
       " 'engage': 993,\n",
       " 'c': 994,\n",
       " 'hurt': 995,\n",
       " 'artist': 996,\n",
       " 'dad': 997,\n",
       " 'former': 998,\n",
       " 'disturb': 999,\n",
       " 'effective': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iDScciIPXBol",
    "outputId": "08801a38-7793-40f7-c3d6-c7f310731ada"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((17500,), (7500,))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = np.array(sequences)\n",
    "\n",
    "train_part= int(len(text)*0.7)\n",
    "train_X, test_X =sequences[:train_part], sequences[train_part:]\n",
    "\n",
    "train_X.shape,test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cDHHIyPrXXXr",
    "outputId": "f79d2613-339b-4ad2-82b6-5d88d1da5599"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17500, 100)\n",
      "(7500, 100)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_len = 100\n",
    "#transforms a list (of length num_samples) of sequences (lists of integers) \n",
    "#into a 2D Numpy array of shape (num_samples, num_timesteps) num_timesteps is the maxlen argument.\n",
    "train_X_pad = pad_sequences(train_X, maxlen=max_len)\n",
    "test_X_pad = pad_sequences(test_X, maxlen=max_len)\n",
    "print(train_X_pad.shape)\n",
    "print(test_X_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TXQwJ0EUX2Zj",
    "outputId": "45049910-5f37-442e-b2f6-fc570bd4ff1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64676"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "ls--G-Belszz"
   },
   "outputs": [],
   "source": [
    "callback1 = ModelCheckpoint('best_model.pt', monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "callback2 = EarlyStopping(patience=10)\n",
    "\n",
    "callbacks=[callback1,callback2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "oGsS11EYXtyn"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input,Embedding,LSTM,Dense\n",
    "\n",
    "def generate_model(vocab_size, max_len, embedding_size, lstm_size):\n",
    "\n",
    "    _input = Input(max_len)\n",
    "\n",
    "    x = Embedding(input_dim = vocab_size, output_dim = embedding_size) (_input)\n",
    "\n",
    "    x = LSTM(lstm_size)(x)\n",
    "\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs= [_input], outputs = [output])\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VtQaSqvdX7fx",
    "outputId": "4de09452-a401-456e-e808-5473e449b158"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 100, 20)           1293520   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 50)                14200     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,307,771\n",
      "Trainable params: 1,307,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = generate_model(vocab_size,max_len,embedding_size=20, lstm_size = 50)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "woGdw6qdmDHt",
    "outputId": "349ac99f-333b-4427-d6c1-b2728f6d5a1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "291/292 [============================>.] - ETA: 0s - loss: 0.4691 - accuracy: 0.7632"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model.pt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model.pt/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f24985a2d90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "292/292 [==============================] - 19s 51ms/step - loss: 0.4688 - accuracy: 0.7634 - val_loss: 0.3483 - val_accuracy: 0.8552\n",
      "Epoch 2/100\n",
      "292/292 [==============================] - 8s 27ms/step - loss: 0.2185 - accuracy: 0.9180 - val_loss: 0.3571 - val_accuracy: 0.8531\n",
      "Epoch 3/100\n",
      "292/292 [==============================] - 8s 28ms/step - loss: 0.1158 - accuracy: 0.9615 - val_loss: 0.3762 - val_accuracy: 0.8441\n",
      "Epoch 4/100\n",
      "292/292 [==============================] - 8s 27ms/step - loss: 0.0672 - accuracy: 0.9779 - val_loss: 0.5211 - val_accuracy: 0.8372\n",
      "Epoch 5/100\n",
      "292/292 [==============================] - 8s 28ms/step - loss: 0.0407 - accuracy: 0.9881 - val_loss: 0.6301 - val_accuracy: 0.8388\n",
      "Epoch 6/100\n",
      "292/292 [==============================] - 8s 28ms/step - loss: 0.0259 - accuracy: 0.9923 - val_loss: 0.6825 - val_accuracy: 0.8343\n",
      "Epoch 7/100\n",
      "292/292 [==============================] - 8s 27ms/step - loss: 0.0282 - accuracy: 0.9913 - val_loss: 0.5846 - val_accuracy: 0.8148\n",
      "Epoch 8/100\n",
      "292/292 [==============================] - 8s 27ms/step - loss: 0.0202 - accuracy: 0.9941 - val_loss: 0.8406 - val_accuracy: 0.8295\n",
      "Epoch 9/100\n",
      "292/292 [==============================] - 8s 27ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.8198 - val_accuracy: 0.8295\n",
      "Epoch 10/100\n",
      "292/292 [==============================] - 8s 27ms/step - loss: 0.0080 - accuracy: 0.9981 - val_loss: 1.0081 - val_accuracy: 0.8292\n",
      "Epoch 11/100\n",
      "292/292 [==============================] - 8s 28ms/step - loss: 0.0140 - accuracy: 0.9961 - val_loss: 1.0386 - val_accuracy: 0.8232\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(train_X_pad, trainY, epochs=100, callbacks = callbacks,\n",
    "          validation_data=(test_X_pad, testY), batch_size=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dMD3h0y-myD3",
    "outputId": "593102f7-2c4b-4351-8f12-871a1eaaaab6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17500, 100)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ESXICaEum2Dn",
    "outputId": "1d19b6d0-df99-4f94-fb9d-10418b77ad66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17500,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bE-UPJgdm6e2",
    "outputId": "7d12a93f-4387-4492-ff30-b77efb2f40dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 100, 20)           1293520   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 50)                14200     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,307,771\n",
      "Trainable params: 1,307,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_POFXyl7YAjx",
    "outputId": "df7c47ef-1520-4d3b-c2f2-8f0f8a32e594"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.78      0.82      3800\n",
      "           1       0.79      0.87      0.83      3700\n",
      "\n",
      "    accuracy                           0.82      7500\n",
      "   macro avg       0.83      0.82      0.82      7500\n",
      "weighted avg       0.83      0.82      0.82      7500\n",
      "\n",
      "[[2951  849]\n",
      " [ 477 3223]]\n",
      "Accuracy: 0.8232\n"
     ]
    }
   ],
   "source": [
    "pred_test_lstm = model.predict(test_X_pad)\n",
    "#pred_test = np.argmax(pred_test,axis=1)\n",
    "pred_test_lstm = pred_test_lstm.round()\n",
    "\n",
    "#print evaluation metrics \n",
    "print(classification_report(testY,pred_test_lstm))\n",
    "print(confusion_matrix(testY,pred_test_lstm))\n",
    "print(\"Accuracy:\",accuracy_score(testY, pred_test_lstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "gX5V9D0L8xP-"
   },
   "outputs": [],
   "source": [
    "acc_lstm_50 = accuracy_score(testY, pred_test_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L1ZtAJb-ZaFG",
    "outputId": "ff68a377-10c0-4bd3-b193-62a76d705c1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 100, 50)           3233800   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 20)                5680      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,239,501\n",
      "Trainable params: 3,239,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "292/292 [==============================] - 11s 22ms/step - loss: 0.4583 - accuracy: 0.7825\n",
      "Epoch 2/10\n",
      "292/292 [==============================] - 6s 22ms/step - loss: 0.2018 - accuracy: 0.9266\n",
      "Epoch 3/10\n",
      "292/292 [==============================] - 6s 22ms/step - loss: 0.0939 - accuracy: 0.9698\n",
      "Epoch 4/10\n",
      "292/292 [==============================] - 6s 22ms/step - loss: 0.0474 - accuracy: 0.9859\n",
      "Epoch 5/10\n",
      "292/292 [==============================] - 6s 22ms/step - loss: 0.0278 - accuracy: 0.9925\n",
      "Epoch 6/10\n",
      "292/292 [==============================] - 6s 22ms/step - loss: 0.0274 - accuracy: 0.9913\n",
      "Epoch 7/10\n",
      "292/292 [==============================] - 6s 22ms/step - loss: 0.0225 - accuracy: 0.9933\n",
      "Epoch 8/10\n",
      "292/292 [==============================] - 6s 22ms/step - loss: 0.0194 - accuracy: 0.9945\n",
      "Epoch 9/10\n",
      "292/292 [==============================] - 6s 22ms/step - loss: 0.0183 - accuracy: 0.9943\n",
      "Epoch 10/10\n",
      "292/292 [==============================] - 6s 22ms/step - loss: 0.0089 - accuracy: 0.9981\n"
     ]
    }
   ],
   "source": [
    "model_2 = generate_model(vocab_size,max_len,embedding_size=50, lstm_size=20)\n",
    "model_2.summary()\n",
    "\n",
    "history = model_2.fit(train_X_pad, trainY, epochs=10, batch_size=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q3QVuPGgZi2Q",
    "outputId": "a1f95778-2adc-4288-a57d-30656d534879"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83      3800\n",
      "           1       0.83      0.82      0.83      3700\n",
      "\n",
      "    accuracy                           0.83      7500\n",
      "   macro avg       0.83      0.83      0.83      7500\n",
      "weighted avg       0.83      0.83      0.83      7500\n",
      "\n",
      "[[3194  606]\n",
      " [ 668 3032]]\n",
      "Accuracy: 0.8301333333333333\n"
     ]
    }
   ],
   "source": [
    "pred_test_2 = model_2.predict(test_X_pad)\n",
    "#pred_test = np.argmax(pred_test,axis=1)\n",
    "pred_test_2 = pred_test_2.round()\n",
    "\n",
    "#print evaluation metrics \n",
    "print(classification_report(testY,pred_test_2))\n",
    "print(confusion_matrix(testY,pred_test_2))\n",
    "print(\"Accuracy:\",accuracy_score(testY, pred_test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "rZ96gyqV9BBO"
   },
   "outputs": [],
   "source": [
    "acc_lstm_20 = accuracy_score(testY, pred_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGPd-uvn_GKG"
   },
   "source": [
    "## Create a report/table for the experimental results. \n",
    "\n",
    "  - The table should contain accuracy, f1-score, precision and recall for each of the 6 models (2 count vectorizer,2 Tf_IDF and 2 Embedings)\n",
    "  - Write few sentences about which model performed the best in your opinion (and why)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "-vHlEORjbLTg",
    "outputId": "07f5541b-5cc1-4b60-e7ce-4cec563809bb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-b61826a7-02a4-4336-a053-15dc5cd99fb7\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>f-1 score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_model</td>\n",
       "      <td>0.823200</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_ff</td>\n",
       "      <td>0.861467</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lr_model_tf</td>\n",
       "      <td>0.866533</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model</td>\n",
       "      <td>0.823200</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model_2</td>\n",
       "      <td>0.830133</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b61826a7-02a4-4336-a053-15dc5cd99fb7')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-b61826a7-02a4-4336-a053-15dc5cd99fb7 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-b61826a7-02a4-4336-a053-15dc5cd99fb7');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "         Model  Accuracy  f-1 score  Precision  Recall\n",
       "0     lr_model  0.823200       0.85       0.85    0.85\n",
       "1     model_ff  0.861467       0.86       0.86    0.86\n",
       "2  lr_model_tf  0.866533       0.87       0.87    0.87\n",
       "3        model  0.823200       0.82       0.83    0.82\n",
       "4      model_2  0.830133       0.83       0.83    0.83"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = {'Model': ['lr_model', 'model_ff', 'lr_model_tf','model','model_2'],\n",
    "        'Accuracy': [acc_lr_model, acc_model_ff, acc_tf, acc_lstm_50, acc_lstm_20],\n",
    "        'f-1 score': [0.85, 0.86, 0.87, 0.82, 0.83],\n",
    "        'Precision': [0.85, 0.86, 0.87, 0.83, 0.83],\n",
    "        'Recall': [0.85, 0.86, 0.87, 0.82, 0.83]\n",
    "         }\n",
    "df = pd.DataFrame(data=r)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-7I4bSdACpR"
   },
   "source": [
    "According to the given results, TfidfVectorizer (model - Logistic regression) apperas to be the best model. I expected that the wordembedding models will give better results because of the way the word embedding vectors are made. The Feed Forward model for CountVectorizer is also very precise so I guess I would try these two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OuhjoIRuAVbi"
   },
   "source": [
    "## Use the model on unseen data\n",
    "\n",
    "  - Find 3 english reviews (for which it is clear whether they are Good or Bad) from your favourite movie on IMDB\n",
    "  - Use the best model to classify them"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": " Workshop_11_IMDB_Katerina_Dimevska.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
