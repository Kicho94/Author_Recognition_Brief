{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Our goal is to create an NLP classifier that when given a paragraph from a famous classical book will be able to predict the text's author."
      ],
      "metadata": {
        "id": "eJao1Rrq4HNK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tDTLQBNuSbxU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the feature set and label set"
      ],
      "metadata": {
        "id": "UZG9TGZr9DlF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cPF1fCYNs-lK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "918dcb5e-ea0c-4936-a165-278bcfcd6b20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      Pretty soon I wanted to smoke, and asked the w...\n",
              "1      Her sister, Miss Watson, a tolerable slim old ...\n",
              "2      Now she had got a start, and she went on and t...\n",
              "3      Miss Watson she kept pecking at me, and it got...\n",
              "4      I set down again, a-shaking all over, and got ...\n",
              "                             ...                        \n",
              "994    I was on the point of asking him what that wor...\n",
              "995      1. Knowledge of Literature.--Nil.\\r\\n  2.   ...\n",
              "996    I see that I have alluded above to his powers ...\n",
              "997    During the first week or so we had no callers,...\n",
              "998    It was upon the 4th of March, as I have good r...\n",
              "Name: v2, Length: 999, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "path_to_text = 'books_and_authors'\n",
        "data = pd.read_csv(path_to_text, names=['v1', 'v2'])\n",
        "\n",
        "label = data['v1']\n",
        "text = data['v2']\n",
        "\n",
        "text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text preprocessing using NLTK"
      ],
      "metadata": {
        "id": "-HM5b5MXpjwu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kQMEPwLuVos_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd8d0c86-8760-4c0d-fbb8-4bd40ee6464b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stopwords_ = stopwords.words('english')\n",
        "\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "wnl = WordNetLemmatizer()\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "import string"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll try two different datasets. The first (text_preprocessed) will be fully preprocessed (low letters, missing punctuation, words represented like tokens and then lemmatization. The second dataset (text_preprocessed_1) will only have low letters and will be tokenized."
      ],
      "metadata": {
        "id": "3msY8Crf2vm5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#First dataset - fully preprocessed"
      ],
      "metadata": {
        "id": "PyfDsCg15M20"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "G4TuGNFyVFld"
      },
      "outputs": [],
      "source": [
        "text_preprocessed = []\n",
        "for sentence in text:\n",
        "    #sentence lower\n",
        "    sentence = sentence.lower()\n",
        "\n",
        "    #string punct\n",
        "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
        "    #tokenize\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    \n",
        "    # stop-words\n",
        "    tokens_stop_words = []\n",
        "    \n",
        "    for token in tokens:\n",
        "          if token not in stopwords_:\n",
        "                tokens_stop_words.append(token)\n",
        "                \n",
        "    # Lemmatization\n",
        "    tokens_lemma = []\n",
        "    for token in tokens_stop_words:\n",
        "          tokens_lemma.append(wnl.lemmatize(token, get_wordnet_pos(nltk.pos_tag([token])[0][1])))\n",
        "            \n",
        "    final = ' '.join(tokens_lemma)\n",
        "    \n",
        "    text_preprocessed.append(final)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCSyKfMSXUV-"
      },
      "source": [
        "#Second dataset with lower letters and tokenisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "S1lVUTtWS2sW"
      },
      "outputs": [],
      "source": [
        "text_preprocessed_1 = []\n",
        "for sentence in text:\n",
        "    #sentence lower\n",
        "    sentence = sentence.lower()\n",
        "    #tokenize\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    \n",
        "    text_preprocessed_1.append(' '.join(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ToIgCuOZtlb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c63193d-75c4-48f4-b5bc-9d5c63d1d1f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(999, 999, 999)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "len(text_preprocessed_1),len(text_preprocessed), len(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yf-0K8WSt-Vq"
      },
      "source": [
        "### Extracting Text and Train Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qV50_5d7t9Pe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26a8d177-831c-4474-a5f8-850ddffae1e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(699, 300, 699, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "trainX, testX, trainY, testY = train_test_split(\n",
        "    text_preprocessed, label, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "len(trainX), len(testX), len(trainY), len(testY)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label encoding"
      ],
      "metadata": {
        "id": "rsBvpyLw5oAn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qRaf0P1JuHBa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77b3ad31-c8fc-4e54-fa41-a5120899fad4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "trainY= le.fit_transform(trainY)\n",
        "testY = le.fit_transform(testY)\n",
        "trainY.shape,testY.shape\n",
        "trainY[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ROCu1wnCpXiQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "244d3a63-3daa-452c-aed8-8797ac5a414d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2, 3, 4, 5, 6]), array([ 68, 104,  89, 167,  74, 108,  89]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "np.unique(trainY, return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DlRHzeJspXiR"
      },
      "outputs": [],
      "source": [
        "#trainY"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we'll use CountVectorizer to process the data and to show us the number of apperances of each token (word)."
      ],
      "metadata": {
        "id": "7Oryyg39-MTA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "g8Y0uHPguNI1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84cd9426-38b3-447f-91fb-0b2d8d86e963"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 5000)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Count Vectors as features\n",
        "# create a count vectorizer object \n",
        "count_vect = CountVectorizer(analyzer='word', ngram_range=(1, 1), max_features=5000)\n",
        "count_vect.fit(text_preprocessed)\n",
        "\n",
        "# transform the training and test data using count vectorizer object\n",
        "trainX_vec = count_vect.transform(trainX)\n",
        "testX_vec = count_vect.transform(testX)\n",
        "trainX_vec.shape,\n",
        "testX_vec.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_ = count_vect.vocabulary_\n",
        "new_data = pd.DataFrame.from_dict(dict_, orient='index')"
      ],
      "metadata": {
        "id": "p1GrRQdJOkzm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "pEmOBj94Ru9Z",
        "outputId": "29de336e-b63b-461e-a675-42dfe04cf348"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               0\n",
              "pretty      3526\n",
              "soon        4202\n",
              "want        4817\n",
              "smoke       4162\n",
              "ask          274\n",
              "...          ...\n",
              "moorgate    2852\n",
              "coroner      970\n",
              "stamford    4269\n",
              "laboratory  2404\n",
              "test        4486\n",
              "\n",
              "[5000 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-93283160-1a76-4578-a0dc-97f465ea8a86\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pretty</th>\n",
              "      <td>3526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>soon</th>\n",
              "      <td>4202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>want</th>\n",
              "      <td>4817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smoke</th>\n",
              "      <td>4162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ask</th>\n",
              "      <td>274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>moorgate</th>\n",
              "      <td>2852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>coroner</th>\n",
              "      <td>970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stamford</th>\n",
              "      <td>4269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>laboratory</th>\n",
              "      <td>2404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>4486</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93283160-1a76-4578-a0dc-97f465ea8a86')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-93283160-1a76-4578-a0dc-97f465ea8a86 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-93283160-1a76-4578-a0dc-97f465ea8a86');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "_Oliij53Q1JJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('count_vect: ')\n",
        "print(count_vect.vocabulary_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swaPnzjz_ioq",
        "outputId": "1672ff47-3580-48af-c811-7a803e72d629"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count_vect: \n",
            "{'pretty': 3526, 'soon': 4202, 'want': 4817, 'smoke': 4162, 'ask': 274, 'widow': 4897, 'let': 2488, 'wouldnt': 4959, 'say': 3936, 'mean': 2706, 'practice': 3475, 'wasnt': 4826, 'clean': 721, 'must': 2914, 'try': 4668, 'way': 4833, 'people': 3281, 'get': 1888, 'thing': 4512, 'dont': 1371, 'know': 2399, 'nothing': 3031, 'moses': 2865, 'kin': 2377, 'use': 4745, 'anybody': 200, 'go': 1916, 'see': 3983, 'yet': 4988, 'find': 1727, 'power': 3472, 'fault': 1685, 'good': 1923, 'take': 4442, 'course': 1002, 'right': 3846, 'do': 1351, 'sister': 4116, 'miss': 2807, 'watson': 4831, 'tolerable': 4570, 'slim': 4151, 'old': 3096, 'maid': 2621, 'come': 788, 'live': 2542, 'set': 4017, 'work': 4948, 'middle': 2765, 'hard': 2022, 'hour': 2142, 'make': 2629, 'ease': 1466, 'couldnt': 986, 'stood': 4310, 'much': 2887, 'longer': 2563, 'deadly': 1118, 'dull': 1440, 'would': 4958, 'put': 3646, 'foot': 1777, 'like': 2515, 'straight': 4318, 'gap': 1860, 'stretch': 4330, 'behave': 393, 'told': 4569, 'bad': 339, 'place': 3374, 'wish': 4922, 'mad': 2611, 'didnt': 1245, 'harm': 2026, 'somewhere': 4198, 'change': 656, 'warnt': 4822, 'particular': 3232, 'wicked': 4892, 'whole': 4887, 'world': 4949, 'well': 4853, 'advantage': 78, 'mind': 2786, 'never': 2980, 'trouble': 4658, 'start': 4276, 'body': 477, 'around': 256, 'day': 1112, 'long': 2562, 'sing': 4108, 'forever': 1789, 'ever': 1575, 'think': 4514, 'reckon': 3735, 'tom': 4571, 'sawyer': 3935, 'considerable': 896, 'sight': 4088, 'glad': 1899, 'together': 4566, 'kept': 2368, 'peck': 3268, 'tiresome': 4559, 'lonesome': 2561, 'fetch': 1712, 'nigger': 2993, 'prayer': 3481, 'everybody': 1577, 'bed': 383, 'room': 3874, 'piece': 3346, 'candle': 594, 'table': 4439, 'chair': 652, 'window': 4911, 'something': 4195, 'cheerful': 674, 'felt': 1705, 'dead': 1117, 'star': 4274, 'shin': 4052, 'leaf': 2464, 'rustle': 3893, 'wood': 4940, 'mournful': 2880, 'heard': 2051, 'owl': 3168, 'away': 326, 'somebody': 4193, 'dog': 1361, 'cry': 1049, 'die': 1246, 'wind': 4910, 'whisper': 4880, 'cold': 771, 'shiver': 4056, 'run': 3891, 'kind': 2378, 'sound': 4212, 'ghost': 1890, 'tell': 4463, 'cant': 596, 'understood': 4710, 'rest': 3820, 'easy': 1470, 'grave': 1953, 'every': 1576, 'night': 2995, 'grieve': 1970, 'scar': 3942, 'company': 817, 'spider': 4240, 'crawl': 1020, 'shoulder': 4066, 'lit': 2537, 'could': 984, 'need': 2963, 'awful': 328, 'sign': 4089, 'luck': 2592, 'shook': 4060, 'clothes': 745, 'turn': 4680, 'track': 4606, 'three': 4528, 'time': 4551, 'cross': 1041, 'breast': 518, 'tie': 4546, 'little': 2541, 'lock': 2550, 'hair': 2003, 'thread': 4526, 'keep': 2364, 'witch': 4925, 'hadnt': 2001, 'confidence': 867, 'lose': 2574, 'horseshoe': 2135, 'found': 1808, 'instead': 2270, 'nail': 2927, 'door': 1373, 'kill': 2376, 'pipe': 3366, 'house': 2143, 'still': 4301, 'death': 1126, 'clock': 735, 'town': 4603, 'lick': 2499, 'twig': 4686, 'snap': 4166, 'dark': 1092, 'amongst': 161, 'stir': 4304, 'listen': 2535, 'directly': 1276, 'barely': 354, 'hear': 2050, 'meyow': 2762, 'soft': 4179, 'light': 2509, 'scramble': 3962, 'shed': 4039, 'slip': 4153, 'ground': 1980, 'among': 160, 'tree': 4638, 'sure': 4401, 'enough': 1541, 'wait': 4811, 'along': 140, 'path': 3252, 'back': 336, 'towards': 4600, 'end': 1526, 'garden': 1862, 'stoop': 4312, 'branch': 508, 'head': 2046, 'passing': 3243, 'kitchen': 2388, 'fell': 1700, 'root': 3875, 'noise': 3009, 'laid': 2416, 'big': 430, 'name': 2931, 'jim': 2332, 'clear': 723, 'behind': 396, 'neck': 2961, 'minute': 2794, 'touch': 4595, 'nearly': 2954, 'likely': 2516, 'close': 738, 'ankle': 180, 'itch': 2321, 'dasnt': 1103, 'scratch': 3964, 'ear': 1457, 'begin': 392, 'next': 2987, 'seem': 3986, 'id': 2172, 'notice': 3032, 'plenty': 3400, 'since': 4106, 'quality': 3650, 'funeral': 1849, 'sleep': 4139, 'aint': 114, 'wont': 4939, 'upwards': 4742, 'thousand': 4525, 'lean': 2466, 'leg': 2477, 'till': 4549, 'one': 3105, 'mine': 2787, 'nose': 3025, 'tear': 4461, 'eye': 1641, 'inside': 2264, 'six': 4123, 'seven': 4019, 'eleven': 1502, 'different': 1249, 'stand': 4271, 'teeth': 4462, 'ready': 3718, 'breathe': 520, 'heavy': 2061, 'comfortable': 792, 'creep': 1027, 'hand': 2012, 'knee': 2389, 'ten': 4470, 'fun': 1847, 'might': 2772, 'wake': 4812, 'disturbance': 1341, 'slid': 4146, 'five': 1743, 'cent': 643, 'pay': 3264, 'sweat': 4422, 'play': 3386, 'everything': 1580, 'cut': 1075, 'fence': 1708, 'steep': 4294, 'top': 4581, 'hill': 2093, 'side': 4086, 'hat': 2038, 'hung': 2161, 'limb': 2520, 'afterwards': 97, 'trance': 4618, 'rode': 3868, 'state': 4279, 'show': 4069, 'new': 2982, 'spread': 4253, 'tire': 4557, 'proud': 3602, 'hardly': 2024, 'mile': 2777, 'look': 2566, 'country': 997, 'strange': 4321, 'mouth': 2881, 'open': 3108, 'wonder': 4936, 'always': 152, 'talk': 4445, 'fire': 1731, 'whenever': 4867, 'happen': 2018, 'bout': 500, 'seat': 3974, 'round': 3880, 'string': 4334, 'charm': 666, 'devil': 1232, 'give': 1898, 'cure': 1061, 'anything': 202, 'ruin': 3889, 'servant': 4014, 'stuck': 4344, 'account': 42, 'edge': 1481, 'village': 4786, 'four': 1809, 'twinkle': 4688, 'sick': 4082, 'folk': 1770, 'maybe': 2699, 'sparkle': 4224, 'fine': 1728, 'river': 3856, 'broad': 536, 'grand': 1942, 'jo': 2333, 'harper': 2029, 'ben': 405, 'rogers': 3869, 'two': 4690, 'boy': 503, 'hid': 2085, 'skiff': 4130, 'pull': 3620, 'half': 2005, 'ashore': 272, 'clump': 750, 'swear': 4421, 'secret': 3977, 'hole': 2111, 'part': 3230, 'hundred': 2160, 'yard': 4977, 'cave': 638, 'poked': 3421, 'passage': 3241, 'wall': 4814, 'narrow': 2937, 'damp': 1082, 'stop': 4313, 'willing': 4904, 'sheet': 4041, 'paper': 3209, 'write': 4969, 'oath': 3052, 'read': 3713, 'swore': 4431, 'stick': 4297, 'band': 347, 'order': 3126, 'person': 3307, 'family': 1662, 'mustnt': 2916, 'eat': 1471, 'nobody': 3007, 'belong': 401, 'mark': 2663, 'throat': 4532, 'burnt': 563, 'ash': 270, 'scatter': 3945, 'blot': 466, 'list': 2534, 'blood': 462, 'mention': 2739, 'curse': 1068, 'forgot': 1793, 'rule': 3890, 'else': 1506, 'fair': 1655, 'square': 4257, 'others': 3141, 'stump': 4349, 'thought': 4524, 'offer': 3086, 'morning': 2859, 'scold': 3958, 'grease': 1956, 'clay': 720, 'sorry': 4208, 'awhile': 329, 'closet': 741, 'prayed': 3480, 'pray': 3479, 'whatever': 4862, 'hook': 2123, 'without': 4931, 'somehow': 4194, 'fool': 1775, 'deacon': 1116, 'money': 2837, 'pork': 3443, 'silver': 4097, 'snuffbox': 4171, 'stole': 4307, 'fat': 1680, 'self': 3990, 'spiritual': 4242, 'gift': 1893, 'many': 2655, 'help': 2075, 'include': 2221, 'last': 2443, 'sometimes': 4196, 'providence': 3606, 'water': 4830, 'hold': 2110, 'knock': 2397, 'judged': 2346, 'poor': 3437, 'chap': 658, 'though': 4523, 'agoing': 103, 'ignorant': 2183, 'pap': 3208, 'year': 4980, 'whale': 4860, 'sober': 4176, 'drownded': 1427, 'twelve': 4682, 'anyway': 203, 'man': 2637, 'size': 4128, 'rag': 3676, 'uncommon': 4702, 'face': 1646, 'float': 1756, 'bury': 566, 'bank': 349, 'mighty': 2774, 'woman': 4935, 'dress': 1412, 'uncomfortable': 4701, 'played': 3387, 'robber': 3864, 'month': 2846, 'resign': 3811, 'robbed': 3863, 'pretend': 3524, 'hop': 2124, 'charge': 662, 'cart': 621, 'stuff': 4347, 'market': 2665, 'call': 589, 'hog': 2108, 'marked': 2664, 'profit': 3570, 'sent': 4002, 'blazing': 455, 'news': 2985, 'parcel': 3214, 'spanish': 4220, 'merchant': 2740, 'rich': 3838, 'arab': 228, 'camp': 592, 'hollow': 2114, 'elephant': 1500, 'camel': 591, 'load': 2546, 'dimonds': 1263, 'guard': 1987, 'soldier': 4184, 'lay': 2459, 'lot': 2577, 'scoop': 3959, 'slick': 4145, 'sword': 4430, 'gun': 1995, 'even': 1572, 'rot': 3877, 'worth': 4956, 'mouthful': 2882, 'believe': 399, 'crowd': 1043, 'saturday': 3929, 'word': 4945, 'rush': 3892, 'sundayschool': 4387, 'bust': 568, 'chase': 667, 'child': 684, 'doll': 1364, 'hymnbook': 2171, 'teacher': 4460, 'drop': 1424, 'book': 483, 'enchantment': 1521, 'treasure': 4634, 'enemy': 1530, 'magician': 2618, 'spite': 4243, 'whoever': 4886, 'rub': 3885, 'lamp': 2423, 'ring': 3850, 'theyve': 4508, 'build': 552, 'palace': 3189, 'forty': 1804, 'fill': 1724, 'full': 1845, 'daughter': 1105, 'china': 692, 'marry': 2671, 'wherever': 4871, 'understand': 4709, 'tin': 4553, 'iron': 2309, 'rubbed': 3886, 'calculate': 587, 'sell': 3992, 'none': 3015, 'lie': 2501, 'first': 1735, 'school': 3952, 'hiding': 2089, 'cheer': 673, 'sort': 4209, 'living': 2545, 'tight': 4547, 'mostly': 2867, 'weather': 4842, 'slide': 4147, 'best': 419, 'bit': 439, 'slow': 4154, 'satisfactory': 3926, 'ashamed': 271, 'breakfast': 517, 'reach': 3712, 'quick': 3659, 'throw': 4535, 'left': 2475, 'ahead': 110, 'mess': 2750, 'feel': 1698, 'worried': 4954, 'fall': 1659, 'front': 1840, 'clumb': 749, 'stile': 4300, 'high': 2090, 'board': 474, 'inch': 2217, 'snow': 4170, 'quarry': 3653, 'curious': 1063, 'follow': 1771, 'hairball': 2004, 'fist': 1738, 'fourth': 1810, 'stomach': 4308, 'ox': 3171, 'spirit': 4241, 'stay': 4284, 'held': 2073, 'floor': 1758, 'solid': 4189, 'roll': 3870, 'another': 188, 'act': 53, 'counterfeit': 993, 'quarter': 3654, 'brass': 512, 'pas': 3237, 'greasy': 1957, 'dollar': 1365, 'judge': 2345, 'difference': 1248, 'manage': 2638, 'split': 4246, 'raw': 3711, 'potato': 3464, 'alone': 139, 'yo': 4991, 'ole': 3099, 'father': 1683, 'he': 2045, 'hell': 2074, 'en': 1518, 'den': 1185, 'agin': 100, 'de': 1115, 'deys': 1238, 'angel': 173, 'em': 1507, 'white': 4882, 'tother': 4594, 'black': 444, 'git': 1897, 'sail': 3905, 'gwyne': 1996, 'la': 2402, 'considable': 894, 'life': 2502, 'joy': 2343, 'hurt': 2168, 'yous': 4996, 'po': 3407, 'bill': 431, 'shut': 4079, 'may': 2698, 'breath': 519, 'unexpected': 4714, 'fifty': 1720, 'tangle': 4449, 'gray': 1955, 'whisker': 4878, 'color': 781, 'flesh': 1753, 'boot': 484, 'toe': 4565, 'lid': 2500, 'ill': 2184, 'learn': 2468, 'meddle': 2715, 'looky': 2567, 'bring': 533, 'air': 115, 'lem': 2481, 'catch': 632, 'mother': 2869, 'nuther': 3047, 'whisky': 4879, 'drink': 1416, 'cuss': 1071, 'law': 2456, 'court': 1003, 'guardian': 1988, 'interfere': 2285, 'separate': 4005, 'hed': 2063, 'thatcher': 4494, 'quit': 3666, 'business': 567, 'pleased': 3397, 'cowhide': 1012, 'blue': 470, 'raise': 3683, 'borrow': 490, 'drunk': 1428, 'carry': 620, 'pan': 3201, 'midnight': 2769, 'jail': 2323, 'week': 4847, 'satisfied': 3927, 'bos': 491, 'son': 4199, 'warm': 4819, 'nice': 2989, 'dinner': 1269, 'supper': 4397, 'pie': 3345, 'speak': 4225, 'hug': 2151, 'wife': 4899, 'sympathy': 4436, 'rise': 3852, 'kiss': 2387, 'record': 3741, 'tucked': 4671, 'beautiful': 379, 'spare': 4222, 'powerful': 3473, 'trade': 4607, 'coat': 764, 'jug': 2349, 'daylight': 1113, 'porch': 3442, 'broke': 537, 'arm': 248, 'couple': 1000, 'dodge': 1357, 'trial': 4644, 'line': 2526, 'hang': 2017, 'watch': 4829, 'spring': 4254, 'shore': 4062, 'log': 2554, 'hut': 2170, 'thick': 4509, 'chance': 655, 'cabin': 579, 'key': 2371, 'fish': 1736, 'hunt': 2164, 'store': 4314, 'game': 1859, 'home': 2117, 'drove': 1425, 'lazy': 2460, 'smoking': 4163, 'fishing': 1737, 'study': 4346, 'dirt': 1277, 'wash': 4825, 'plate': 3384, 'comb': 785, 'regular': 3762, 'bother': 493, 'objection': 3054, 'handy': 2016, 'dreadful': 1407, 'fix': 1744, 'leave': 2472, 'oak': 3048, 'careful': 613, 'knife': 2393, 'rusty': 3894, 'handle': 2014, 'rafter': 3675, 'roof': 3873, 'far': 1668, 'blowing': 468, 'chink': 693, 'blanket': 450, 'saw': 3934, 'bottom': 495, 'job': 2334, 'rid': 3842, 'natural': 2945, 'wrong': 4974, 'lawyer': 2458, 'win': 4909, 'lawsuit': 2457, 'allow': 136, 'guess': 1990, 'skip': 4132, 'general': 1872, 'uneasy': 4713, 'sack': 3895, 'corn': 968, 'meal': 2705, 'ammunition': 159, 'newspaper': 2986, 'besides': 417, 'bow': 501, 'walk': 4813, 'tramp': 4617, 'across': 52, 'alive': 130, 'holler': 2113, 'whether': 4872, 'asleep': 276, 'cooking': 958, 'mud': 2889, 'liquor': 2532, 'govment': 1932, 'here': 2081, 'anxiety': 196, 'expense': 1620, 'yes': 4986, 'property': 3586, 'trap': 4626, 'notion': 3033, 'blame': 448, 'chin': 691, 'shove': 4068, 'wealthy': 4837, 'men': 2733, 'oh': 3094, 'wonderful': 4937, 'free': 1821, 'mulatter': 2896, 'shirt': 4055, 'gold': 1920, 'chain': 651, 'college': 776, 'language': 2434, 'vote': 4803, 'cool': 960, 'road': 3858, 'specimen': 4230, 'heel': 2066, 'tub': 4669, 'salt': 3915, 'bark': 355, 'speech': 4234, 'sudden': 4366, 'rattle': 3708, 'kick': 2374, 'judgment': 2348, 'howl': 2148, 'fairly': 1656, 'previous': 3529, 'pile': 3351, 'blind': 461, 'steal': 4288, 'drank': 1398, 'tumble': 4676, 'groan': 1976, 'moan': 2817, 'sleepy': 4140, 'burning': 562, 'scream': 3965, 'wild': 4901, 'yell': 4983, 'snake': 4165, 'jump': 2350, 'biting': 441, 'pant': 3206, 'fast': 1678, 'strike': 4333, 'grab': 1934, 'wore': 4947, 'wolf': 4933, 'terrible': 4481, 'corner': 969, 'low': 2587, 'jumped': 2351, 'beg': 391, 'laugh': 2450, 'roar': 3860, 'short': 4063, 'jacket': 2322, 'lightning': 2514, 'save': 3932, 'strong': 4339, 'doze': 1389, 'barrel': 358, 'point': 3418, 'drag': 1393, 'within': 4930, 'less': 2486, 'forgotten': 1794, 'bitter': 442, 'interest': 2283, 'bore': 487, 'just': 2353, 'misfortune': 2805, 'excitement': 1607, 'value': 4760, 'novelty': 3036, 'whistle': 4881, 'acquire': 51, 'negro': 2968, 'suffer': 4368, 'practise': 3476, 'consist': 900, 'peculiar': 3269, 'liquid': 2531, 'produce': 3564, 'tongue': 4576, 'interval': 2289, 'midst': 2770, 'music': 2907, 'the': 4495, 'reader': 3714, 'probably': 3553, 'attention': 305, 'strode': 4336, 'street': 4328, 'harmony': 2027, 'soul': 4211, 'gratitude': 1952, 'discover': 1295, 'planet': 3380, 'no': 3003, 'doubt': 1381, 'deep': 1146, 'pleasure': 3398, 'concerned': 851, 'summer': 4383, 'presently': 3515, 'checked': 671, 'stranger': 4323, 'him': 2094, 'shade': 4026, 'large': 2439, 'newcomer': 2983, 'age': 98, 'either': 1491, 'sex': 4024, 'curiosity': 1062, 'shabby': 4025, 'st': 4261, 'petersburg': 3318, 'too': 4578, 'weekday': 4848, 'simply': 4103, 'astound': 292, 'cap': 598, 'dainty': 1078, 'cloth': 743, 'shoe': 4058, 'on': 3104, 'and': 171, 'friday': 1831, 'bright': 530, 'ribbon': 3837, 'ate': 295, 'splendid': 4245, 'marvel': 2675, 'outfit': 3147, 'grow': 1983, 'neither': 2973, 'spoke': 4248, 'move': 2883, 'but': 570, 'circle': 707, 'finally': 1726, 'copper': 962, 'pocket': 3408, 'struck': 4342, 'instant': 2268, 'gripped': 1975, 'cat': 630, 'space': 4219, 'tug': 4674, 'tore': 4586, 'cover': 1008, 'dust': 1447, 'glory': 1912, 'confusion': 876, 'form': 1795, 'fog': 1768, 'battle': 368, 'appear': 212, 'pound': 3468, 'brushing': 548, 'sob': 4175, 'occasionally': 3069, 'shake': 4028, 'threaten': 4527, 'caught': 635, 'respond': 3818, 'feather': 1692, 'snatch': 4168, 'stone': 4309, 'threw': 4530, 'hit': 2103, 'tail': 4441, 'ran': 3689, 'traitor': 4616, 'thus': 4541, 'position': 3451, 'gate': 1866, 'dare': 1090, 'outside': 3151, 'decline': 1142, 'vulgar': 4806, 'fresh': 1828, 'song': 4200, 'heart': 2054, 'young': 4995, 'issue': 2318, 'lip': 2530, 'step': 4296, 'bloom': 464, 'fragrance': 1813, 'beyond': 424, 'green': 1966, 'land': 2425, 'dreamy': 1410, 'invite': 2304, 'bucket': 551, 'whitewash': 4883, 'brush': 547, 'survey': 4411, 'gladness': 1900, 'melancholy': 2722, 'settle': 4018, 'upon': 4734, 'thirty': 4517, 'nine': 2999, 'existence': 1617, 'burden': 559, 'sigh': 4087, 'dipped': 1273, 'pass': 3240, 'topmost': 4584, 'repeat': 3792, 'operation': 3112, 'compare': 819, 'streak': 4326, 'continent': 928, 'sat': 3924, 'discourage': 1293, 'pail': 3182, 'pump': 3626, 'remember': 3781, 'girl': 1896, 'quarrel': 3652, 'fight': 1721, 'although': 150, 'generally': 1873, 'energy': 1532, 'plan': 3379, 'sorrow': 4207, 'trip': 4649, 'delicious': 1175, 'worldly': 4950, 'wealth': 4836, 'examine': 1594, 'it': 2319, 'toy': 4604, 'marble': 2658, 'buy': 575, 'exchange': 1605, 'pure': 3634, 'freedom': 1822, 'return': 3828, 'idea': 2173, 'hopeless': 2127, 'moment': 2832, 'burst': 564, 'great': 1958, 'magnificent': 2619, 'whose': 4890, 'dread': 1406, 'gait': 1856, 'proof': 3582, 'anticipation': 192, 'apple': 215, 'dingdongdong': 1267, 'personate': 3312, 'steamboat': 4291, 'drew': 1414, 'near': 2952, 'slacken': 4135, 'speed': 4235, 'laborious': 2406, 'circumstance': 708, 'for': 1780, 'missouri': 2809, 'consider': 895, 'draw': 1401, 'boat': 475, 'captain': 605, 'combine': 787, 'imagine': 2192, 'late': 2444, 'steamer': 4292, 'sun': 4385, 'retire': 3826, 'artist': 268, 'dangle': 1088, 'munch': 2900, 'innocent': 2259, 'lack': 2411, 'material': 2690, 'remain': 3776, 'repair': 3791, 'miller': 2782, 'bought': 497, 'rat': 3705, 'swing': 4429, 'with': 4926, 'afternoon': 95, 'cannon': 595, 'fragment': 1812, 'glass': 1903, 'human': 2156, 'action': 54, 'namely': 2933, 'covet': 1009, 'necessary': 2958, 'difficult': 1250, 'attain': 301, 'wise': 4921, 'philosopher': 3328, 'writer': 4970, 'comprehend': 838, 'consists': 901, 'oblige': 3055, 'construct': 911, 'artificial': 267, 'flower': 1762, 'perform': 3291, 'climb': 733, 'amusement': 164, 'gentleman': 1881, 'england': 1535, 'drive': 1419, 'twenty': 4684, 'daily': 1077, 'privilege': 3550, 'cost': 977, 'wage': 4807, 'service': 4016, 'present': 3512, 'aunt': 312, 'polly': 3430, 'sit': 4118, 'pleasant': 3395, 'apartment': 206, 'bedroom': 386, 'library': 2498, 'quiet': 3663, 'odor': 3081, 'murmur': 2903, 'effect': 1485, 'nod': 3008, 'lap': 2438, 'spectacle': 4232, 'propped': 3593, 'safety': 3904, 'desert': 1203, 'ago': 102, 'sid': 4085, 'lead': 2461, 'second': 3975, 'clod': 736, 'collect': 775, 'surprised': 4407, 'faculty': 1649, 'sally': 3913, 'rescue': 3804, 'personal': 3309, 'peace': 3266, 'muddy': 2890, 'alley': 135, 'safely': 3903, 'capture': 607, 'punishment': 3630, 'hasten': 2035, 'toward': 4599, 'public': 3613, 'military': 2778, 'met': 2753, 'conflict': 872, 'accord': 39, 'army': 253, 'joe': 2335, 'bosom': 492, 'friend': 1832, 'condescend': 858, 'that': 4493, 'suit': 4378, 'small': 4156, 'conduct': 860, 'field': 1714, 'deliver': 1179, 'count': 989, 'prisoner': 3545, 'term': 4479, 'agree': 105, 'appoint': 219, 'march': 2659, 'homeward': 2118, 'lovely': 2585, 'creature': 1024, 'yellow': 4984, 'plait': 3378, 'hero': 2082, 'shot': 4065, 'certain': 648, 'vanished': 4761, 'memory': 2732, 'love': 2582, 'distraction': 1335, 'regard': 3759, 'passion': 3244, 'partiality': 3231, 'confess': 864, 'proudest': 3603, 'casual': 628, 'visit': 4796, 'worship': 4955, 'absurd': 26, 'boyish': 505, 'admiration': 68, 'foolishness': 1776, 'dangerous': 1087, 'performance': 3292, 'glance': 1901, 'aside': 273, 'halt': 2009, 'heave': 2058, 'threshold': 4529, 'toss': 4591, 'pansy': 3205, 'disappear': 1282, 'direction': 1275, 'picked': 3341, 'straw': 4325, 'balance': 343, 'tilt': 4550, 'effort': 1487, 'nearer': 2953, 'bare': 353, 'only': 3106, 'button': 574, 'or': 3121, 'possibly': 3459, 'post': 3460, 'anatomy': 168, 'happy': 2021, 'finger': 1729, 'ecstasy': 1477, 'control': 944, 'silent': 4093, 'perfectly': 3290, 'mischief': 2801, 'pet': 3317, 'model': 2821, 'brimful': 532, 'exultation': 1640, 'lady': 2415, 'discharge': 1289, 'wrath': 4962, 'palm': 3194, 'conscience': 885, 'reproach': 3800, 'yearn': 4981, 'confession': 865, 'discipline': 1291, 'forbade': 1781, 'silence': 4092, 'affair': 84, 'troubled': 4659, 'exalt': 1591, 'knew': 2392, 'consciousness': 889, 'signal': 4090, 'refuse': 3758, 'recognition': 3737, 'picture': 3343, 'unto': 4731, 'bending': 408, 'forgive': 1792, 'ah': 109, 'brought': 542, 'curl': 1065, 'wet': 4859, 'sore': 4205, 'rain': 3681, 'god': 1917, 'abuse': 27, 'sufferer': 4369, 'grief': 1969, 'feeling': 1699, 'pathos': 3254, 'dream': 1409, 'swallow': 4418, 'overflow': 3160, 'wink': 4915, 'trickle': 4646, 'luxury': 2606, 'bear': 373, 'grate': 1950, 'delight': 1176, 'sacred': 3896, 'contact': 918, 'cousin': 1007, 'mary': 2677, 'dance': 1084, 'cloud': 747, 'darkness': 1096, 'sunshine': 4391, 'wander': 4816, 'accustom': 45, 'haunt': 2044, 'sought': 4210, 'desolate': 1209, 'outer': 3146, 'contemplate': 920, 'dreary': 1411, 'vastness': 4769, 'stream': 4327, 'drown': 1426, 'unconsciously': 4706, 'routine': 3882, 'nature': 2947, 'wilt': 4908, 'mightily': 2773, 'increase': 2226, 'dismal': 1306, 'pity': 3373, 'comfort': 791, 'coldly': 773, 'agony': 104, 'varied': 4764, 'depart': 1188, 'halfpast': 2006, 'adore': 74, 'unknown': 4723, 'pause': 3260, 'cast': 626, 'glow': 1913, 'curtain': 1069, 'presence': 3511, 'stealthy': 4289, 'plant': 3381, 'emotion': 1513, 'dispose': 1320, 'clasped': 716, 'out': 3144, 'shelter': 4043, 'friendly': 1833, 'wipe': 4919, 'brow': 543, 'bend': 407, 'lifeless': 2503, 'blight': 460, 'loin': 2556, 'verse': 4776, 'lesson': 2487, 'bent': 412, 'memorize': 2731, 'sermon': 4013, 'mount': 2877, 'shorter': 4064, 'vague': 4756, 'busy': 569, 'recreation': 3743, 'recite': 3734, 'tackle': 4440, 'double': 1379, 'pressure': 3519, 'prospective': 3597, 'gain': 1855, 'accomplish': 37, 'success': 4362, 'swept': 4426, 'system': 4438, 'true': 4661, 'inconceivable': 2223, 'grandeur': 1943, 'weapon': 4838, 'injury': 2254, 'mystery': 2923, 'perhaps': 3293, 'contrive': 942, 'cupboard': 1058, 'arrange': 258, 'basin': 363, 'soap': 4173, 'bench': 406, 'sleeve': 4142, 'pour': 3469, 'gently': 1883, 'enter': 1542, 'diligently': 1255, 'towel': 4601, 'remove': 3787, 'trifle': 4647, 'gathering': 1868, 'resolution': 3812, 'grope': 1978, 'honorable': 2121, 'testimony': 4487, 'drip': 1418, 'emerge': 1512, 'jaw': 2327, 'mask': 2679, 'soil': 4182, 'downward': 1388, 'backward': 338, 'brother': 541, 'distinction': 1331, 'neatly': 2956, 'wrought': 4975, 'privately': 3549, 'smooth': 4164, 'labor': 2403, 'difficulty': 1251, 'plaster': 3383, 'bitterness': 443, 'clothing': 746, 'sunday': 4386, 'years': 4982, 'they': 4507, 'neat': 2955, 'vast': 4768, 'collar': 774, 'crown': 1044, 'exceedingly': 1597, 'improve': 2210, 'fully': 1846, 'cleanliness': 722, 'forget': 1791, 'hope': 2125, 'thoroughly': 4521, 'custom': 1072, 'temper': 4465, 'exhibit': 1613, 'red': 3747, 'ticket': 4544, 'buying': 576, 'various': 4766, 'fifteen': 1719, 'church': 702, 'swarm': 4419, 'noisy': 3011, 'proceed': 3557, 'elderly': 1495, 'absorbed': 24, 'pin': 3357, 'class': 717, 'pattern': 3259, 'prompt': 3578, 'however': 2147, 'reward': 3835, 'in': 2214, 'equal': 1553, 'superintendent': 4393, 'plainly': 3377, 'bound': 499, 'bible': 427, 'pupil': 3631, 'industry': 2241, 'application': 217, 'patient': 3257, 'german': 1886, 'strain': 4320, 'mental': 2738, 'idiot': 2176, 'forth': 1800, 'occasion': 3067, 'express': 1626, 'prize': 3551, 'rare': 3701, 'successful': 4363, 'conspicuous': 903, 'spot': 4251, 'scholar': 3950, 'ambition': 154, 'often': 3091, 'possible': 3458, 'really': 3722, 'hunger': 2162, 'unquestionably': 4728, 'entire': 1545, 'due': 1436, 'pulpit': 3623, 'forefinger': 1786, 'command': 798, 'customary': 1073, 'forward': 1805, 'platform': 3385, 'sings': 4110, 'concert': 852, 'refer': 3753, 'sandy': 3919, 'stiff': 4298, 'upper': 4735, 'almost': 138, 'sharp': 4035, 'curve': 1070, 'abreast': 16, 'compel': 823, 'view': 4782, 'require': 3803, 'cravat': 1019, 'fringe': 1837, 'sharply': 4036, 'fashion': 1677, 'an': 165, 'patiently': 3258, 'press': 3518, 'mr': 2885, 'walter': 4815, 'earnest': 1460, 'honest': 2119, 'reverence': 3832, 'matter': 2695, 'voice': 4801, 'wholly': 4889, 'absent': 20, 'there': 4503, 'afraid': 92, 'bird': 434, 'assemble': 279, 'oration': 3124, 'vary': 4767, 'familiar': 1661, 'beat': 377, 'eaves': 1472, 'sir': 4115, 'thomas': 4519, 'enchant': 1520, 'fed': 1695, 'feast': 1691, 'adventure': 79, 'obsolete': 3063, 'length': 2483, 'tale': 4443, 'wit': 4924, 'anon': 187, 'withal': 4927, 'giant': 1892, 'horrible': 2131, 'club': 748, 'launcelot': 2452, 'shield': 4049, 'afore': 91, 'stroke': 4337, 'asunder': 293, 'fellow': 1702, 'fear': 1689, 'hall': 2008, 'score': 3961, 'damsel': 1083, 'kneel': 2390, 'thanked': 4491, 'deliverance': 1180, 'manner': 2646, 'silk': 4095, 'meat': 2712, 'born': 488, 'bless': 457, 'knight': 2394, 'thou': 4522, 'prison': 3544, 'du': 1432, 'lake': 2417, 'horse': 2133, 'valley': 4758, 'evil': 1585, 'lodge': 2552, 'fortune': 1803, 'therein': 4505, 'host': 2138, 'garret': 1865, 'harness': 2028, 'horseback': 2134, 'haste': 2034, 'moonlight': 2850, 'lash': 2441, 'knightly': 2395, 'truly': 4662, 'yonder': 4992, 'shall': 4031, 'shame': 4032, 'partner': 3235, 'kay': 2360, 'alight': 128, 'assail': 278, 'nay': 2951, 'therefore': 4504, 'ye': 4979, 'earth': 1463, 'yield': 4990, 'seneschal': 3994, 'loath': 2548, 'hither': 2104, 'overcome': 3159, 'reason': 3725, 'advise': 83, 'choose': 695, 'king': 2384, 'arthur': 265, 'queen': 3655, 'grace': 1935, 'mercy': 2743, 'thither': 4518, 'arose': 255, 'early': 1459, 'kays': 2361, 'armor': 252, 'stable': 4262, 'faith': 1657, 'bold': 479, 'ride': 3843, 'american': 155, 'rear': 3724, 'hartford': 2032, 'practical': 3474, 'barren': 359, 'sentiment': 4004, 'poetry': 3417, 'blacksmith': 446, 'uncle': 4700, 'doctor': 1354, 'real': 3719, 'machinery': 2610, 'invent': 2300, 'become': 381, 'rough': 3878, 'match': 2687, 'hercules': 2080, 'alongside': 141, 'crack': 1013, 'joint': 2339, 'skull': 4133, 'neighbor': 2969, 'least': 2469, 'grass': 1948, 'landscape': 2431, 'entirely': 1546, 'shape': 4033, 'prodigious': 3563, 'steel': 4293, 'horn': 2130, 'project': 3573, 'forehead': 1787, 'captive': 606, 'argument': 240, 'bulk': 556, 'agreement': 108, 'comfortably': 793, 'puzzle': 3647, 'circus': 709, 'conclude': 854, 'tower': 4602, 'turret': 4681, 'parchment': 3216, 'particularly': 3233, 'dim': 1257, 'historian': 2101, 'trace': 4605, 'dimmer': 1261, 'sentence': 4003, 'legend': 2479, 'evidently': 1584, 'indicate': 2233, 'smell': 4159, 'wagon': 4808, 'mainly': 2625, 'faint': 1654, 'wheel': 4863, 'apparently': 210, 'cataract': 631, 'golden': 1921, 'sweet': 4424, 'reflect': 3755, 'paid': 3181, 'startle': 4277, 'fantastic': 1667, 'cow': 1010, 'wide': 4894, 'astonish': 290, 'gaze': 1870, 'fascination': 1676, 'totally': 4593, 'overlook': 3162, 'merit': 2746, 'respect': 3816, 'display': 1316, 'surprising': 4408, 'food': 1774, 'approach': 222, 'wretched': 4965, 'patch': 3251, 'indifferent': 2236, 'coarse': 761, 'animal': 178, 'rude': 3887, 'naked': 2929, 'except': 1600, 'humble': 2158, 'response': 3819, 'pain': 3183, 'wilderness': 4902, 'mere': 2744, 'crooked': 1039, 'troop': 4655, 'contentedly': 927, 'reek': 3752, 'main': 2624, 'distant': 1329, 'noble': 3005, 'wound': 4960, 'glorious': 1911, 'plume': 3404, 'flash': 1749, 'mail': 2623, 'banner': 351, 'doublet': 1380, 'joyous': 2344, 'height': 2067, 'huge': 2152, 'castle': 627, 'blast': 453, 'menatarms': 2736, 'morion': 2858, 'flap': 1747, 'figure': 1722, 'dragon': 1396, 'displayed': 1317, 'flung': 1764, 'lower': 2588, 'arch': 233, 'dismount': 1309, 'greet': 1967, 'ceremony': 647, 'fro': 1838, 'altogether': 151, 'hinder': 2095, 'please': 3396, 'thee': 4497, 'liver': 2544, 'idle': 2177, 'purpose': 3640, 'seek': 3985, 'airy': 116, 'pink': 3361, 'goodnatured': 1925, 'frame': 1814, 'arrive': 262, 'smile': 4160, 'inform': 2248, 'page': 3180, 'severe': 4023, 'nettle': 2979, 'question': 3658, 'chatter': 668, 'expect': 1618, 'reply': 3796, 'straightway': 4319, 'satisfy': 3928, 'lunatic': 2600, 'evidence': 1582, 'stumble': 4348, 'total': 4592, 'eclipse': 1475, 'sixth': 4126, 'century': 646, 'occur': 3074, '21st': 5, 'noon': 3018, 'also': 146, 'truth': 4667, 'wherefore': 4868, 'problem': 3556, 'alert': 122, 'pair': 3188, 'nineteenth': 3000, 'kingdom': 2385, 'thirteen': 4516, 'upward': 4741, 'waste': 4828, 'story': 4316, 'immediate': 2193, 'dungeon': 1443, 'scant': 3940, 'common': 803, 'ransom': 3696, 'precious': 3488, 'drinking': 1417, 'illustrious': 2188, 'exaggerate': 1588, 'fact': 1647, 'correct': 972, 'safe': 3902, 'clarence': 715, 'immense': 2195, 'rather': 3707, 'loud': 2578, 'contrast': 938, 'lofty': 2553, 'depend': 1190, 'beam': 372, 'twilight': 4687, 'musician': 2909, 'clothed': 744, 'flag': 1745, 'ornament': 3134, 'strictly': 4332, 'tapestry': 4451, 'art': 264, 'create': 1022, 'scale': 3938, 'represent': 3799, 'carve': 622, 'pillared': 3354, 'rigid': 3847, 'statue': 4283, 'vault': 4770, 'oaken': 3049, 'address': 64, 'lift': 2507, 'remark': 3777, 'bread': 514, 'beef': 387, 'bone': 481, 'average': 320, 'attitude': 307, 'spent': 4239, 'division': 1350, 'prospect': 3596, 'plunge': 3405, 'storm': 4315, 'deafen': 1119, 'observe': 3060, 'object': 3053, 'delighted': 1177, 'paw': 3263, 'growl': 1984, 'already': 145, 'resume': 3823, 'behavior': 394, 'gracious': 1937, 'serious': 4011, 'listener': 2536, 'childlike': 687, 'gentle': 1880, 'el': 1492, 'associate': 284, 'cruel': 1045, 'dealt': 1122, 'relish': 3773, 'shudder': 4077, 'stiffen': 4299, 'physical': 3335, 'weariness': 4840, 'charity': 664, 'utter': 4752, 'disposition': 1321, 'complain': 829, 'force': 1783, 'serve': 4015, 'treatment': 4636, 'philosophical': 3329, 'bearing': 375, 'outcome': 3145, 'training': 4614, 'intellectual': 2276, 'fortitude': 1802, 'indian': 2232, 'strip': 4335, 'murderous': 2902, 'undertaken': 4711, 'dispute': 1322, 'duel': 1437, 'introduce': 2297, 'exist': 1616, 'cause': 636, 'meet': 2720, 'childhood': 685, 'pride': 3532, 'engage': 1533, 'attractive': 309, 'brain': 507, 'society': 4178, 'indeed': 2230, 'mar': 2657, 'spoil': 4247, 'render': 3788, 'impossible': 2206, 'incident': 2218, 'center': 644, 'master': 2683, 'eight': 1490, 'knelt': 2391, 'conspicuously': 904, 'mass': 2681, 'flowerbed': 1763, 'feminine': 1707, 'inclined': 2220, 'assent': 280, 'pardon': 3217, 'elect': 1497, 'single': 4109, 'prowess': 3611, 'fasten': 1679, 'inquiry': 2262, 'trick': 4645, 'case': 624, 'exactly': 1587, 'simple': 4100, 'comment': 801, 'honor': 2120, 'rank': 3693, 'christian': 699, 'brief': 529, 'sweep': 4423, 'maiden': 2622, 'desperate': 1212, 'foreign': 1788, 'conquer': 884, 'quietly': 3664, 'sixteen': 4125, 'pitch': 3371, 'former': 1797, 'dozen': 1390, 'countenance': 990, 'flow': 1761, 'gown': 1933, 'risen': 3853, 'feebly': 1697, 'sway': 4420, 'ancient': 170, 'observable': 3058, 'dumb': 1442, 'endure': 1529, 'merlin': 2747, 'hath': 2041, 'dug': 1439, 'third': 4515, 'modest': 2823, 'prithee': 3547, 'nestle': 2978, 'lad': 2412, 'reality': 3720, 'file': 1723, 'drone': 1422, 'snore': 4169, 'support': 4399, 'subdue': 4353, 'instrument': 2273, 'fold': 1769, 'unconscious': 4705, 'fly': 1766, 'softly': 4181, 'everywhere': 1581, 'cheese': 676, 'nibble': 2988, 'naive': 2928, 'scene': 3946, 'weary': 4841, 'leech': 2474, 'search': 3972, 'rock': 3867, 'richly': 3840, 'row': 3883, 'scabbard': 3937, 'ship': 4054, 'pavilion': 3262, 'fought': 1806, 'pellinore': 3274, 'flee': 1752, 'carlion': 617, 'lightly': 2513, 'counsel': 988, 'liketh': 2518, 'craft': 1016, 'merry': 2749, 'dinadan': 1265, 'awake': 323, 'rouse': 3881, 'joke': 2340, 'sufficiently': 4372, 'metal': 2754, 'mug': 2894, 'loose': 2570, 'fright': 1835, 'crash': 1017, 'din': 1264, 'multitude': 2897, 'immortal': 2196, 'breed': 522, 'sad': 3898, 'flat': 1750, 'wormeaten': 4952, 'dry': 1431, 'convince': 955, 'isnt': 2317, 'antiquity': 194, 'later': 2447, 'petrify': 3320, 'majestic': 2627, 'period': 3295, 'blank': 449, 'note': 3029, 'educate': 1482, 'merely': 2745, 'encounter': 1523, 'ridiculous': 3844, 'garb': 1861, 'intend': 2277, 'secure': 3980, 'spar': 4221, 'monster': 2844, 'escape': 1557, 'sprang': 4252, 'condemn': 857, 'yawn': 4978, 'date': 1104, 'sprung': 4255, 'possibility': 3457, 'ordinary': 3127, 'sane': 3920, 'detail': 1223, 'blush': 473, 'mild': 2775, 'convey': 951, 'random': 3690, 'moral': 2855, 'implies': 2202, 'sample': 3916, 'english': 1536, 'european': 1570, 'history': 2102, 'appearance': 213, 'suppose': 4400, 'conversation': 948, 'character': 660, 'embarrass': 1509, 'delicate': 1173, 'aware': 325, 'relieve': 3770, 'commonsense': 807, 'hint': 2097, 'dear': 1125, 'discuss': 1298, 'interested': 2284, 'compliment': 834, 'shock': 4057, 'distress': 1337, 'situation': 4122, 'degree': 1165, 'past': 3247, 'experience': 1621, 'lifelike': 2504, 'intensity': 2279, 'burn': 561, 'avoid': 321, 'foul': 1807, 'interrupt': 2287, 'travel': 4627, 'smith': 4161, 'robinson': 3866, 'egypt': 1489, 'amount': 162, 'rudiment': 3888, 'favor': 1686, 'calamity': 586, 'fur': 1850, 'realm': 3723, 'answer': 189, 'promise': 3577, 'alarm': 118, 'better': 422, 'leisure': 2480, 'miracle': 2796, 'ought': 3143, 'deepest': 1149, 'message': 2751, 'marrow': 2670, 'raiment': 3680, 'persuade': 3313, 'brave': 513, 'thrust': 4537, 'naught': 2948, 'reluctant': 3774, 'perplexed': 3301, 'determine': 1228, 'delay': 1167, 'treble': 4637, 'peril': 3294, 'compass': 822, 'measure': 2711, 'doom': 1372, 'grade': 1938, 'stage': 4263, 'colossal': 782, 'sublime': 4355, 'blackness': 445, 'shine': 4053, 'fruit': 1843, 'warmth': 4820, 'stillness': 4302, 'knowledge': 2400, 'pale': 3190, 'realize': 3721, 'hearing': 2052, 'danger': 1086, 'deeper': 1148, 'meaning': 2707, 'crept': 1028, 'provision': 3610, 'mercury': 2742, 'rally': 3685, 'cheerfulness': 675, 'tube': 4670, 'solicitude': 4188, 'impatient': 2199, 'tomorrow': 4574, 'gather': 1867, 'triumph': 4650, 'nation': 2942, 'meantime': 2709, 'push': 3645, 'background': 337, 'propose': 3591, 'report': 3797, 'compromise': 841, 'footstep': 1779, 'recall': 3729, 'accept': 30, 'daze': 1114, 'purposely': 3641, 'maze': 2702, 'underground': 4708, 'corridor': 975, 'fierce': 1715, 'glare': 1902, 'enclose': 1522, 'stake': 4268, 'monk': 2839, 'terrace': 4480, 'ti': 4543, 'reveal': 3829, 'terror': 4485, 'morrow': 2860, 'today': 4564, 'weave': 4843, 'potency': 3465, 'seize': 3987, 'heaven': 2059, 'deceive': 1131, 'content': 926, 'thy': 4542, 'cease': 639, 'sufficient': 4371, 'fancy': 1664, 'shadow': 4027, 'implore': 2203, 'sake': 3908, 'assist': 281, 'profound': 3571, 'solitude': 4191, 'movement': 2884, 'perceptible': 3284, 'humanity': 2157, 'image': 2189, 'continued': 932, 'carefully': 614, 'torch': 4585, 'slightly': 4150, 'sky': 4134, 'latin': 2448, 'impulse': 2213, 'slowly': 4155, 'boil': 478, 'rim': 3849, 'priest': 3533, 'motionless': 2873, 'wave': 4832, 'shout': 4067, 'rang': 3691, 'pathetic': 3253, 'protest': 3600, 'condition': 859, 'prove': 3604, 'latter': 2449, 'surely': 4402, 'mistake': 2811, 'restore': 3821, 'dominion': 1369, 'receive': 3730, 'perpetual': 3300, 'minister': 2791, 'per': 3282, 'actual': 58, 'succeed': 4361, 'otherwise': 3142, 'dismiss': 1307, 'send': 3993, 'excuse': 1610, 'repent': 3793, 'extent': 1632, 'reasonable': 3726, 'arrangement': 259, 'darker': 1093, 'struggle': 4343, 'awkward': 330, 'horror': 2132, 'fan': 1663, 'misery': 2804, 'quite': 3667, 'inasmuch': 2215, 'personage': 3308, 'political': 3428, 'authority': 316, 'velvet': 4772, 'consequence': 891, 'habit': 1998, 'carpet': 618, 'convenience': 945, 'properly': 3585, 'suspect': 4413, 'east': 1468, 'parlor': 3224, 'knit': 2396, 'proportion': 3589, 'raphael': 3697, 'nightmare': 2997, 'celebrate': 641, 'several': 4022, 'miraculous': 2797, 'draught': 1400, 'upset': 4738, 'admire': 69, 'bell': 400, 'duty': 1449, 'loll': 2557, 'dish': 1302, 'butter': 573, 'modify': 2825, 'tone': 4575, 'pen': 3276, 'ink': 2255, 'opening': 3109, 'becomes': 382, 'sugar': 4374, 'coffee': 768, 'tea': 4458, 'tobacco': 4563, 'island': 2316, 'tame': 4447, 'british': 535, 'pitiable': 3372, 'panic': 3204, 'event': 1573, 'blown': 469, 'purchase': 3633, 'dissolve': 1326, 'recognize': 3738, 'globe': 1908, 'destruction': 1221, 'easily': 1467, 'subject': 4354, 'suddenly': 4367, 'minor': 2793, 'onward': 3107, 'countryside': 998, 'agreeable': 106, 'envy': 1551, 'satisfaction': 3925, 'george': 1885, 'explain': 1623, 'prefect': 3499, 'steady': 4287, 'contemplative': 922, 'puff': 3617, 'caution': 637, 'demand': 1181, 'secrecy': 3976, 'confide': 866, 'information': 2249, 'document': 1356, 'importance': 2204, 'purloin': 3637, 'royal': 3884, 'individual': 2237, 'possession': 3456, 'clearly': 724, 'infer': 2243, 'nonappearance': 3013, 'result': 3822, 'arise': 243, 'employ': 1515, 'design': 1205, 'nameless': 2932, 'station': 4282, 'thief': 4510, 'method': 2758, 'ingenious': 2250, 'letter': 2489, 'frank': 1817, 'had': 2000, 'perusal': 3315, 'entrance': 1547, 'especially': 1560, 'conceal': 843, 'hurry': 2167, 'vain': 4757, 'endeavor': 1527, 'drawer': 1402, 'uppermost': 4736, 'immediately': 2194, 'observes': 3062, 'transaction': 4619, 'somewhat': 4197, 'similar': 4099, 'converse': 949, 'claim': 714, 'owner': 3170, 'elbow': 1493, 'necessity': 2960, 'openly': 3110, 'driven': 1420, 'despair': 1210, 'commit': 802, 'conviction': 954, 'care': 611, 'thorough': 4520, 'hotel': 2140, 'chief': 682, 'warn': 4821, 'frequently': 1827, 'numerous': 3042, 'distance': 1328, 'chiefly': 683, 'readily': 3715, 'chamber': 654, 'cabinet': 581, 'paris': 3220, 'personally': 3311, 'ransack': 3695, 'enormous': 1540, 'abandon': 8, 'nook': 3017, 'premise': 3505, 'dupin': 1446, 'involve': 2305, 'building': 553, 'devote': 1235, 'furniture': 1852, 'presume': 3521, 'train': 4613, 'police': 3423, 'agent': 99, 'permit': 3299, 'plain': 3376, 'of': 3082, 'to': 4561, 'accurate': 43, 'probed': 3555, 'needle': 2965, 'article': 266, 'deposit': 1193, 'replace': 3795, 'you': 4994, 'compress': 840, 'thin': 4511, 'differ': 1247, 'example': 1595, 'certainly': 649, 'description': 1202, 'aid': 111, 'microscope': 2763, 'recent': 3731, 'fail': 1651, 'detect': 1226, 'instantly': 2269, 'grain': 1941, 'obvious': 3065, 'any': 199, 'unusual': 4732, 'suffice': 4370, 'absolutely': 23, 'complete': 830, 'divide': 1347, 'surface': 4403, 'compartment': 821, 'scrutinize': 3968, 'throughout': 4534, 'adjoin': 65, 'package': 3176, 'volume': 4802, 'officer': 3089, 'apply': 218, 'jealous': 2328, 'scrutiny': 3969, 'binding': 432, 'utterly': 4754, 'observation': 3059, 'memorandumbook': 2729, 'aloud': 143, 'external': 1633, 'finish': 1730, 'departure': 1189, 'depressed': 1194, 'deal': 1121, 'liberal': 2493, 'precisely': 3492, 'check': 670, 'obtain': 3064, 'lately': 2445, 'welcome': 4851, 'conceive': 848, 'medical': 2716, 'opinion': 3113, 'private': 3548, 'physician': 3336, 'recover': 3742, 'vacant': 4755, 'stare': 4275, 'pocketbook': 3409, 'thence': 4501, 'grasped': 1947, 'perfect': 3288, 'tremble': 4639, 'rapid': 3698, 'uttered': 4753, 'request': 3802, 'able': 13, 'persevere': 3305, 'cunning': 1056, 'detailed': 1224, 'mode': 2820, 'investigation': 2301, 'so': 4172, 'extend': 1630, 'defect': 1154, 'highly': 2091, 'resource': 3815, 'forcibly': 1785, 'schoolboy': 3953, 'odd': 3078, 'attract': 308, 'universal': 4719, 'player': 3388, 'number': 3041, 'loses': 2575, 'allude': 137, 'principle': 3541, 'opponent': 3115, 'simpleton': 4101, 'asks': 275, 'instance': 2267, 'variation': 4763, 'suggest': 4375, 'decide': 1134, 'lucky': 2593, 'what': 4861, 'analysis': 167, 'inquire': 2261, 'stupid': 4350, 'expression': 1627, 'accordance': 40, 'correspond': 973, 'attribute': 310, 'machiavelli': 2609, 'depends': 1192, 'intellect': 2275, 'ingenuity': 2251, 'hidden': 2086, 'faithful': 1658, 'diverse': 1345, 'usually': 4750, 'urge': 4743, 'extraordinary': 1636, 'probe': 3554, 'exaggeration': 1590, 'base': 362, 'grant': 1945, 'not': 3027, 'tenor': 4478, 'secrete': 3978, 'concealment': 845, 'adapt': 61, 'adopt': 73, 'disposal': 1319, 'concealed': 844, 'is': 2314, 'discovery': 1296, 'patience': 3256, 'determination': 1227, 'meant': 2708, 'limit': 2522, 'examination': 1593, 'remote': 3785, 'source': 4214, 'defeat': 1153, 'poet': 3414, 'guilty': 1993, 'quote': 3670, 'toute': 4598, 'convention': 947, 'car': 608, 'mathematician': 2693, 'popular': 3440, 'error': 1556, 'worthy': 4957, 'algebra': 124, 'french': 1825, 'if': 2181, 'derive': 1197, 'applicability': 216, 'then': 4500, 'religion': 3771, 'cultivate': 1054, 'mathematical': 2692, 'science': 3956, 'quantity': 3651, 'logic': 2555, 'abstract': 25, 'confound': 873, 'axiom': 332, 'relation': 3766, 'false': 1660, 'consideration': 898, 'motive': 2874, 'motif': 2871, 'necessarily': 2957, 'united': 4718, 'sum': 4381, 'apart': 205, 'as': 269, 'mythology': 2926, 'pagan': 3179, 'fable': 1645, 'continually': 930, 'inference': 2244, 'trust': 4665, 'speedily': 4236, 'convenient': 946, 'capacity': 601, 'reference': 3754, 'surround': 4410, 'policial': 3425, 'anticipate': 191, 'frequent': 1826, 'absence': 19, 'hail': 2002, 'afford': 90, 'opportunity': 3116, 'sooner': 4203, 'impress': 2207, 'concern': 850, 'despise': 1215, 'weak': 4834, 'intricate': 2296, 'recess': 3732, 'commonest': 804, 'simplicity': 4102, 'deliberately': 1170, 'induced': 2238, 'choice': 694, 'desperately': 1213, 'interview': 2291, 'strict': 4331, 'analogy': 166, 'metaphor': 2756, 'physic': 3334, 'motion': 2872, 'subsequent': 4359, 'commensurate': 800, 'forcible': 1784, 'constant': 906, 'inferior': 2245, 'progress': 3572, 'map': 2656, 'party': 3236, 'minutely': 2795, 'dint': 1271, 'excessively': 1604, 'unnoticed': 4726, 'palpably': 3198, 'beneath': 409, 'probable': 3552, 'prevent': 3528, 'portion': 3448, 'perceive': 3283, 'dash': 1100, 'decisive': 1137, 'resort': 3814, 'attempt': 302, 'prepared': 3509, 'accident': 33, 'ministerial': 2792, 'lounge': 2580, 'dawdle': 1110, 'usual': 4749, 'extremity': 1639, 'energetic': 1531, 'miscellaneous': 2800, 'musical': 2908, 'deliberate': 1169, 'excite': 1606, 'suspicion': 4415, 'cardrack': 610, 'dirty': 1278, 'rack': 3673, 'card': 609, 'solitary': 4190, 'torn': 4588, 'alter': 148, 'stayed': 4285, 'seal': 3971, 'cipher': 706, 'diminutive': 1259, 'female': 1706, 'carelessly': 616, 'correspondence': 974, 'excessive': 1603, 'methodical': 2759, 'suggestive': 4377, 'these': 4506, 'visitor': 4797, 'conclusion': 855, 'previously': 3530, 'strongly': 4340, 'intention': 2281, 'maintain': 2626, 'animate': 179, 'topic': 4583, 'rivet': 3857, 'trivial': 4653, 'entertain': 1543, 'broken': 538, 'manifest': 2643, 'reverse': 3833, 'original': 3131, 'bade': 340, 'eagerly': 1455, 'precede': 3486, 'pistol': 3369, 'series': 4010, 'fearful': 1690, 'mob': 2818, 'musket': 2910, 'ball': 345, 'drunkard': 1429, 'whither': 4884, 'farewell': 1670, 'nerve': 2975, 'attendant': 304, 'inevitably': 2242, 'precipitate': 3489, 'at': 294, 'genius': 1878, 'precise': 3491, 'defy': 1164, 'reduce': 3750, 'insult': 2274, 'identity': 2175, 'outwit': 3154, 'acquaint': 49, 'copy': 965, 'consult': 916, 'isitsöornot': 2315, 'scarcely': 3943, 'europe': 1569, 'author': 315, 'literature': 2539, 'remarkable': 3778, 'literary': 2538, 'hitherto': 2105, 'strangely': 4322, 'fate': 1682, 'vizier': 4800, 'scheherazade': 3948, 'arabian': 230, 'farther': 1674, 'monarch': 2835, 'vow': 4804, 'beard': 374, 'prophet': 3588, 'fulfil': 1844, 'religious': 3772, 'confer': 862, 'credit': 1025, 'devout': 1237, 'excellent': 1599, 'sense': 3998, 'accordingly': 41, 'sacrifice': 3897, 'distinctly': 1332, 'slightest': 4149, 'insist': 2265, 'actually': 59, 'despite': 1216, 'advice': 82, 'when': 4865, 'reading': 3717, 'plot': 3402, 'wedding': 4846, 'pretence': 3523, 'occupy': 3073, 'couch': 982, 'admit': 72, 'awaken': 324, 'husband': 2169, 'wring': 4967, 'she': 4038, 'capital': 603, 'slept': 4143, 'genteel': 1879, 'prevail': 3527, 'postpone': 3461, 'fare': 1669, 'narration': 2935, 'mistaken': 2812, 'wing': 4914, 'violent': 4791, 'other': 3140, 'notwithstanding': 3034, 'deprive': 1195, 'break': 516, 'descend': 1198, 'eve': 1571, 'heir': 2071, 'basket': 365, 'triumphed': 4652, 'beauty': 380, 'proper': 3584, 'ala': 117, 'inherit': 2253, 'add': 62, 'compound': 837, 'odious': 3080, 'happily': 2019, 'sinbad': 4105, 'sailor': 3906, 'related': 3765, 'remedy': 3780, 'neglect': 2967, 'pinch': 3359, 'forthwith': 1801, 'plea': 3393, 'sequel': 4007, 'hum': 2155, 'arabic': 231, 'retail': 3824, 'enjoy': 1538, 'possess': 3455, 'desire': 1207, 'packed': 3177, 'bundle': 558, 'porter': 3447, 'await': 322, 'arrival': 261, 'vessel': 4777, 'region': 3760, 'sand': 3918, 'ocean': 3076, 'singular': 4111, 'declare': 1140, 'distinguish': 1333, 'louder': 2579, 'horizon': 2129, 'speck': 4231, 'rapidly': 3700, 'swim': 4428, 'sea': 3970, 'foam': 1767, 'illuminate': 2186, 'audience': 311, 'unlike': 4725, 'exception': 1601, 'completely': 831, 'glimpse': 1906, 'moon': 2849, 'deficiency': 1159, 'provide': 3605, 'parallel': 3212, 'eyebrow': 1642, 'beast': 376, 'rapidity': 3699, 'duck': 1435, 'writhe': 4972, 'alike': 129, 'nostril': 3026, 'puffed': 3618, 'violence': 4790, 'shriek': 4072, 'disagreeable': 1281, 'hideous': 2088, 'surpass': 4405, 'astonishment': 291, 'resemble': 3805, 'garment': 1864, 'supply': 4398, 'ugly': 4693, 'fitting': 1742, 'skin': 4131, 'wretch': 4964, 'tip': 4555, 'box': 502, 'turban': 4678, 'contrivance': 941, 'weight': 4850, 'wider': 4896, 'victim': 4781, 'contemplation': 921, 'positively': 3453, 'accompany': 36, 'dense': 1186, 'thunder': 4539, 'mananimals': 2640, 'trumpet': 4663, 'harsh': 2031, 'accent': 29, 'spoken': 4249, 'loss': 2576, 'specie': 4229, 'trepidation': 4643, 'demon': 1182, 'mankind': 2644, 'vermin': 4775, 'savage': 3930, 'us': 4744, 'torture': 4590, 'malicious': 2632, 'equally': 1554, 'opposite': 3117, 'folly': 1772, 'regret': 3761, 'useless': 4747, 'mananimal': 2639, 'own': 3169, 'exercise': 1611, 'bestow': 420, 'token': 4568, 'teach': 4459, 'enable': 1519, 'ardent': 236, 'majesty': 2628, 'dialect': 1240, 'connect': 882, 'link': 2529, 'permission': 3298, 'translate': 4623, 'desirous': 1208, 'narrative': 2936, 'kindness': 2382, 'rate': 3706, 'pomegranate': 3431, 'conjure': 881, 'usher': 4748, 'ligeia': 2508, 'fascinate': 1675, 'ms': 2886, 'bottle': 494, 'descent': 1199, 'william': 4903, 'wilson': 4907, 'wherein': 4869, 'portrayed': 3450, 'domain': 1366, 'marvellous': 2676, 'murder': 2901, 'recital': 3733, 'demonstrate': 1183, 'capability': 599, 'illusion': 2187, 'premature': 3504, 'burial': 560, 'dr': 1391, 'professor': 3568, 'gordon': 1927, 'keen': 2362, 'criticism': 1035, 'poe': 3412, 'charles': 665, 'dickens': 1242, 'mercilessly': 2741, 'expose': 1625, 'poem': 3413, 'melody': 2723, 'tamerlane': 4448, 'city': 710, 'raven': 3710, 'sens': 3996, 'atmosphere': 297, 'imagination': 2190, 'construction': 912, 'absolute': 22, 'sympathize': 4435, 'sarah': 3923, 'superstition': 4396, 'edgar': 1480, 'echo': 1474, 'david': 1108, 'married': 2669, 'hopkins': 2128, 'meeting': 2721, 'parental': 3219, 'disapproval': 1285, 'profession': 3566, 'talent': 4444, 'orphan': 3135, 'utmost': 4751, 'destitution': 1220, 'future': 1854, 'john': 2337, 'allan': 132, 'richmond': 3841, 'affection': 87, 'childless': 686, 'attend': 303, 'manor': 2648, 'london': 2558, 'apt': 227, 'afterward': 96, 'mechanical': 2714, 'genuine': 1884, 'sensitive': 4001, 'tender': 4475, 'seventeen': 4020, 'university': 4721, 'virginia': 4792, 'institution': 2271, 'official': 3090, 'contrary': 937, 'creditable': 1026, 'student': 4345, 'contract': 934, 'debt': 1128, 'eventually': 1574, 'venture': 4774, 'youthful': 4998, 'publish': 3615, 'title': 4560, 'baltimore': 346, 'manuscript': 2654, 'admission': 71, 'academy': 28, 'west': 4857, 'attach': 298, 'accommodation': 35, 'disregard': 1323, 'aim': 113, 'dismissal': 1308, 'marriage': 2667, 'thrown': 4536, 'career': 612, 'periodical': 3296, 'prose': 3595, 'submit': 4358, 'select': 3989, 'magazine': 2616, 'philadelphia': 3326, 'york': 4993, 'punctual': 3628, 'industrious': 2240, 'critic': 1034, 'mirror': 2799, 'willingness': 4905, 'irregularity': 2311, 'capricious': 604, 'invariably': 2299, 'presentiment': 3514, 'gentlemanly': 1882, 'lamentable': 2421, 'wine': 4912, 'intoxication': 2295, 'visible': 4794, 'insane': 2263, 'september': 4006, 'southern': 4216, 'messenger': 2752, 'bride': 526, 'devotion': 1236, 'feature': 1693, 'poetic': 3415, 'production': 3565, 'inspire': 2266, 'consumption': 917, 'happiness': 2020, '30': 7, 'impart': 2197, 'chafe': 650, 'lee': 2473, 'blew': 459, 'chill': 689, 'journal': 2341, 'toil': 4567, 'salary': 3911, 'contribute': 939, 'draft': 1392, '10': 0, 'reputation': 3801, 'establish': 1562, 'securely': 3981, '20': 4, 'winter': 4917, 'monument': 2847, 'mountain': 2878, 'faroff': 1673, 'flutter': 1765, 'youth': 4997, 'malignant': 2633, 'estimate': 1566, 'thanks': 4492, 'scandal': 3939, 'dispel': 1313, 'was': 4824, 'household': 2144, 'france': 1815, 'appreciate': 220, 'warrant': 4823, 'anomalous': 186, 'centre': 645, 'distinct': 1330, 'germany': 1887, 'atlantic': 296, 'task': 4454, 'contemporary': 923, 'grateful': 1951, 'praise': 3478, 'deserve': 1204, 'friendship': 1834, 'justice': 2354, 'flourish': 1760, 'writes': 4971, 'generous': 1876, 'mixed': 2815, 'confine': 870, 'inner': 2257, 'imaginative': 2191, 'biography': 433, 'peculiarity': 3270, 'rarely': 3702, 'romantic': 3872, 'marriagebed': 2668, 'estate': 1564, 'classical': 719, 'education': 1483, 'join': 2338, 'greek': 1965, 'consul': 913, 'birth': 435, 'expectation': 1619, 'authorship': 317, 'competent': 827, 'drawn': 1405, 'shakespeare': 4030, 'milton': 2784, 'tenderness': 4477, 'appreciation': 221, 'classic': 718, 'style': 4352, 'pope': 3439, 'glitter': 1907, 'malignity': 2634, 'collins': 778, 'nambypamby': 2930, 'vigorous': 4783, 'obscure': 3056, 'dulness': 1441, 'respectable': 3817, 'southey': 4217, 'traditional': 4610, 'piety': 3349, 'clutch': 753, 'occasional': 3068, 'naturally': 2946, 'unfortunate': 4715, 'taste': 4455, 'kernel': 2369, 'poetical': 3416, 'purely': 3635, 'idleness': 2178, 'wordsworth': 4946, 'assurance': 288, 'stock': 4305, 'fireside': 1732, 'soar': 4174, 'combination': 786, 'dependent': 1191, 'organization': 3129, 'unhappy': 4716, 'conception': 849, 'juvenile': 2358, 'association': 285, 'playground': 3392, 'modulate': 2826, 'maturity': 2697, 'metre': 2760, 'valuable': 4759, 'phrase': 3333, 'innate': 2256, 'dimness': 1262, 'outline': 3149, 'tendency': 4474, 'wither': 4929, 'drawingroom': 1404, 'serene': 4008, 'column': 784, 'perfection': 3289, 'exquisite': 1629, 'kindred': 2383, 'sunset': 4390, 'quotation': 3669, 'creation': 1023, 'divine': 1348, 'veneration': 4773, 'enthusiasm': 1544, 'disciple': 1290, 'zeal': 4999, 'madness': 2615, 'veil': 4771, 'rent': 3790, 'throng': 4533, 'posse': 3454, 'repose': 3798, 'aristotle': 245, 'desirable': 1206, 'parnassus': 3226, 'residence': 3810, 'temperament': 4466, 'tradition': 4609, 'prime': 3534, 'needful': 2964, 'group': 1981, 'predominate': 3497, 'earlier': 1458, 'judging': 2347, 'standard': 4272, 'govern': 1929, 'ideal': 2174, 'esteem': 1565, 'definition': 1163, 'disagree': 1280, 'writing': 4973, 'guide': 1992, 'temple': 4467, 'offering': 3087, 'oracle': 3122, 'chosen': 698, 'seldom': 3988, 'influence': 2247, 'distinguishes': 1334, 'resolve': 3813, 'tend': 4472, 'paint': 3186, 'chemical': 677, 'mystic': 2924, 'envelop': 1550, 'affect': 85, 'rainbow': 3682, 'extra': 1634, 'subtle': 4360, 'graceful': 1936, 'arabesque': 229, 'sombre': 4192, 'stamp': 4270, 'muse': 2905, 'concede': 847, 'deficient': 1160, 'diction': 1244, 'scientific': 3957, 'precision': 3493, 'demonstration': 1184, 'personality': 3310, 'heat': 2057, 'originality': 3132, 'repetition': 3794, 'antagonistic': 190, 'mastery': 2684, 'inhabit': 2252, 'impression': 2208, 'important': 2205, 'conveyed': 952, 'october': 3077, 'continental': 929, 'principally': 3540, 'brilliant': 531, 'eloquence': 1505, 'expressive': 1628, 'fiery': 1718, 'glowed': 1914, 'pallor': 3193, 'quicken': 3660, 'frozen': 1842, 'mortal': 2861, 'vision': 4795, 'proposition': 3592, 'define': 1161, 'reject': 3763, 'process': 3559, 'built': 554, 'spell': 4237, 'dwell': 1451, 'passionate': 3245, 'damn': 1081, 'gnawed': 1915, 'anguish': 177, 'shroud': 4075, 'gloom': 1909, 'beating': 378, 'aidenn': 112, 'portal': 3446, 'disturbed': 1342, 'constitution': 908, 'loved': 2583, 'fitful': 1740, 'destiny': 1219, 'sin': 4104, 'pursuit': 3644, 'intimate': 2293, 'reflection': 3756, 'element': 1499, 'revelation': 3830, 'solemn': 4186, 'stately': 4280, 'indication': 2234, 'phase': 3325, 'symbol': 4433, 'social': 4177, 'shrewd': 4070, 'compose': 835, 'villain': 4788, 'novel': 3035, 'militate': 2779, 'contradict': 936, 'cheek': 672, 'his': 2100, 'readiness': 3716, 'constitutional': 909, 'arrogance': 263, 'prejudice': 3502, 'angle': 175, 'morbid': 2856, 'drapery': 1399, 'acquaintance': 50, 'reside': 3809, 'office': 3088, 'treat': 4635, 'courtesy': 1004, 'resentment': 3807, 'employment': 1516, 'ability': 12, 'mannered': 2647, 'development': 1231, 'activity': 57, 'accuse': 44, 'connection': 883, 'infirmity': 2246, 'temporary': 4468, 'vanity': 4762, 'doubtless': 1383, 'modesty': 2824, 'retain': 3825, 'speaks': 4226, 'type': 4691, 'evident': 1583, 'preface': 3498, 'compels': 825, 'price': 3531, 'tomb': 4572, 'season': 3973, 'south': 4215, 'thursday': 4540, 'february': 1694, 'universe': 4720, 'deny': 1187, 'belief': 398, 'cordial': 966, 'portrait': 3449, 'sickness': 4084, 'health': 2047, 'sole': 4185, 'deepen': 1147, 'pool': 3435, 'vivid': 4799, 'sensation': 3997, 'oppress': 3118, 'mansion': 2649, 'grey': 1968, 'discernible': 1288, 'narrowly': 2938, 'aspect': 277, 'principal': 3539, 'overspread': 3164, 'inconsistency': 2224, 'remind': 3783, 'extensive': 1631, 'decay': 1129, 'observer': 3061, 'gothic': 1928, 'heighten': 2068, 'ceiling': 640, 'hesitate': 2083, 'acknowledge': 48, 'staircase': 4267, 'mingle': 2788, 'perplexity': 3302, 'feeble': 1696, 'gleam': 1904, 'prominent': 3576, 'fret': 1830, 'comfortless': 795, 'antique': 193, 'pervade': 3316, 'constrain': 910, 'sincerity': 4107, 'awe': 327, 'terribly': 4482, 'companion': 814, 'boyhood': 504, 'complexion': 833, 'luminous': 2598, 'comparison': 820, 'pallid': 3192, 'hebrew': 2062, 'breadth': 515, 'prominence': 3575, 'ghastly': 1889, 'lustre': 2604, 'texture': 4488, 'nervous': 2976, 'agitation': 101, 'trait': 4615, 'deduce': 1143, 'tremulous': 4642, 'abeyance': 9, 'abrupt': 17, 'leaden': 2462, 'opium': 3114, 'intense': 2278, 'solace': 4183, 'malady': 2630, 'wear': 4839, 'oppressive': 3120, 'slave': 4137, 'perish': 3297, 'intolerable': 2294, 'abhorrence': 10, 'grim': 1971, 'moreover': 2857, 'tenant': 4471, 'whence': 4866, 'palpable': 3197, 'tenderly': 4476, 'beloved': 404, 'relative': 3767, 'decease': 1130, 'race': 3672, 'retreat': 3827, 'emaciate': 1508, 'buck': 550, 'alice': 125, 'ramble': 3687, 'wintry': 4918, 'paddock': 3178, 'terrier': 4483, 'bid': 428, 'weigh': 4849, 'shepherd': 4044, 'nevertheless': 2981, 'dignity': 1253, 'pamper': 3199, 'harden': 2023, 'muscle': 2904, 'north': 3021, 'manuel': 2652, 'weakness': 4835, 'memorable': 2728, 'treachery': 4631, 'orchard': 3125, 'stroll': 4338, 'park': 3223, 'accepted': 32, 'rope': 3876, 'wisdom': 4920, 'menacingly': 2735, 'displeasure': 1318, 'surprise': 4406, 'tighten': 4548, 'rage': 3677, 'halfway': 2007, 'twist': 4689, 'fury': 1853, 'chest': 678, 'angry': 176, 'strength': 4329, 'dimly': 1260, 'hoarse': 2107, 'locomotive': 2551, 'anger': 174, 'nursing': 3046, 'pent': 3280, 'crate': 1018, 'bulge': 555, 'saloonkeeper': 3914, 'peer': 3273, 'sickly': 4083, 'bar': 352, 'whereupon': 4870, 'sullenly': 4380, 'clerk': 727, 'railway': 3679, 'advance': 76, 'quiver': 3668, 'detestable': 1229, 'mew': 2761, 'silly': 4096, 'outrage': 3150, 'parch': 3215, 'torment': 4587, 'metamorphose': 2755, 'relief': 3769, 'launch': 2453, 'whirl': 4877, 'snarl': 4167, 'blow': 467, 'stagger': 4264, 'limply': 2525, 'bloody': 463, 'advanced': 77, 'hurl': 2166, 'shift': 4050, 'coolly': 961, 'wrench': 4963, 'described': 1201, 'announce': 182, 'consignment': 899, 'genial': 1877, 'introduction': 2298, 'primitive': 3535, 'fiercer': 1717, 'latent': 2446, 'arouse': 257, 'conciliate': 853, 'curly': 1066, 'deck': 1138, 'narwhal': 2940, 'perrault': 3303, 'françois': 1819, 'twice': 4685, 'destine': 1218, 'developed': 1230, 'calm': 590, 'administer': 67, 'treacherous': 4630, 'meditate': 2718, 'punish': 3629, 'whip': 4876, 'sang': 3921, 'culprit': 1053, 'gloomy': 1910, 'annoyed': 184, 'tireless': 4558, 'pulse': 3624, 'propeller': 3583, 'apparent': 209, 'steadily': 4286, 'colder': 772, 'sank': 3922, 'curiously': 1064, 'beach': 371, 'primordial': 3536, 'loaf': 2547, 'constantly': 907, 'fang': 1665, 'leather': 2470, 'crystal': 1050, 'ghostly': 1891, 'penetrate': 3278, 'mockery': 2819, 'adventurer': 80, 'pit': 3370, 'alien': 127, 'affected': 86, 'crush': 1047, 'exaltation': 1592, 'mote': 2868, 'amidst': 158, 'fade': 1650, 'persist': 3306, 'hungry': 2163, 'eagerness': 1456, 'suggestion': 4376, 'coal': 759, 'henry': 2078, 'surge': 4404, 'overturn': 3166, 'commotion': 808, 'withdraw': 4928, 'breathing': 521, 'heavily': 2060, 'closer': 740, 'cluster': 752, 'uproar': 4737, 'disturb': 1340, 'comrade': 842, 'flame': 1746, 'casually': 629, 'sled': 4138, 'fiercely': 1716, 'cries': 1030, 'midday': 2764, 'intervene': 2290, 'northern': 3023, 'swiftly': 4427, 'pall': 3191, 'arctic': 234, 'pot': 3463, 'exclamation': 1609, 'amid': 157, 'triumphant': 4651, 'stout': 4317, 'pursuer': 3643, 'unseen': 4730, 'frighten': 1836, 'unable': 4696, 'trail': 4612, 'trot': 4657, 'slink': 4152, 'scent': 3947, 'wistfulness': 4923, 'frost': 1841, 'goin': 1919, 'smart': 4157, 'shewolf': 4046, 'dubiously': 1434, 'menace': 2734, 'playfully': 3390, 'lure': 2602, 'security': 3982, 'companionship': 815, 'playfulness': 3391, 'intent': 2280, 'leap': 2467, 'wolfpack': 4934, 'screen': 3966, 'quickly': 3661, 'succession': 4364, 'yelp': 4985, 'recognise': 3736, 'lonely': 2560, 'firewood': 1733, 'cooked': 957, 'protection': 3599, 'whimper': 4875, 'chorus': 697, 'eager': 1454, 'continuous': 933, 'brute': 549, 'brand': 509, 'pack': 3175, 'hasty': 2037, 'scorch': 3960, 'worn': 4953, 'chop': 696, 'trunk': 4664, 'hoist': 2109, 'lighten': 2511, 'fort': 1799, 'mcgurry': 2703, 'range': 3692, 'starve': 4278, 'crouch': 1042, 'awoke': 331, 'delayed': 1168, 'grip': 1974, 'prod': 3562, 'fond': 1773, 'delicately': 1174, 'quest': 3657, 'slash': 4136, 'moose': 2854, 'rabbit': 3671, 'hastily': 2036, 'missile': 2808, 'delicacy': 1172, 'boldest': 480, 'overpower': 3163, 'benumbed': 414, 'pineknot': 3360, 'factor': 1648, 'flood': 1757, 'bursting': 565, 'tremendously': 4641, 'mitten': 2814, 'protect': 3598, 'melt': 2724, 'haunch': 2043, 'dawn': 1111, 'strove': 4341, 'mysterious': 2922, 'closely': 739, 'sinking': 4112, 'linger': 2528, 'leader': 2463, 'direct': 1274, 'member': 2725, 'pace': 3173, 'kindly': 2381, 'prone': 3580, 'betrayed': 421, 'carriage': 619, 'gaunt': 1869, 'mate': 2689, 'roughly': 3879, 'lover': 2586, 'abruptly': 18, 'vigour': 4784, 'elder': 1494, 'resent': 3806, 'confront': 874, 'precipitately': 3490, 'collide': 777, 'longstanding': 2565, 'limp': 2524, 'contraction': 935, 'bull': 557, 'shrewdly': 4071, 'savagely': 3931, 'martinez': 2673, 'san': 3917, 'francisco': 1816, 'bay': 369, 'landsman': 2432, 'placid': 3375, 'pilothouse': 3356, 'moist': 2829, 'obscurity': 3057, 'conscious': 887, 'pilot': 3355, 'labour': 2407, 'tide': 4545, 'navigation': 2950, 'specialist': 4228, 'essay': 1561, 'current': 1067, 'aboard': 14, 'greedy': 1964, 'special': 4227, 'redfaced': 3748, 'enjoyment': 1539, 'shrill': 4073, 'pip': 3365, 'gong': 1922, 'daredevil': 1091, 'sunk': 4389, 'comin': 796, 'decency': 1133, 'amuse': 163, 'confident': 868, 'partly': 3234, 'clad': 713, 'trim': 4648, 'quietness': 3665, 'squarely': 4258, 'lifepreservers': 2506, 'remembrance': 3782, 'overhead': 3161, 'now': 3038, 'empty': 1517, 'litter': 2540, 'flight': 1754, 'wrap': 4961, 'canvas': 597, 'gallantly': 1857, 'comer': 790, 'bedlam': 385, 'overcoat': 3158, 'purplish': 3639, 'impel': 2200, 'laughter': 2451, 'pig': 3350, 'butcher': 571, 'capable': 600, 'helpless': 2076, 'disaster': 1286, 'assistance': 282, 'passenger': 3242, 'overboard': 3157, 'consequent': 892, 'painful': 3184, 'pang': 3203, 'lung': 2601, 'lifepreserver': 2505, 'strangle': 4324, 'survive': 4412, 'oar': 3050, 'paroxysm': 3227, 'final': 1725, 'community': 812, 'drift': 1415, 'liable': 2492, 'blankness': 451, 'cigar': 704, 'careless': 615, 'suffocate': 4373, 'vexed': 4779, 'rhythm': 3836, 'flare': 1748, 'counter': 991, 'ripple': 3851, 'ponder': 3432, 'tremendous': 4640, 'rasp': 3704, 'hot': 2139, 'painfully': 3185, 'beside': 416, 'terrific': 4484, 'tiny': 4554, 'cockney': 766, 'milk': 2780, 'draggle': 1394, 'hip': 2098, 'proclaim': 3561, 'cook': 956, 'decidedly': 1135, 'galley': 1858, 'posture': 3462, 'bang': 348, 'offend': 3084, 'coalbox': 760, 'dislike': 1304, 'cheap': 669, 'frayed': 1820, 'apologetic': 208, 'trouser': 4660, 'furnish': 1851, 'clutched': 754, 'prolong': 3574, 'me': 2704, 'clung': 751, 'schooner': 3955, 'pacific': 3174, 'southwest': 4218, 'lowlying': 2590, 'loom': 2568, 'hatch': 2039, 'noisily': 3010, 'haul': 2042, 'massive': 2682, 'been': 388, 'mould': 2875, 'lump': 2599, 'firmly': 1734, 'advertisement': 81, 'lurk': 2603, 'dormant': 1377, 'compelling': 824, 'grin': 1972, 'thumb': 4538, 'swell': 4425, 'hue': 2150, 'larsen': 2440, 'relaxed': 3768, 'diabolical': 1239, 'blasphemy': 452, 'crackle': 1014, 'spark': 4223, 'voyage': 4805, 'vile': 4785, 'occurrence': 3075, 'torrent': 4589, 'corpse': 971, 'humour': 2159, 'defiance': 1158, 'rebuke': 3728, 'crew': 1029, 'companionway': 816, 'hunter': 2165, 'superior': 4394, 'them': 4498, 'likeness': 2517, 'scarecrow': 3944, 'soften': 4180, 'blunt': 472, 'sensibility': 3999, 'slight': 4148, 'eyes': 1643, 'unusually': 4733, 'handsome': 2015, 'brood': 539, 'masculine': 2678, 'surrender': 4409, 'attack': 300, 'johansen': 2336, 'fit': 1739, 'aft': 94, 'cabinboy': 580, 'ard': 235, 'grown': 1985, 'rail': 3678, 'port': 3445, 'entry': 1549, 'tough': 4596, 'nasty': 2941, 'bleak': 456, 'splash': 4244, 'summon': 4384, 'hatchcover': 2040, 'freight': 1824, 'darkeyed': 1094, 'liberally': 2495, 'barking': 356, 'ominous': 3102, 'miniature': 2789, 'decision': 1136, 'frankness': 1818, 'openness': 3111, 'rig': 3845, 'anxiously': 198, 'all': 131, 'confuse': 875, 'down': 1385, 'coast': 763, 'mugridge': 2895, 'behaviour': 395, 'assistant': 283, 'ignorance': 2182, 'peel': 3271, 'lively': 2543, 'tray': 4629, 'tall': 4446, 'poop': 3436, 'madman': 2614, 'poise': 3419, 'epoch': 1552, 'lord': 2571, 'seventyfive': 4021, 'favour': 1687, 'birthday': 436, 'westminster': 4858, 'cocklane': 765, 'earthly': 1465, 'communication': 810, 'chicken': 681, 'pastor': 3248, 'achievement': 46, 'honour': 2122, 'procession': 3560, 'sixty': 4127, 'woodman': 4943, 'mire': 2798, 'poultry': 3467, 'farmer': 1672, 'revolution': 3834, 'silently': 4094, 'muffle': 2892, 'tread': 4632, 'justify': 2356, 'national': 2943, 'robbery': 3865, 'publicly': 3614, 'highwayman': 2092, 'tradesman': 4608, 'challenged': 653, 'failure': 1652, 'mayor': 2701, 'blunderbuss': 471, 'diamond': 1241, 'musketeer': 2911, 'criminal': 1032, 'tuesday': 4673, 'pamphlet': 3200, 'sixpence': 4124, 'greatness': 1962, 'chronicle': 701, 'dover': 1384, 'november': 3037, 'lumber': 2597, 'coach': 755, 'coachman': 758, 'war': 4818, 'droop': 1423, 'driver': 1421, 'emphatic': 1514, 'steam': 4290, 'mist': 2810, 'coachlamps': 757, 'plod': 3401, 'traveller': 4628, 'shy': 4081, 'confidential': 869, 'league': 2465, 'landlord': 2430, 'nondescript': 3014, 'perch': 3286, 'armchest': 250, 'negative': 2966, 'communicate': 809, 'closing': 742, 'tool': 4579, 'completeness': 832, 'flint': 1755, 'meanwhile': 2710, 'bridle': 528, 'darkly': 1095, 'depth': 1196, 'momentary': 2833, 'eternal': 1568, 'neighbour': 2971, 'darling': 1097, 'county': 999, 'colour': 783, 'muffler': 2893, 'fain': 1653, 'bald': 344, 'tellson': 4464, 'mare': 2660, 'uneasiness': 4712, 'leathern': 2471, 'contempt': 924, 'submission': 4356, 'variety': 4765, 'hedge': 2064, 'roadside': 3859, 'congratulate': 877, 'destination': 1217, 'dogkennel': 1362, 'lorry': 2572, 'concord': 856, 'establishment': 1563, 'consequently': 893, 'landlady': 2429, 'brown': 544, 'cuff': 1051, 'waistcoat': 4810, 'stocking': 4306, 'flaxen': 1751, 'wig': 4900, 'spun': 4256, 'linen': 2527, 'habitually': 1999, 'quaint': 3649, 'reserve': 3808, 'healthy': 2048, 'bachelor': 335, 'cliff': 731, 'heap': 2049, 'neighbourhood': 2972, 'lamplighter': 2424, 'desperation': 1214, 'manette': 2641, 'oil': 3095, 'graf': 1940, 'mahogany': 2620, 'pick': 3340, 'channel': 657, 'pierglass': 3348, 'hospital': 2136, 'cupid': 1059, 'cripple': 1033, 'divinity': 1349, 'formal': 1796, 'journey': 2342, 'trustee': 4666, 'customer': 1074, 'fellowcreatures': 1703, 'mangle': 2642, 'monsieur': 2843, 'clergy': 725, 'courage': 1001, 'useful': 4746, 'blooming': 465, 'uncertainty': 4699, 'wholesome': 4888, 'anywhere': 204, 'englishman': 1537, 'scrap': 3963, 'bonnet': 482, 'wooden': 4942, 'suspend': 4414, 'irregular': 2310, 'lame': 2419, 'dam': 1079, 'sip': 4114, 'earthenware': 1464, 'handkerchief': 2013, 'squeeze': 4259, 'dart': 1098, 'cask': 625, 'sport': 4250, 'inclination': 2219, 'embrace': 1510, 'rake': 3684, 'doorstep': 1374, 'mat': 2686, 'stain': 4265, 'saint': 3907, 'antoine': 195, 'nurse': 3045, 'baby': 334, 'smear': 4158, 'bag': 341, 'nightcap': 2996, 'undergone': 4707, 'grind': 1973, 'mill': 2781, 'doorway': 1375, 'afresh': 93, 'pole': 3422, 'chimney': 690, 'baker': 342, 'shelf': 4042, 'scanty': 3941, 'preparation': 3507, 'sale': 3912, 'roast': 3861, 'chestnut': 679, 'abide': 11, 'offence': 3083, 'diverge': 1344, 'shop': 4061, 'beer': 389, 'hammer': 2011, 'pavement': 3261, 'kennel': 2367, 'eccentric': 1473, 'pulley': 3622, 'grove': 1982, 'wineshop': 4913, 'keeper': 2365, 'madame': 2612, 'defarge': 1152, 'composure': 836, 'preside': 3517, 'shawl': 4037, 'toothpick': 4580, 'cough': 983, 'courtyard': 1006, 'nest': 2977, 'poverty': 3470, 'poison': 3420, 'languish': 2435, 'nicety': 2990, 'upside': 4739, 'tombstone': 4573, 'battery': 367, 'hears': 2053, 'hide': 2087, 'mound': 2876, 'marsh': 2672, 'pirate': 3368, 'cattle': 634, 'gargery': 1863, 'goodlooking': 1924, 'apron': 226, 'loop': 2569, 'bib': 425, 'forge': 1790, 'dwelling': 1452, 'churchyard': 703, 'peeped': 3272, 'crust': 1048, 'slice': 4144, 'which': 4873, 'stimulate': 4303, 'exertion': 1612, 'tonight': 4577, 'diminish': 1258, 'competition': 828, 'appetite': 214, 'bite': 440, 'medicine': 2717, 'virtue': 4793, 'pint': 3363, 'mixture': 2816, 'rob': 3862, 'housekeep': 2145, 'errand': 1555, 'sworn': 4432, 'impatience': 2198, 'christmas': 700, 'pudding': 3616, 'greatly': 1961, 'hulk': 2154, 'unreasonable': 4729, 'pantry': 3207, 'downstairs': 1387, 'owe': 3167, 'alarmed': 119, 'mincemeat': 2785, 'pockethandkerchief': 3410, 'brandy': 510, 'secretly': 3979, 'dilute': 1256, 'compact': 813, 'tempt': 4469, 'coarser': 762, 'web': 4845, 'blade': 447, 'invisible': 2302, 'phantom': 3324, 'dike': 1254, 'who': 4885, 'despatch': 1211, 'ditch': 1343, 'dine': 1266, 'nothin': 3030, 'pursue': 3642, 'coming': 797, 'likewise': 2519, 'mutter': 2918, 'constable': 905, 'dustpan': 1448, 'superb': 4392, 'pickle': 3342, 'fowl': 1811, 'yesterday': 4987, 'dresser': 1413, 'parlour': 3225, 'crockery': 1037, 'poodle': 3434, 'mantelshelf': 2650, 'housekeeper': 2146, 'holiday': 2112, 'policeman': 3424, 'dictate': 1243, 'dissuade': 1327, 'dwelt': 1453, 'clergyman': 726, 'conference': 863, 'vestry': 4778, 'congregation': 879, 'extreme': 1638, 'wopsle': 4944, 'hubble': 2149, 'wheelwright': 4864, 'pumblechook': 3625, 'appropriate': 224, 'roman': 3871, 'uncommonly': 4703, 'middleaged': 2766, 'mum': 2898, 'orange': 3123, 'extraordinarily': 1635, 'lane': 2433, 'acute': 60, 'shilling': 4051, 'miserable': 2803, 'meditative': 2719, 'actively': 56, 'pronounce': 3581, 'necessitate': 2959, 'sergeant': 4009, 'tar': 4452, 'prefer': 3500, 'hospitality': 2137, 'liberality': 2494, 'blaze': 454, 'approve': 225, 'polite': 3426, 'sensible': 4000, 'arid': 242, 'footing': 1778, 'sleet': 4141, 'convict': 953, 'hound': 2141, 'sheep': 4040, 'annoyance': 183, 'wonderfully': 4938, 'prisonship': 3546, 'ha': 1997, 'exasperate': 1596, 'assure': 289, 'innocence': 2258, 'distribute': 1338, 'reasonably': 3727, 'landingplace': 2428, 'greatcoat': 1960, 'dip': 1272, 'noah': 3004, 'ark': 247, 'moor': 2851, 'debate': 1127, 'domestic': 1368, 'cowardly': 1011, 'intercourse': 2282, 'newly': 2984, 'positive': 3452, 'over': 3156, 'theory': 4502, 'eyesight': 1644, 'stair': 4266, 'exceptional': 1602, 'declaration': 1139, 'assume': 287, 'earnings': 1462, 'greataunt': 1959, 'limited': 2523, 'penny': 3279, 'cottage': 979, 'upstairs': 4740, 'dignify': 1252, 'disadvantage': 1279, 'biddy': 429, 'mend': 2737, 'alphabet': 144, 'considerably': 897, 'disguise': 1300, 'purblind': 3632, 'hearth': 2055, 'print': 3542, 'monosyllable': 2841, 'occupation': 3072, 'purple': 3638, 'couldn': 985, 'share': 4034, 'scrooge': 3967, 'grasp': 1946, 'nipped': 3001, 'pelt': 3275, 'entreaty': 1548, 'countinghouse': 995, 'keyhole': 2372, 'dingy': 1268, 'predict': 3495, 'comforter': 794, 'richer': 3839, 'nephew': 2974, 'origin': 3130, 'belonging': 402, 'charitable': 663, 'consent': 890, 'freely': 1823, 'proffer': 3569, 'labourer': 2408, 'butler': 572, 'monday': 2836, 'pierce': 3347, 'dunstan': 1445, 'mumble': 2899, 'contend': 925, 'austen': 313, 'persuasion': 3314, 'elinor': 1503, 'marianne': 2661, 'jane': 2325, 'amiable': 156, 'bennet': 411, 'dashwood': 1101, 'darcy': 1089, 'edward': 1484, 'ferrars': 1709, 'colonel': 779, 'dashwoods': 1102, 'rival': 3855, 'matchmaking': 2688, 'inward': 2306, 'bruise': 546, 'squire': 4260, 'middleton': 2768, 'rejoice': 3764, 'population': 3441, 'palmer': 3195, 'pearl': 3267, 'chapter': 659, 'momentous': 2834, 'norland': 3020, 'ancestor': 169, 'civil': 711, 'local': 2549, 'barton': 361, 'wellknown': 4855, 'oldfashioned': 3097, 'devonshire': 1234, 'delightful': 1178, 'canal': 593, 'yew': 4989, 'accomplishment': 38, 'lavender': 2455, 'generation': 1874, 'alteration': 149, 'legal': 2478, 'niece': 2992, 'attachment': 299, 'goodness': 1926, 'independent': 2231, 'disappointment': 1284, 'bequest': 415, 'imperfect': 2201, 'outweigh': 3153, 'unkind': 4722, 'apiece': 207, 'improvement': 2211, 'twelvemonth': 4683, 'unless': 4724, 'selfish': 3991, 'propriety': 3594, 'ayear': 333, 'addition': 63, 'income': 2222, 'generosity': 1875, 'inconvenience': 2225, 'motherinlaw': 2870, 'disgust': 1301, 'favourite': 1688, 'earnestly': 1461, 'daughterinlaw': 1106, 'eldest': 1496, 'counteract': 992, 'affectionate': 88, 'taught': 4456, 'encourage': 1524, 'affliction': 89, 'renew': 3789, 'wretchedness': 4966, 'consolation': 902, 'deeply': 1150, 'sisterinlaw': 4117, 'mistress': 2813, 'civility': 712, 'accommodate': 34, 'invitation': 2303, 'harry': 2030, 'annuity': 185, 'clog': 737, 'payment': 3265, 'amaze': 153, 'spend': 4238, 'engagement': 1534, 'acceptable': 31, 'belongs': 403, 'disinclination': 1303, 'suitable': 4379, 'prudence': 3612, 'rely': 3775, 'politeness': 3427, 'maternal': 2691, 'intimacy': 2292, 'doctrine': 1355, 'elinors': 1504, 'comprehension': 839, 'recommend': 3739, 'blessing': 458, 'seriously': 4012, 'mamma': 2636, 'admires': 70, 'drawing': 1403, 'mama': 2635, 'indifference': 2235, 'excellence': 1598, 'mutual': 2919, 'mariannes': 2662, 'conjecture': 880, 'doubtful': 1382, 'encouragement': 1525, 'preference': 3501, 'dejection': 1166, 'indulgence': 2239, 'removal': 3786, 'contain': 919, 'proposal': 3590, 'parish': 3221, 'anxious': 197, 'deliberation': 1171, 'recommendation': 3740, 'continue': 931, 'guest': 1991, 'approbation': 223, 'moderate': 2822, 'dispatch': 1312, 'soninlaw': 4201, 'explanation': 1624, 'hence': 2077, 'pianoforte': 3338, 'prepare': 3508, 'preserve': 3516, 'defer': 1157, 'discourse': 1294, 'unpleasant': 4727, 'wooded': 4941, 'pasture': 3250, 'defective': 1155, 'shutter': 4080, 'elegance': 1498, 'widen': 4895, 'beforehand': 390, 'saving': 3933, 'perseverance': 3304, 'wellbred': 4854, 'commonplace': 806, 'recur': 3746, 'outward': 3152, 'unconnected': 4704, 'breeding': 523, 'pique': 3367, 'ham': 2010, 'mayflower': 2700, 'pilgrim': 3352, 'sorely': 4206, 'adorn': 75, 'standish': 4273, 'petition': 3319, 'brewster': 524, 'etc': 1567, 'duxbury': 1450, 'plymouth': 3406, 'mantle': 2651, 'fatal': 1681, 'disease': 1299, 'memorial': 2730, 'detain': 1225, 'bradford': 506, 'priscilla': 3543, 'alden': 120, 'myles': 2920, 'shone': 4059, 'oldhame': 3098, 'lyford': 2608, 'colony': 780, 'nigh': 2994, 'idler': 2179, 'dame': 1080, 'tendance': 4473, 'writ': 4968, 'governor': 1931, 'growth': 1986, 'crop': 1040, 'convert': 950, 'ordination': 3128, 'liberalminded': 2496, 'nile': 2998, 'sustain': 4417, 'plantation': 3382, 'manly': 2645, 'instruction': 2272, 'transfer': 4620, 'treason': 4633, 'council': 987, 'winslow': 4916, 'witness': 4932, 'merrily': 2748, 'ferret': 1710, 'madden': 2613, 'preach': 3485, 'communion': 811, 'fellowship': 1704, 'appeal': 211, 'exaggerated': 1589, 'occupant': 3071, 'liberty': 2497, 'borne': 489, 'anne': 181, 'daunt': 1107, 'sundry': 4388, 'lighter': 2512, 'heartily': 2056, 'coney': 861, 'docket': 1353, 'scholarly': 3951, 'sadness': 3901, 'notably': 3028, 'hick': 2084, 'plead': 3394, 'criticize': 1036, 'docile': 1352, 'theme': 4499, 'benevolent': 410, 'defensive': 1156, 'comedy': 789, 'transform': 4621, 'duff': 1438, 'soothe': 4204, 'irritated': 2312, 'deed': 1145, 'discus': 1297, 'are': 237, 'unite': 4717, 'downright': 1386, 'esher': 1558, 'counting': 994, 'hopeful': 2126, 'powder': 3471, 'native': 2944, 'argumentative': 241, 'shuffle': 4078, 'lucie': 2591, 'austin': 314, 'parent': 3218, 'province': 3608, 'jurisprudence': 2352, 'taylor': 4457, 'james': 2324, 'jeremy': 2330, 'bentham': 413, 'philosophy': 3330, 'coachhouse': 756, 'niebuhr': 2991, 'grote': 1979, 'forbid': 1782, 'arithmetic': 246, 'sadly': 3900, 'scheme': 3949, 'sympathetic': 4434, 'boulogne': 498, 'heinrich': 2070, 'heine': 2069, 'climate': 732, 'desultory': 1222, 'confirm': 871, 'monteagle': 2845, 'radical': 3674, 'alexander': 123, 'lansdowne': 2436, 'characteristic': 661, 'norton': 3024, 'kinglake': 2386, 'ranke': 3694, 'italian': 2320, 'translation': 4624, 'memoir': 2727, 'sketch': 4129, 'lent': 2485, 'illness': 2185, 'hassan': 2033, 'janet': 2326, 'nubian': 3040, 'originally': 3133, 'pious': 3364, 'shrink': 4074, 'omit': 3103, 'refuge': 3757, 'prince': 3537, 'bridge': 527, 'philip': 3327, 'politics': 3429, 'toast': 4562, 'precinct': 3487, 'alick': 126, 'contribution': 940, 'incessant': 2216, 'exclaim': 1608, 'monograph': 2840, 'mattress': 2696, 'painter': 3187, 'cape': 602, 'autumn': 318, '1862': 2, 'arrest': 260, 'mourn': 2879, 'million': 2783, 'lament': 2420, 'nobly': 3006, 'exile': 1615, 'superiority': 4395, 'thebe': 4496, 'eastern': 1469, 'kindliness': 2380, 'government': 1930, 'sits': 4119, 'reed': 3751, 'luxor': 2605, 'poorest': 3438, 'fellah': 1701, 'omar': 3100, 'consulgeneral': 915, 'prophecy': 3587, 'princess': 3538, 'dragoman': 1395, 'children': 688, 'esneh': 1559, 'everyone': 1579, 'lamb': 2418, 'kinder': 2379, 'thank': 4490, 'seed': 3984, 'pretension': 3525, 'narrowness': 2939, 'dissent': 1324, 'cairo': 584, '11': 1, 'hekekian': 2072, 'bey': 423, 'armenian': 251, 'viceconsul': 4780, 'sakna': 3909, 'levantine': 2490, 'fantasia': 1666, 'nurreddin': 3044, 'jewel': 2331, '25': 6, 'achmet': 47, 'consular': 914, 'coptic': 964, 'copt': 963, 'thrill': 4531, 'improvised': 2212, 'ie': 2180, 'bedaween': 384, 'bazaar': 370, 'cup': 1057, 'kettle': 2370, 'donkey': 1370, 'proceeding': 3558, 'mosque': 2866, 'touloun': 4597, 'lacework': 2410, 'brick': 525, 'cookingplace': 959, 'cake': 585, 'biscuit': 437, 'piastre': 3339, 'salaam': 3910, 'turk': 4679, 'pillar': 3353, 'mohammed': 2828, 'memlooks': 2726, 'divert': 1346, 'sitti': 4120, 'compensation': 826, 'queer': 3656, 'mohammad': 2827, 'everyday': 1578, 'quickness': 3662, 'senior': 3995, 'muchtalkedof': 2888, 'feshn': 1711, 'assouan': 286, 'prays': 3484, 'poultice': 3466, 'kiethelhairack': 2375, 'khateer': 2373, 'weled': 4852, 'clever': 728, 'pug': 3619, 'mortar': 2862, 'osman': 3138, 'anyone': 201, 'contrives': 943, 'costume': 978, 'par': 3210, 'effective': 1486, 'muslim': 2912, 'pasha': 3239, 'bibbeh': 426, 'girgis': 1895, 'hareem': 2025, 'describe': 1200, 'dome': 1367, 'panel': 3202, 'conceals': 846, 'holy': 2116, 'mason': 2680, 'mussulman': 2913, 'sheykh': 4048, 'pastoral': 3249, 'sheyk': 4047, 'symptom': 4437, 'elevation': 1501, 'picturesque': 3344, 'palmtrees': 3196, 'villager': 4787, 'nominal': 3012, 'cloak': 734, 'andrasool': 172, 'function': 1848, 'transparent': 4625, 'siout': 4113, 'december': 1132, 'minieh': 2790, 'district': 1339, 'dreadfully': 1408, 'wassef': 4827, 'deface': 1151, 'koran': 2401, 'nun': 3043, 'tropic': 4656, 'lending': 2482, 'cage': 583, 'girgeh': 1894, 'egg': 1488, 'keneh': 2366, 'mecca': 2713, 'such': 4365, 'being': 397, 'weaver': 4844, 'edfou': 1479, 'philæ': 3331, 'nubia': 3039, 'northeast': 3022, 'sour': 4213, 'abou': 15, 'simbel': 4098, 'kalabshee': 2359, 'darweesh': 1099, 'preliminary': 3503, 'ramadan': 3686, 'parasite': 3213, 'ombo': 3101, 'necklace': 2962, 'museum': 2906, 'mustapha': 2915, 'code': 767, 'extravagance': 1637, 'hire': 2099, 'osiris': 3137, 'saddle': 3899, 'disobeyed': 1310, 'interruption': 2288, 'congratulation': 878, 'pencil': 3277, 'tragic': 4611, 'brooke': 540, 'provincial': 3609, 'impressiveness': 2209, 'paragraph': 3211, 'remarkably': 3779, 'celia': 642, 'aristocratic': 244, 'puritan': 3636, 'economy': 1476, 'mildly': 2776, 'dorothea': 1378, 'pascal': 3238, 'tipton': 4556, 'rash': 3703, 'martyrdom': 2674, 'incur': 2229, 'lausanne': 2454, 'grange': 1944, 'uncertain': 4698, 'suspicious': 4416, 'presumably': 3520, 'catholic': 633, 'laborer': 2405, 'whim': 4874, 'risk': 3854, 'conscientious': 886, 'chettam': 680, 'inwardly': 2307, 'baronet': 357, 'cadwallader': 582, 'rector': 3744, 'casaubon': 623, 'mortification': 2863, 'davy': 1109, 'oddity': 3079, 'triviality': 4654, 'farm': 1671, 'argue': 239, 'statement': 4281, 'liret': 2533, 'groom': 1977, 'protestant': 3601, 'core': 967, 'dodo': 1358, 'offensive': 3085, 'interpret': 2286, 'allege': 134, 'predominance': 3496, 'cleverness': 729, 'disliked': 1305, 'mole': 2830, 'curate': 1060, 'labyrinthine': 2409, 'mythical': 2925, 'formidable': 1798, 'greece': 1963, 'things': 4513, 'landholder': 2427, 'gravel': 1954, 'loneliness': 2559, 'rectory': 3745, 'lowick': 2589, 'bordering': 486, 'coil': 769, 'dissimulate': 1325, 'consciously': 888, 'mood': 2848, 'lime': 2521, 'pumpkin': 3627, 'vista': 4798, 'neighborhood': 2970, 'active': 55, 'stupidity': 4351, 'dispensation': 1314, 'embroidery': 1511, 'exhort': 1614, 'petty': 3321, 'cottages': 981, 'presumptuous': 3522, 'discern': 1287, 'oppression': 3119, 'lovegood': 2584, 'disappointed': 1283, 'wickedness': 4893, 'speculation': 4233, 'oftener': 3092, 'doings': 1363, 'tantripp': 4450, 'pinkandwhite': 3362, 'shaken': 4029, 'armchair': 249, 'absentminded': 21, 'freshitt': 1829, 'noose': 3019, 'bishop': 438, 'commonly': 805, 'fitness': 1741, 'preoccupation': 3506, 'preconceive': 3494, 'providentially': 3607, 'matrimonial': 2694, 'justly': 2357, 'definite': 1162, 'level': 2491, 'discontent': 1292, 'myself': 2921, 'cradle': 1015, 'stool': 4311, 'schoolmaster': 3954, 'ludicrous': 2595, 'sittingroom': 4121, 'pluck': 3403, 'metaphorically': 2757, 'parsonage': 3229, 'pony': 3433, 'phaeton': 3323, 'from': 1839, 'middlemarch': 2767, 'rampant': 3688, 'area': 238, 'lens': 2484, 'exact': 1586, 'disown': 1311, 'irritation': 2313, 'bough': 496, 'agreeably': 107, 'hindrance': 2096, 'courtship': 1005, 'fatigue': 1684, 'submissive': 4357, 'tune': 4677, 'deanery': 1124, 'passive': 3246, 'culpable': 1052, 'grassy': 1949, 'incumbent': 2228, 'gradually': 1939, 'male': 2631, 'avenue': 319, 'deafness': 1120, 'calf': 588, 'border': 485, 'tucker': 4672, 'lightbrown': 2510, 'parishioner': 3222, 'cottager': 980, 'ladislaw': 2414, 'dubious': 1433, 'dinnerparty': 1270, 'manufacturer': 2653, 'banker': 350, 'professional': 3567, 'vincy': 4789, 'practitioner': 3477, 'lydgate': 2607, 'nonsense': 3016, 'keenly': 2363, 'silas': 4091, 'marner': 2666, 'raveloe': 3709, 'culture': 1055, 'lass': 2442, 'jem': 2329, 'ca': 577, 'incredible': 2227, 'parson': 3228, 'herb': 2079, 'oates': 3051, 'tarley': 4453, 'lantern': 2437, 'prayermeeting': 3482, 'pathway': 3255, 'dane': 1085, 'longing': 2564, 'perception': 3285, 'prayermeetings': 3483, 'widower': 4898, 'solemnly': 4187, 'pocketknife': 3411, 'mute': 2917, 'declares': 1141, 'cruelly': 1046, 'hedgerow': 2065, 'pew': 3322, 'occult': 3070, 'osgood': 3136, 'prompting': 3579, 'guinea': 1994, 'countless': 996, 'aloof': 142, 'shrunk': 4076, 'knot': 2398, 'transient': 4622, 'outlay': 3148, 'hoard': 2106, 'coin': 770, 'monotony': 2842, 'brownish': 545, 'plentifully': 3399, 'ale': 121, 'porkpie': 3444, 'dunsey': 1444, 'godfrey': 1918, 'nancy': 2934, 'lammeter': 2422, 'distrain': 1336, 'molly': 2831, 'drunken': 1430, 'ud': 4692, 'drain': 1397, 'floss': 1759, 'laden': 2413, 'ogg': 3093, 'willow': 4906, 'dorlcote': 1376, 'croft': 1038, 'wagoner': 4809, 'oven': 3155, 'remonstrance': 3784, 'playfellow': 3389, 'tulliver': 4675, 'lefthand': 2476, 'eddication': 1478, 'midsummer': 2771, 'th': 4489, 'wi': 4891, 'arbitration': 232, 'riley': 3848, 'glegg': 1905, 'bessy': 418, 'allays': 133, 'summat': 4382, 'niver': 3002, 'mudport': 2891, 'wench': 4856, 'un': 4695, 'cute': 1076, 'pinafore': 3358, 'ull': 4694, 'gell': 1871, 'lucy': 2594, 'deane': 1123, 'maggie': 2617, 'brandyandwater': 511, 'puzzlin': 3648, 'stelling': 4295, 'mislead': 2806, 'oxford': 3172, 'aroma': 254, 'timpson': 4552, 'dispense': 1315, 'naughty': 2949, 'pullet': 3621, 'attic': 306, 'fetish': 1713, 'yap': 4976, 'luke': 2596, 'mastiff': 2685, 'physiognomy': 3337, 'worm': 4951, 'peremptory': 3287, 'mischievous': 2802, 'dodson': 1359, 'dodsons': 1360, 'bob': 476, 'bat': 366, 'lors': 2573, 'holmes': 2115, 'obviously': 3066, 'deduction': 1144, 'tophat': 4582, 'cigarette': 705, 'crime': 1031, 'client': 730, 'briony': 534, 'preposterous': 3510, 'ostler': 3139, 'adler': 66, 'photograph': 3332, 'cab': 578, 'monica': 2838, 'landau': 2426, 'altar': 147, 'irene': 2308, 'sherlock': 4045, 'guardsman': 1989, 'lounger': 2581, 'endeavour': 1528, 'redheaded': 3749, 'presentation': 3513, 'mortimer': 2864, 'unambitious': 4697, '1882': 3, 'devon': 1233, 'comparative': 818, 'justified': 2355, 'expert': 1622, 'baskerville': 364, 'overtake': 3165, 'hugo': 2153, 'commend': 799, 'reveller': 3831, 'moorland': 2853, 'craze': 1021, 'inquest': 2260, 'barrymore': 360, 'corroborate': 976, 'moorgate': 2852, 'coroner': 970, 'stamford': 4269, 'laboratory': 2404, 'test': 4486}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_vect.vocabulary_['crime']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9S5h4vZnq6H",
        "outputId": "5d5d1664-835b-416d-8102-8a21caed06cc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1031"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "h2wb9TqQuYZE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f29c52bd-9993-4ab7-a31a-b8e1eaa92b31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.80      0.83        30\n",
            "           1       0.83      0.87      0.85        39\n",
            "           2       0.70      0.74      0.72        31\n",
            "           3       0.83      0.95      0.89        65\n",
            "           4       0.93      0.87      0.90        46\n",
            "           5       0.76      0.71      0.73        48\n",
            "           6       0.89      0.76      0.82        41\n",
            "\n",
            "    accuracy                           0.83       300\n",
            "   macro avg       0.83      0.81      0.82       300\n",
            "weighted avg       0.83      0.83      0.83       300\n",
            "\n",
            "[[24  1  4  0  0  1  0]\n",
            " [ 1 34  0  3  1  0  0]\n",
            " [ 1  1 23  1  0  5  0]\n",
            " [ 0  2  0 62  0  1  0]\n",
            " [ 1  0  0  2 40  0  3]\n",
            " [ 1  1  5  5  1 34  1]\n",
            " [ 0  2  1  2  1  4 31]]\n",
            "Accuracy: 0.8266666666666667\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "\n",
        "\n",
        "#create an instance of the model\n",
        "lr_model = LogisticRegression(random_state=7, C=1, max_iter = 500) #pomalo C se poloshi, pogolemo isto poloshi\n",
        "#train the model\n",
        "lr_model.fit(trainX_vec, trainY)\n",
        "\n",
        "#predict test data\n",
        "pred_test = lr_model.predict(testX_vec)\n",
        "\n",
        "#print evaluation metrics \n",
        "print(classification_report(testY,pred_test))\n",
        "print(confusion_matrix(testY,pred_test))\n",
        "print(\"Accuracy:\", accuracy_score(testY, pred_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4KSr1-hn4aY"
      },
      "source": [
        "### Вториот модел - не процесиран текст"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "TxSTEdkbx9sZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8441a502-7177-49cd-8836-f030f84cce3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(699, 300, 699, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "trainX_1, testX_1, trainY_1, testY_1 = train_test_split(\n",
        "    text_preprocessed_1, label, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "len(trainX), len(testX), len(trainY), len(testY)\n",
        "\n",
        "\n",
        "len(trainX_1), len(testX_1) ,len(trainY_1), len(testY_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "WO-aOegA1S4k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee78b66b-423a-415b-f9d4-8d330924131c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "trainY_1= le.fit_transform(trainY_1)\n",
        "testY_1 = le.fit_transform(testY_1)\n",
        "trainY_1.shape,testY_1.shape\n",
        "trainY_1[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "CT0m5SOw1sOL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbf88798-864c-4e96-adf6-556a317f565a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 5000)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "count_vect_1 = CountVectorizer(max_features=5000)\n",
        "count_vect_1.fit(text_preprocessed_1)\n",
        "\n",
        "# transform the training and test data using count vectorizer object\n",
        "trainX_1_vec = count_vect.transform(trainX_1)\n",
        "testX_1_vec = count_vect.transform(testX_1)\n",
        "trainX_1_vec.shape,\n",
        "testX_1_vec.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "T1bUVcdYo-iF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbbf2a36-941c-43f6-ed89-a8ff64199ddb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.87      0.84        30\n",
            "           1       0.76      0.90      0.82        39\n",
            "           2       0.76      0.71      0.73        31\n",
            "           3       0.81      0.94      0.87        65\n",
            "           4       0.83      0.76      0.80        46\n",
            "           5       0.85      0.73      0.79        48\n",
            "           6       0.77      0.66      0.71        41\n",
            "\n",
            "    accuracy                           0.80       300\n",
            "   macro avg       0.80      0.79      0.79       300\n",
            "weighted avg       0.80      0.80      0.80       300\n",
            "\n",
            "[[26  1  1  1  1  0  0]\n",
            " [ 1 35  0  0  2  0  1]\n",
            " [ 2  1 22  1  1  3  1]\n",
            " [ 0  2  0 61  1  1  0]\n",
            " [ 2  2  0  2 35  0  5]\n",
            " [ 0  2  4  6  0 35  1]\n",
            " [ 1  3  2  4  2  2 27]]\n",
            "Accuracy: 0.8033333333333333\n"
          ]
        }
      ],
      "source": [
        "lr_model_1 = LogisticRegression(random_state=0, C=100, max_iter=1000) #so ponisko C, polosha preciznost\n",
        "lr_model_1.fit(trainX_1_vec, trainY_1)\n",
        "\n",
        "pred_test_1 = lr_model_1.predict(testX_1_vec)\n",
        "\n",
        "#print evaluation metrics \n",
        "print(classification_report(testY_1,pred_test_1))\n",
        "print(confusion_matrix(testY_1,pred_test_1))\n",
        "print(\"Accuracy:\",accuracy_score(testY_1, pred_test_1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mYdUrcYmS5wt"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "IDLweyMdqpwX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5085b34-5141-4093-8331-a1c997bfcc08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((699, 5000), (300, 5000))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(max_features=5000, stop_words={\"english\"}, ngram_range=(1, 3)) \n",
        "tfidf.fit(text)\n",
        "\n",
        "X_train_tfidf = tfidf.transform(trainX)\n",
        "X_test_tfidf = tfidf.transform(testX)\n",
        "\n",
        "X_train_tfidf.shape, X_test_tfidf.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "RfPZHh8lxw1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c50b675d-21f8-47fc-a90c-0d9458fb4932"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.73      0.83        30\n",
            "           1       0.82      0.92      0.87        39\n",
            "           2       0.75      0.77      0.76        31\n",
            "           3       0.91      0.98      0.95        65\n",
            "           4       0.93      0.91      0.92        46\n",
            "           5       0.89      0.85      0.87        48\n",
            "           6       0.85      0.83      0.84        41\n",
            "\n",
            "    accuracy                           0.88       300\n",
            "   macro avg       0.87      0.86      0.86       300\n",
            "weighted avg       0.88      0.88      0.88       300\n",
            "\n",
            "[[22  2  3  2  0  1  0]\n",
            " [ 0 36  0  0  1  0  2]\n",
            " [ 1  1 24  1  0  3  1]\n",
            " [ 0  1  0 64  0  0  0]\n",
            " [ 0  0  0  1 42  0  3]\n",
            " [ 0  1  3  2  1 41  0]\n",
            " [ 0  3  2  0  1  1 34]]\n",
            "Accuracy: 0.8766666666666667\n"
          ]
        }
      ],
      "source": [
        "lr_model_tf = LogisticRegression(random_state=0, C=10, max_iter=1000)\n",
        "lr_model_tf.fit(X_train_tfidf, trainY)\n",
        "pred_test_tf = lr_model_tf.predict(X_test_tfidf)\n",
        "\n",
        "#print evaluation metrics \n",
        "print(classification_report(testY,pred_test_tf))\n",
        "print(confusion_matrix(testY,pred_test_tf))\n",
        "print(\"Accuracy:\",accuracy_score(testY, pred_test_tf))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Multinomial NB"
      ],
      "metadata": {
        "id": "lnJbRVRMEyLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "metadata": {
        "id": "xPGjahKHE2sS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb = MultinomialNB(alpha=0.01)\n",
        "nb.fit(X_train_tfidf, trainY)\n",
        "pred_test_nb = nb.predict(X_test_tfidf)\n",
        "\n",
        "#print evaluation metrics \n",
        "print(classification_report(testY,pred_test_nb))\n",
        "print(confusion_matrix(testY,pred_test_nb))\n",
        "print(\"Accuracy:\",accuracy_score(testY, pred_test_nb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBLDOoiqFTab",
        "outputId": "871a5fbe-b662-4e47-ccfe-224f1e60fd45"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.53      0.70        30\n",
            "           1       0.85      0.90      0.88        39\n",
            "           2       0.88      0.71      0.79        31\n",
            "           3       0.74      0.97      0.84        65\n",
            "           4       0.98      0.91      0.94        46\n",
            "           5       0.75      0.81      0.78        48\n",
            "           6       0.84      0.78      0.81        41\n",
            "\n",
            "    accuracy                           0.83       300\n",
            "   macro avg       0.86      0.80      0.82       300\n",
            "weighted avg       0.85      0.83      0.83       300\n",
            "\n",
            "[[16  3  2  6  0  2  1]\n",
            " [ 0 35  0  1  0  0  3]\n",
            " [ 0  1 22  3  1  4  0]\n",
            " [ 0  1  1 63  0  0  0]\n",
            " [ 0  0  0  1 42  2  1]\n",
            " [ 0  1  0  7  0 39  1]\n",
            " [ 0  0  0  4  0  5 32]]\n",
            "Accuracy: 0.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVM classifier"
      ],
      "metadata": {
        "id": "JHBIdX8qHDYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "svm_model = svm.SVC(kernel='linear', probability=True, C=10, gamma=0.1)\n",
        "svm_model.fit(trainX_vec, trainY)\n",
        "\n",
        "pred_test_svm = svm_model.predict(testX_vec)\n",
        "print(classification_report(testY,pred_test_svm))\n",
        "print(confusion_matrix(testY,pred_test_svm))\n",
        "print(\"Accuracy:\", accuracy_score(testY, pred_test_svm))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7esh_FXJRJR",
        "outputId": "4dd7053a-1ac4-4c0e-80cf-164425900af1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.73      0.77        30\n",
            "           1       0.74      0.87      0.80        39\n",
            "           2       0.70      0.74      0.72        31\n",
            "           3       0.84      0.88      0.86        65\n",
            "           4       0.93      0.80      0.86        46\n",
            "           5       0.63      0.71      0.67        48\n",
            "           6       0.91      0.71      0.79        41\n",
            "\n",
            "    accuracy                           0.79       300\n",
            "   macro avg       0.79      0.78      0.78       300\n",
            "weighted avg       0.80      0.79      0.79       300\n",
            "\n",
            "[[22  1  2  0  0  5  0]\n",
            " [ 1 34  1  2  1  0  0]\n",
            " [ 1  1 23  1  0  5  0]\n",
            " [ 0  3  1 57  0  3  1]\n",
            " [ 1  2  0  2 37  3  1]\n",
            " [ 2  3  3  4  1 34  1]\n",
            " [ 0  2  3  2  1  4 29]]\n",
            "Accuracy: 0.7866666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "X9YKtB8-pXid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c70397c1-dc72-4ec8-8330-072101032393"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99\n",
            "Now she had got a start, and she went on and told me all about the good\r\n",
            "place. She said all a body would have to do there was to go around all\r\n",
            "day long with a harp and sing, forever and ever. So I didn't think\r\n",
            "much of it. But I never said so. I asked her if she reckoned Tom Sawyer\r\n",
            "would go there, and she said not by a considerable sight. I was glad\r\n",
            "about that, because I wanted him and me to be together.\n"
          ]
        }
      ],
      "source": [
        "words= nltk.word_tokenize(text[2])\n",
        "length= len(words) \n",
        "print(length) \n",
        "print(text[2]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "-bX8a2DtpXid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11992b63-6ee8-486a-f5c1-15122fd02e32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "“Yo' ole father doan' know yit what he's a-gwyne to do. Sometimes he\r\n",
            "spec he'll go 'way, en den agin he spec he'll stay. De bes' way is to\r\n",
            "res' easy en let de ole man take his own way. Dey's two angels hoverin'\r\n",
            "roun' 'bout him. One uv 'em is white en shiny, en t'other one is black.\r\n",
            "De white one gits him to go right a little while, den de black one sail\r\n",
            "in en bust it all up. A body can't tell yit which one gwyne to fetch\r\n",
            "him at de las'. But you is all right. You gwyne to have considable\r\n",
            "trouble in yo' life, en considable joy. Sometimes you gwyne to git\r\n",
            "hurt, en sometimes you gwyne to git sick; but every time you's gwyne\r\n",
            "to git well agin. Dey's two gals flyin' 'bout you in yo' life. One\r\n",
            "uv 'em's light en t'other one is dark. One is rich en t'other is po'.\r\n",
            "You's gwyne to marry de po' one fust en de rich one by en by. You\r\n",
            "wants to keep 'way fum de water as much as you kin, en don't run no\r\n",
            "resk, 'kase it's down in de bills dat you's gwyne to git hung.”\n",
            "15\n"
          ]
        }
      ],
      "source": [
        "paragraph = text[25]\n",
        "sentences = nltk.sent_tokenize(paragraph) \n",
        "length= len(sentences) \n",
        "print(text[25]) \n",
        "print(length) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "HzUSRQfOZylr"
      },
      "outputs": [],
      "source": [
        "# # embeddings \n",
        "# from gensim.models.word2vec import Word2Vec\n",
        "# from gensim.models import Phrases\n",
        "\n",
        "# bigramer = Phrases(sentences)\n",
        "# model = Word2Vec(bigramer[sentences], window=5, min_count=10, workers=4)\n",
        "\n",
        "# # unload memory\n",
        "# model.init_sims(replace=True) \n",
        "\n",
        "# # Storing a model\n",
        "# model.save(\"author\")\n",
        "# # new_model = gensim.models.Word2Vec.load('author')\n",
        "\n",
        "# # Switch to KeyedVectors instance  \n",
        "# # w2v = {w: vec for w,vec in text_preprocessed}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "dvXe3ijQehQm"
      },
      "outputs": [],
      "source": [
        "# model.most_similar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "nae2IGVjicsO"
      },
      "outputs": [],
      "source": [
        "class EmbeddingVectorizer(object):\n",
        "    # If word2vec were passed in during initialization, use those\n",
        "    def __init__(self, word2vec):\n",
        "        self.word2vec = word2vec\n",
        "        self.word2weight = None\n",
        "        self.dim = 100\n",
        "    \n",
        "    # learning word2weight\n",
        "    def fit(self, X, y):\n",
        "        vect = TfidfVectorizer(min_df=5, ngram_range=(1,3))\n",
        "        vect.fit(X)\n",
        "        max_idf = max(vect.idf_)\n",
        "        self.word2weight = defaultdict(\n",
        "        lambda: max_idf, [(w, vect.idf_[i]) for w, i in vect.vocabulary_.items()]\n",
        "        )\n",
        "        return self\n",
        "    \n",
        "    # Use learned word2weight\n",
        "    def transform(self, X):\n",
        "        return np.array([\n",
        "            np.mean([\n",
        "                self.word2vec[w]*self.word2weight[w] \n",
        "                for w in words if w in self.word2vec] or \n",
        "                [np.zeros(self.dim)], axis=0) \n",
        "            for words in X\n",
        "        ])\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "8QH12lzY_W_Z"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer #similar to the CountVectorizer and TfIDF from sci-kit\n",
        "\n",
        "#The word embedding layer expects input sequences to be comprised of integers.\n",
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "tokenizer.fit_on_texts(text_preprocessed)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(text_preprocessed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Y3ES4MU5_0jI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "124872f1-5732-4682-fa2f-d7e91598fce6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'’': 1,\n",
              " '“': 2,\n",
              " '”': 3,\n",
              " 'say': 4,\n",
              " 'would': 5,\n",
              " 'one': 6,\n",
              " 'go': 7,\n",
              " 'mr': 8,\n",
              " 'make': 9,\n",
              " 'man': 10,\n",
              " 'could': 11,\n",
              " 'like': 12,\n",
              " 'come': 13,\n",
              " 'take': 14,\n",
              " 'time': 15,\n",
              " 'get': 16,\n",
              " 'see': 17,\n",
              " 'upon': 18,\n",
              " 'little': 19,\n",
              " 'know': 20,\n",
              " 'look': 21,\n",
              " 'well': 22,\n",
              " 'great': 23,\n",
              " 'hand': 24,\n",
              " 'good': 25,\n",
              " 'give': 26,\n",
              " 'much': 27,\n",
              " 'thing': 28,\n",
              " 'seem': 29,\n",
              " 'way': 30,\n",
              " 'old': 31,\n",
              " '‘': 32,\n",
              " 'might': 33,\n",
              " 'day': 34,\n",
              " 'never': 35,\n",
              " 'even': 36,\n",
              " 'two': 37,\n",
              " 'every': 38,\n",
              " 'eye': 39,\n",
              " 'men': 40,\n",
              " 'turn': 41,\n",
              " 'life': 42,\n",
              " 'head': 43,\n",
              " 'thought': 44,\n",
              " 'house': 45,\n",
              " 'sir': 46,\n",
              " 'back': 47,\n",
              " 'young': 48,\n",
              " 'people': 49,\n",
              " 'woman': 50,\n",
              " 'first': 51,\n",
              " 'work': 52,\n",
              " 'tom': 53,\n",
              " 'must': 54,\n",
              " 'think': 55,\n",
              " 'may': 56,\n",
              " 'mind': 57,\n",
              " 'always': 58,\n",
              " 'many': 59,\n",
              " 'call': 60,\n",
              " 'face': 61,\n",
              " 'saw': 62,\n",
              " 'away': 63,\n",
              " 'long': 64,\n",
              " 'though': 65,\n",
              " 'u': 66,\n",
              " 'last': 67,\n",
              " 'year': 68,\n",
              " 'without': 69,\n",
              " 'want': 70,\n",
              " 'nothing': 71,\n",
              " 'ever': 72,\n",
              " 'casaubon': 73,\n",
              " 'boy': 74,\n",
              " 'night': 75,\n",
              " 'put': 76,\n",
              " 'place': 77,\n",
              " 'world': 78,\n",
              " 'yet': 79,\n",
              " 'found': 80,\n",
              " 'lady': 81,\n",
              " 'knew': 82,\n",
              " 'right': 83,\n",
              " 'open': 84,\n",
              " 'friend': 85,\n",
              " 'enough': 86,\n",
              " 'three': 87,\n",
              " 'large': 88,\n",
              " 'still': 89,\n",
              " 'miss': 90,\n",
              " 'begin': 91,\n",
              " 'point': 92,\n",
              " 'small': 93,\n",
              " 'show': 94,\n",
              " 'mother': 95,\n",
              " 'joe': 96,\n",
              " 'soon': 97,\n",
              " 'tell': 98,\n",
              " 'light': 99,\n",
              " 'end': 100,\n",
              " 'side': 101,\n",
              " 'word': 102,\n",
              " 'far': 103,\n",
              " 'water': 104,\n",
              " 'fire': 105,\n",
              " 'another': 106,\n",
              " 'quite': 107,\n",
              " 'ask': 108,\n",
              " 'use': 109,\n",
              " 'keep': 110,\n",
              " 'home': 111,\n",
              " 'part': 112,\n",
              " 'new': 113,\n",
              " 'round': 114,\n",
              " 'family': 115,\n",
              " 'child': 116,\n",
              " 'left': 117,\n",
              " 'shall': 118,\n",
              " 'dorothea': 119,\n",
              " 'dog': 120,\n",
              " 'brooke': 121,\n",
              " 'along': 122,\n",
              " 'sort': 123,\n",
              " 'however': 124,\n",
              " 'letter': 125,\n",
              " 'sister': 126,\n",
              " 'feel': 127,\n",
              " 'heart': 128,\n",
              " 'set': 129,\n",
              " 'lay': 130,\n",
              " 'do': 131,\n",
              " 'black': 132,\n",
              " 'rather': 133,\n",
              " 'kind': 134,\n",
              " 'talk': 135,\n",
              " 'poor': 136,\n",
              " 'door': 137,\n",
              " 'among': 138,\n",
              " 'love': 139,\n",
              " 'heard': 140,\n",
              " 'let': 141,\n",
              " 'find': 142,\n",
              " 'whole': 143,\n",
              " 'till': 144,\n",
              " 'high': 145,\n",
              " 'moment': 146,\n",
              " 'become': 147,\n",
              " 'something': 148,\n",
              " 'felt': 149,\n",
              " 'close': 150,\n",
              " 'walk': 151,\n",
              " 'maggie': 152,\n",
              " 'mean': 153,\n",
              " 'anything': 154,\n",
              " 'money': 155,\n",
              " 'believe': 156,\n",
              " 'interest': 157,\n",
              " 'wish': 158,\n",
              " 'whose': 159,\n",
              " 'live': 160,\n",
              " 'stand': 161,\n",
              " 'present': 162,\n",
              " 'course': 163,\n",
              " 'foot': 164,\n",
              " 'body': 165,\n",
              " 'towards': 166,\n",
              " 'air': 167,\n",
              " 'try': 168,\n",
              " 'bad': 169,\n",
              " 'next': 170,\n",
              " 'learn': 171,\n",
              " 'form': 172,\n",
              " 'hour': 173,\n",
              " 'room': 174,\n",
              " 'nature': 175,\n",
              " 'around': 176,\n",
              " 'best': 177,\n",
              " 'father': 178,\n",
              " 'carry': 179,\n",
              " 'wife': 180,\n",
              " 'told': 181,\n",
              " 'rest': 182,\n",
              " 'name': 183,\n",
              " 'behind': 184,\n",
              " 'half': 185,\n",
              " 'gentleman': 186,\n",
              " 'reason': 187,\n",
              " 'dear': 188,\n",
              " 'book': 189,\n",
              " 'celia': 190,\n",
              " 'together': 191,\n",
              " 'run': 192,\n",
              " 'minute': 193,\n",
              " 'country': 194,\n",
              " 'less': 195,\n",
              " 'manner': 196,\n",
              " 'also': 197,\n",
              " 'cold': 198,\n",
              " 'white': 199,\n",
              " 'speak': 200,\n",
              " 'perhaps': 201,\n",
              " 'dark': 202,\n",
              " 'morning': 203,\n",
              " 'omar': 204,\n",
              " 'tulliver': 205,\n",
              " 'die': 206,\n",
              " 'near': 207,\n",
              " 'certain': 208,\n",
              " 'fact': 209,\n",
              " 'hair': 210,\n",
              " 'write': 211,\n",
              " 'fine': 212,\n",
              " 'read': 213,\n",
              " 'full': 214,\n",
              " 'within': 215,\n",
              " 'idea': 216,\n",
              " 'pretty': 217,\n",
              " 'sure': 218,\n",
              " 'short': 219,\n",
              " 'appear': 220,\n",
              " 'girl': 221,\n",
              " 'brought': 222,\n",
              " 'church': 223,\n",
              " 'everything': 224,\n",
              " 'order': 225,\n",
              " 'help': 226,\n",
              " 'step': 227,\n",
              " 'sat': 228,\n",
              " 'return': 229,\n",
              " 'often': 230,\n",
              " 'poe': 231,\n",
              " 'window': 232,\n",
              " 'since': 233,\n",
              " 'follow': 234,\n",
              " 'matter': 235,\n",
              " 'held': 236,\n",
              " 'leave': 237,\n",
              " 'really': 238,\n",
              " 'indeed': 239,\n",
              " 'stood': 240,\n",
              " 'cry': 241,\n",
              " 'death': 242,\n",
              " 'leg': 243,\n",
              " 'stop': 244,\n",
              " 'arm': 245,\n",
              " 'whether': 246,\n",
              " 'person': 247,\n",
              " 'wolf': 248,\n",
              " 'knowledge': 249,\n",
              " 'several': 250,\n",
              " 'didnt': 251,\n",
              " 'mouth': 252,\n",
              " 'rise': 253,\n",
              " 'move': 254,\n",
              " 'hope': 255,\n",
              " 'almost': 256,\n",
              " 'master': 257,\n",
              " 'table': 258,\n",
              " 'sound': 259,\n",
              " 'notice': 260,\n",
              " 'mention': 261,\n",
              " 'hold': 262,\n",
              " 'understand': 263,\n",
              " 'ran': 264,\n",
              " 'remember': 265,\n",
              " 'voice': 266,\n",
              " 'character': 267,\n",
              " 'dead': 268,\n",
              " 'six': 269,\n",
              " 'king': 270,\n",
              " 'opinion': 271,\n",
              " 'wind': 272,\n",
              " 'need': 273,\n",
              " 'town': 274,\n",
              " 'hear': 275,\n",
              " 'alone': 276,\n",
              " 'beautiful': 277,\n",
              " 'line': 278,\n",
              " 'across': 279,\n",
              " 'street': 280,\n",
              " 'age': 281,\n",
              " 'regard': 282,\n",
              " 'least': 283,\n",
              " 'case': 284,\n",
              " 'english': 285,\n",
              " 'james': 286,\n",
              " 'particular': 287,\n",
              " 'start': 288,\n",
              " 'thousand': 289,\n",
              " 'five': 290,\n",
              " 'cut': 291,\n",
              " 'hardly': 292,\n",
              " 'hundred': 293,\n",
              " 'low': 294,\n",
              " 'occasion': 295,\n",
              " 'hard': 296,\n",
              " 'change': 297,\n",
              " 'kept': 298,\n",
              " 'lose': 299,\n",
              " 'ground': 300,\n",
              " 'state': 301,\n",
              " 'dress': 302,\n",
              " 'attention': 303,\n",
              " 'doubt': 304,\n",
              " 'sit': 305,\n",
              " 'view': 306,\n",
              " 'expect': 307,\n",
              " 'judge': 308,\n",
              " 'son': 309,\n",
              " 'general': 310,\n",
              " 'thus': 311,\n",
              " 'enter': 312,\n",
              " 'mere': 313,\n",
              " 'object': 314,\n",
              " 'receive': 315,\n",
              " 'silas': 316,\n",
              " 'heavy': 317,\n",
              " 'four': 318,\n",
              " 'wall': 319,\n",
              " 'sometimes': 320,\n",
              " 'drop': 321,\n",
              " 'school': 322,\n",
              " 'reach': 323,\n",
              " 'business': 324,\n",
              " 'boat': 325,\n",
              " 'brother': 326,\n",
              " 'fear': 327,\n",
              " 'question': 328,\n",
              " 'suppose': 329,\n",
              " 'send': 330,\n",
              " 'certainly': 331,\n",
              " 'couldnt': 332,\n",
              " 'spirit': 333,\n",
              " 'stone': 334,\n",
              " 'beyond': 335,\n",
              " 'remain': 336,\n",
              " 'fellow': 337,\n",
              " 'john': 338,\n",
              " 'clear': 339,\n",
              " 'stick': 340,\n",
              " 'rush': 341,\n",
              " 'lie': 342,\n",
              " 'bit': 343,\n",
              " 'laugh': 344,\n",
              " 'strong': 345,\n",
              " 'lead': 346,\n",
              " 'true': 347,\n",
              " 'forward': 348,\n",
              " 'horse': 349,\n",
              " 'already': 350,\n",
              " 'sense': 351,\n",
              " 'sea': 352,\n",
              " 'handsome': 353,\n",
              " 'dashwood': 354,\n",
              " 'marner': 355,\n",
              " 'listen': 356,\n",
              " 'big': 357,\n",
              " 'touch': 358,\n",
              " 'none': 359,\n",
              " 'front': 360,\n",
              " 'save': 361,\n",
              " 'pass': 362,\n",
              " 'effect': 363,\n",
              " 'truth': 364,\n",
              " 'expression': 365,\n",
              " 'husband': 366,\n",
              " 'trouble': 367,\n",
              " 'shoulder': 368,\n",
              " 'sign': 369,\n",
              " 'fell': 370,\n",
              " 'sleep': 371,\n",
              " 'happen': 372,\n",
              " 'eat': 373,\n",
              " 'else': 374,\n",
              " 'others': 375,\n",
              " 'bring': 376,\n",
              " 'grow': 377,\n",
              " 'possible': 378,\n",
              " 'uncle': 379,\n",
              " 'real': 380,\n",
              " 'cause': 381,\n",
              " 'ear': 382,\n",
              " 'hill': 383,\n",
              " 'charm': 384,\n",
              " 'month': 385,\n",
              " 'daughter': 386,\n",
              " 'fall': 387,\n",
              " 'watch': 388,\n",
              " 'soul': 389,\n",
              " 'neither': 390,\n",
              " 'land': 391,\n",
              " 'picture': 392,\n",
              " 'remarkable': 393,\n",
              " 'holmes': 394,\n",
              " 'company': 395,\n",
              " 'deep': 396,\n",
              " 'either': 397,\n",
              " 'met': 398,\n",
              " 'creature': 399,\n",
              " 'visit': 400,\n",
              " 'glance': 401,\n",
              " 'altogether': 402,\n",
              " 'answer': 403,\n",
              " 'minister': 404,\n",
              " 'add': 405,\n",
              " 'marriage': 406,\n",
              " 'power': 407,\n",
              " 'sight': 408,\n",
              " 'ready': 409,\n",
              " 'account': 410,\n",
              " 'offer': 411,\n",
              " 'wore': 412,\n",
              " 'god': 413,\n",
              " 'red': 414,\n",
              " 'except': 415,\n",
              " 'desire': 416,\n",
              " 'buck': 417,\n",
              " 'warnt': 418,\n",
              " 'everybody': 419,\n",
              " 'wait': 420,\n",
              " 'laid': 421,\n",
              " 'nose': 422,\n",
              " 'play': 423,\n",
              " 'wonder': 424,\n",
              " 'river': 425,\n",
              " 'throw': 426,\n",
              " 'corner': 427,\n",
              " 'peculiar': 428,\n",
              " 'wood': 429,\n",
              " 'pay': 430,\n",
              " 'strange': 431,\n",
              " 'village': 432,\n",
              " 'pull': 433,\n",
              " 'secret': 434,\n",
              " 'raise': 435,\n",
              " 'quiet': 436,\n",
              " 'direction': 437,\n",
              " 'ye': 438,\n",
              " 'early': 439,\n",
              " 'smile': 440,\n",
              " 'story': 441,\n",
              " 'appearance': 442,\n",
              " 'habit': 443,\n",
              " 'subject': 444,\n",
              " 'longer': 445,\n",
              " 'easy': 446,\n",
              " 'clothes': 447,\n",
              " 'hat': 448,\n",
              " 'narrow': 449,\n",
              " 'sent': 450,\n",
              " 'color': 451,\n",
              " 'court': 452,\n",
              " 'blue': 453,\n",
              " 'lip': 454,\n",
              " 'sun': 455,\n",
              " 'england': 456,\n",
              " 'therefore': 457,\n",
              " 'pain': 458,\n",
              " 'care': 459,\n",
              " 'beauty': 460,\n",
              " 'piece': 461,\n",
              " 'tree': 462,\n",
              " 'servant': 463,\n",
              " 'act': 464,\n",
              " 'em': 465,\n",
              " 'week': 466,\n",
              " 'chance': 467,\n",
              " 'study': 468,\n",
              " 'suffer': 469,\n",
              " 'produce': 470,\n",
              " 'spoke': 471,\n",
              " 'although': 472,\n",
              " 'toward': 473,\n",
              " 'purpose': 474,\n",
              " 'bread': 475,\n",
              " 'observe': 476,\n",
              " 'past': 477,\n",
              " 'affection': 478,\n",
              " 'chettam': 479,\n",
              " 'wouldnt': 480,\n",
              " 'knee': 481,\n",
              " 'ten': 482,\n",
              " 'seat': 483,\n",
              " 'paper': 484,\n",
              " 'fair': 485,\n",
              " 'arab': 486,\n",
              " 'sword': 487,\n",
              " 'crowd': 488,\n",
              " 'besides': 489,\n",
              " 'pleasure': 490,\n",
              " 'circle': 491,\n",
              " 'settle': 492,\n",
              " 'consider': 493,\n",
              " 'draw': 494,\n",
              " 'dream': 495,\n",
              " 'darkness': 496,\n",
              " 'struggle': 497,\n",
              " 'relation': 498,\n",
              " 'usual': 499,\n",
              " 'genius': 500,\n",
              " 'wine': 501,\n",
              " 'taste': 502,\n",
              " 'bob': 503,\n",
              " 'widow': 504,\n",
              " 'watson': 505,\n",
              " 'cross': 506,\n",
              " 'instead': 507,\n",
              " 'nearly': 508,\n",
              " 'lean': 509,\n",
              " 'square': 510,\n",
              " 'rag': 511,\n",
              " 'weather': 512,\n",
              " 'fish': 513,\n",
              " 'presently': 514,\n",
              " 'passion': 515,\n",
              " 'happy': 516,\n",
              " 'finger': 517,\n",
              " 'length': 518,\n",
              " 'tale': 519,\n",
              " 'knight': 520,\n",
              " 'fortune': 521,\n",
              " 'arthur': 522,\n",
              " 'figure': 523,\n",
              " 'society': 524,\n",
              " 'search': 525,\n",
              " 'conversation': 526,\n",
              " 'promise': 527,\n",
              " 'able': 528,\n",
              " 'trust': 529,\n",
              " 'companion': 530,\n",
              " 'cadwallader': 531,\n",
              " 'riley': 532,\n",
              " 'kill': 533,\n",
              " 'kitchen': 534,\n",
              " 'neck': 535,\n",
              " 'mine': 536,\n",
              " 'afterwards': 537,\n",
              " 'marry': 538,\n",
              " 'stay': 539,\n",
              " 'roll': 540,\n",
              " 'cabin': 541,\n",
              " 'allow': 542,\n",
              " 'speech': 543,\n",
              " 'bright': 544,\n",
              " 'struck': 545,\n",
              " 'human': 546,\n",
              " 'action': 547,\n",
              " 'service': 548,\n",
              " 'presence': 549,\n",
              " 'difficulty': 550,\n",
              " 'various': 551,\n",
              " 'express': 552,\n",
              " 'secure': 553,\n",
              " 'especially': 554,\n",
              " 'fit': 555,\n",
              " 'lord': 556,\n",
              " 'norland': 557,\n",
              " 'anybody': 558,\n",
              " 'advantage': 559,\n",
              " 'seven': 560,\n",
              " 'different': 561,\n",
              " 'teeth': 562,\n",
              " 'whatever': 563,\n",
              " 'floor': 564,\n",
              " 'oh': 565,\n",
              " 'wonderful': 566,\n",
              " 'road': 567,\n",
              " 'wild': 568,\n",
              " 'position': 569,\n",
              " 'drew': 570,\n",
              " 'late': 571,\n",
              " 'second': 572,\n",
              " 'effort': 573,\n",
              " 'increase': 574,\n",
              " 'simple': 575,\n",
              " 'merely': 576,\n",
              " 'charles': 577,\n",
              " 'feature': 578,\n",
              " 'strength': 579,\n",
              " 'snarl': 580,\n",
              " 'deck': 581,\n",
              " 'cottage': 582,\n",
              " 'fetch': 583,\n",
              " 'star': 584,\n",
              " 'jim': 585,\n",
              " 'hung': 586,\n",
              " 'edge': 587,\n",
              " 'passage': 588,\n",
              " 'mark': 589,\n",
              " 'rich': 590,\n",
              " 'soldier': 591,\n",
              " 'worth': 592,\n",
              " 'warm': 593,\n",
              " 'dinner': 594,\n",
              " 'couple': 595,\n",
              " 'cover': 596,\n",
              " 'necessary': 597,\n",
              " 'confess': 598,\n",
              " 'launcelot': 599,\n",
              " 'hall': 600,\n",
              " 'shape': 601,\n",
              " 'respect': 602,\n",
              " 'reply': 603,\n",
              " 'pair': 604,\n",
              " 'address': 605,\n",
              " 'lift': 606,\n",
              " 'note': 607,\n",
              " 'satisfaction': 608,\n",
              " 'mill': 609,\n",
              " 'stretch': 610,\n",
              " 'reckon': 611,\n",
              " 'garden': 612,\n",
              " 'comfortable': 613,\n",
              " 'top': 614,\n",
              " 'mile': 615,\n",
              " 'broad': 616,\n",
              " 'blood': 617,\n",
              " 'snow': 618,\n",
              " 'hang': 619,\n",
              " 'natural': 620,\n",
              " 'free': 621,\n",
              " 'fast': 622,\n",
              " 'strike': 623,\n",
              " 'finally': 624,\n",
              " 'pocket': 625,\n",
              " 'gate': 626,\n",
              " 'captain': 627,\n",
              " 'pleasant': 628,\n",
              " 'term': 629,\n",
              " 'affair': 630,\n",
              " 'comfort': 631,\n",
              " 'mystery': 632,\n",
              " 'hunger': 633,\n",
              " 'entirely': 634,\n",
              " 'scene': 635,\n",
              " 'later': 636,\n",
              " 'ordinary': 637,\n",
              " 'history': 638,\n",
              " 'measure': 639,\n",
              " 'slowly': 640,\n",
              " 'latter': 641,\n",
              " 'party': 642,\n",
              " 'deal': 643,\n",
              " 'william': 644,\n",
              " 'gordon': 645,\n",
              " 'future': 646,\n",
              " 'london': 647,\n",
              " 'style': 648,\n",
              " 'health': 649,\n",
              " 'grey': 650,\n",
              " 'neighbour': 651,\n",
              " 'wopsle': 652,\n",
              " 'baskerville': 653,\n",
              " 'bed': 654,\n",
              " 'chair': 655,\n",
              " 'likely': 656,\n",
              " 'yard': 657,\n",
              " 'nobody': 658,\n",
              " 'fill': 659,\n",
              " 'pas': 660,\n",
              " 'law': 661,\n",
              " 'fog': 662,\n",
              " 'fresh': 663,\n",
              " 'green': 664,\n",
              " 'difficult': 665,\n",
              " 'shot': 666,\n",
              " 'memory': 667,\n",
              " 'pause': 668,\n",
              " 'circumstance': 669,\n",
              " 'press': 670,\n",
              " 'earth': 671,\n",
              " 'pride': 672,\n",
              " 'engage': 673,\n",
              " 'experience': 674,\n",
              " 'terror': 675,\n",
              " 'duty': 676,\n",
              " 'event': 677,\n",
              " 'suddenly': 678,\n",
              " 'complete': 679,\n",
              " 'perfect': 680,\n",
              " 'enjoy': 681,\n",
              " 'poem': 682,\n",
              " 'imagination': 683,\n",
              " 'impression': 684,\n",
              " 'elinor': 685,\n",
              " 'austin': 686,\n",
              " 'quality': 687,\n",
              " 'rode': 688,\n",
              " 'pap': 689,\n",
              " 'bank': 690,\n",
              " 'ill': 691,\n",
              " 'broke': 692,\n",
              " 'knife': 693,\n",
              " 'wrong': 694,\n",
              " 'sudden': 695,\n",
              " 'instant': 696,\n",
              " 'pound': 697,\n",
              " 'threw': 698,\n",
              " 'nine': 699,\n",
              " 'plan': 700,\n",
              " 'imagine': 701,\n",
              " 'deliver': 702,\n",
              " 'curl': 703,\n",
              " 'delight': 704,\n",
              " 'verse': 705,\n",
              " 'fashion': 706,\n",
              " 'animal': 707,\n",
              " 'arrive': 708,\n",
              " 'remark': 709,\n",
              " 'force': 710,\n",
              " 'honor': 711,\n",
              " 'sprang': 712,\n",
              " 'cease': 713,\n",
              " 'prefect': 714,\n",
              " 'furniture': 715,\n",
              " 'fail': 716,\n",
              " 'instance': 717,\n",
              " 'apart': 718,\n",
              " 'concern': 719,\n",
              " 'attempt': 720,\n",
              " 'sailor': 721,\n",
              " 'kindness': 722,\n",
              " 'leap': 723,\n",
              " 'pack': 724,\n",
              " 'passenger': 725,\n",
              " 'squire': 726,\n",
              " 'duff': 727,\n",
              " 'raveloe': 728,\n",
              " 'candle': 729,\n",
              " 'noise': 730,\n",
              " 'devil': 731,\n",
              " 'grand': 732,\n",
              " 'living': 733,\n",
              " 'de': 734,\n",
              " 'spring': 735,\n",
              " 'hunt': 736,\n",
              " 'terrible': 737,\n",
              " 'probably': 738,\n",
              " 'curiosity': 739,\n",
              " 'dare': 740,\n",
              " 'flower': 741,\n",
              " 'ago': 742,\n",
              " 'accord': 743,\n",
              " 'admiration': 744,\n",
              " 'depart': 745,\n",
              " 'spot': 746,\n",
              " 'sharp': 747,\n",
              " 'evil': 748,\n",
              " 'queen': 749,\n",
              " 'faith': 750,\n",
              " 'american': 751,\n",
              " 'match': 752,\n",
              " 'reflect': 753,\n",
              " 'wide': 754,\n",
              " 'shock': 755,\n",
              " 'determine': 756,\n",
              " 'fancy': 757,\n",
              " 'continued': 758,\n",
              " 'shout': 759,\n",
              " 'condition': 760,\n",
              " 'result': 761,\n",
              " 'immediately': 762,\n",
              " 'odd': 763,\n",
              " 'poet': 764,\n",
              " 'religious': 765,\n",
              " 'possess': 766,\n",
              " 'married': 767,\n",
              " 'join': 768,\n",
              " 'rope': 769,\n",
              " 'chest': 770,\n",
              " 'brown': 771,\n",
              " 'clergyman': 772,\n",
              " 'amiable': 773,\n",
              " 'edward': 774,\n",
              " 'clean': 775,\n",
              " 'leaf': 776,\n",
              " 'tie': 777,\n",
              " 'tear': 778,\n",
              " 'inside': 779,\n",
              " 'guard': 780,\n",
              " 'breakfast': 781,\n",
              " 'quick': 782,\n",
              " 'en': 783,\n",
              " 'hurt': 784,\n",
              " 'shut': 785,\n",
              " 'breath': 786,\n",
              " 'coat': 787,\n",
              " 'win': 788,\n",
              " 'bow': 789,\n",
              " 'language': 790,\n",
              " 'heel': 791,\n",
              " 'caught': 792,\n",
              " 'outside': 793,\n",
              " 'aunt': 794,\n",
              " 'suit': 795,\n",
              " 'conduct': 796,\n",
              " 'perfectly': 797,\n",
              " 'unto': 798,\n",
              " 'feeling': 799,\n",
              " 'pity': 800,\n",
              " 'success': 801,\n",
              " 'remove': 802,\n",
              " 'sunday': 803,\n",
              " 'equal': 804,\n",
              " 'bound': 805,\n",
              " 'require': 806,\n",
              " 'stroke': 807,\n",
              " 'kay': 808,\n",
              " 'art': 809,\n",
              " 'period': 810,\n",
              " 'intend': 811,\n",
              " 'interested': 812,\n",
              " 'situation': 813,\n",
              " 'pale': 814,\n",
              " 'accept': 815,\n",
              " 'heaven': 816,\n",
              " 'design': 817,\n",
              " 'd——': 818,\n",
              " 'surface': 819,\n",
              " 'principle': 820,\n",
              " 'meant': 821,\n",
              " 'opportunity': 822,\n",
              " 'intention': 823,\n",
              " 'tomb': 824,\n",
              " 'henry': 825,\n",
              " 'tall': 826,\n",
              " 'wi': 827,\n",
              " 'sing': 828,\n",
              " 'glad': 829,\n",
              " 'nigger': 830,\n",
              " 'shook': 831,\n",
              " 'clock': 832,\n",
              " 'stir': 833,\n",
              " 'spread': 834,\n",
              " 'sorry': 835,\n",
              " 'iron': 836,\n",
              " 'quarter': 837,\n",
              " 'fifty': 838,\n",
              " 'drove': 839,\n",
              " 'handle': 840,\n",
              " 'mud': 841,\n",
              " 'yes': 842,\n",
              " 'notion': 843,\n",
              " 'beg': 844,\n",
              " 'bore': 845,\n",
              " 'tongue': 846,\n",
              " 'discover': 847,\n",
              " 'music': 848,\n",
              " 'dread': 849,\n",
              " 'glass': 850,\n",
              " 'wise': 851,\n",
              " 'public': 852,\n",
              " 'conscience': 853,\n",
              " 'cloud': 854,\n",
              " 'german': 855,\n",
              " 'afraid': 856,\n",
              " 'forth': 857,\n",
              " 'grace': 858,\n",
              " 'doctor': 859,\n",
              " 'trace': 860,\n",
              " 'paid': 861,\n",
              " 'food': 862,\n",
              " 'occur': 863,\n",
              " 'common': 864,\n",
              " 'impossible': 865,\n",
              " 'dozen': 866,\n",
              " 'merlin': 867,\n",
              " 'dry': 868,\n",
              " 'escape': 869,\n",
              " 'ought': 870,\n",
              " 'seize': 871,\n",
              " 'plain': 872,\n",
              " 'aid': 873,\n",
              " 'private': 874,\n",
              " 'number': 875,\n",
              " 'weak': 876,\n",
              " 'author': 877,\n",
              " 'excellent': 878,\n",
              " 'break': 879,\n",
              " 'surprise': 880,\n",
              " 'member': 881,\n",
              " 'mist': 882,\n",
              " 'colour': 883,\n",
              " 'mistress': 884,\n",
              " 'lyford': 885,\n",
              " 'cairo': 886,\n",
              " 'smoke': 887,\n",
              " 'grave': 888,\n",
              " 'whenever': 889,\n",
              " 'throat': 890,\n",
              " 'bury': 891,\n",
              " 'lot': 892,\n",
              " 'difference': 893,\n",
              " 'key': 894,\n",
              " 'guess': 895,\n",
              " 'reader': 896,\n",
              " 'shake': 897,\n",
              " 'energy': 898,\n",
              " 'examine': 899,\n",
              " 'drive': 900,\n",
              " 'field': 901,\n",
              " 'prisoner': 902,\n",
              " 'nearer': 903,\n",
              " 'wander': 904,\n",
              " 'accustom': 905,\n",
              " 'stream': 906,\n",
              " 'gain': 907,\n",
              " 'system': 908,\n",
              " 'forget': 909,\n",
              " 'proceed': 910,\n",
              " 'adventure': 911,\n",
              " 'wheel': 912,\n",
              " 'apparently': 913,\n",
              " 'mail': 914,\n",
              " 'seek': 915,\n",
              " 'fly': 916,\n",
              " 'date': 917,\n",
              " 'travel': 918,\n",
              " 'today': 919,\n",
              " 'shadow': 920,\n",
              " 'sake': 921,\n",
              " 'sky': 922,\n",
              " 'clearly': 923,\n",
              " 'driven': 924,\n",
              " 'distance': 925,\n",
              " 'article': 926,\n",
              " 'example': 927,\n",
              " 'description': 928,\n",
              " 'volume': 929,\n",
              " 'finish': 930,\n",
              " 'medical': 931,\n",
              " 'suggest': 932,\n",
              " 'decide': 933,\n",
              " 'usually': 934,\n",
              " 'beneath': 935,\n",
              " 'perceive': 936,\n",
              " 'visitor': 937,\n",
              " 'vessel': 938,\n",
              " 'supply': 939,\n",
              " 'teach': 940,\n",
              " 'respectable': 941,\n",
              " 'dignity': 942,\n",
              " 'twice': 943,\n",
              " 'fond': 944,\n",
              " 'honour': 945,\n",
              " 'stelling': 946,\n",
              " 'straight': 947,\n",
              " 'considerable': 948,\n",
              " 'confidence': 949,\n",
              " 'damp': 950,\n",
              " 'belong': 951,\n",
              " 'pretend': 952,\n",
              " 'charge': 953,\n",
              " 'gun': 954,\n",
              " 'spite': 955,\n",
              " 'drink': 956,\n",
              " 'dreadful': 957,\n",
              " 'chin': 958,\n",
              " 'rattle': 959,\n",
              " 'judgment': 960,\n",
              " 'value': 961,\n",
              " 'summer': 962,\n",
              " 'ate': 963,\n",
              " 'cat': 964,\n",
              " 'existence': 965,\n",
              " 'repeat': 966,\n",
              " 'generally': 967,\n",
              " 'twenty': 968,\n",
              " 'march': 969,\n",
              " 'mary': 970,\n",
              " 'temper': 971,\n",
              " 'mental': 972,\n",
              " 'nay': 973,\n",
              " 'grass': 974,\n",
              " 'merit': 975,\n",
              " 'noble': 976,\n",
              " 'century': 977,\n",
              " 'immediate': 978,\n",
              " 'render': 979,\n",
              " 'single': 980,\n",
              " 'christian': 981,\n",
              " 'countenance': 982,\n",
              " 'ship': 983,\n",
              " 'convince': 984,\n",
              " 'aware': 985,\n",
              " 'degree': 986,\n",
              " 'amount': 987,\n",
              " 'push': 988,\n",
              " 'propose': 989,\n",
              " 'personage': 990,\n",
              " 'butter': 991,\n",
              " 'hotel': 992,\n",
              " 'building': 993,\n",
              " 'apply': 994,\n",
              " 'broken': 995,\n",
              " 'admit': 996,\n",
              " 'basket': 997,\n",
              " 'skin': 998,\n",
              " 'bottle': 999,\n",
              " 'talent': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "hTxuijiE_-yM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e16307b-b489-46ff-fddc-fdc05a6a49f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(699, 300, 699, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "sequences = np.array(sequences)\n",
        "\n",
        "trainX, testX, trainY, testY = train_test_split(\n",
        "    sequences, label, test_size=0.3, random_state=42)\n",
        "trainX = np.array(trainX)\n",
        "testX = np.array(testX)\n",
        "trainY = np.array(trainY)\n",
        "testY = np.array(testY)\n",
        "\n",
        "\n",
        "len(trainX), len(testX), len(trainY), len(testY)\n",
        "\n",
        "# trainX.shape, testX.shape, trainY.shape, testY.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "E3ykWyt8AQHn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "607d7b0f-2471-48fe-928d-6aa8fd7024be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(699, 100)\n",
            "(300, 100)\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_len = 100\n",
        "#transforms a list (of length num_samples) of sequences (lists of integers) \n",
        "#into a 2D Numpy array of shape (num_samples, num_timesteps) num_timesteps is the maxlen argument.\n",
        "\n",
        "train_X_pad = pad_sequences(trainX, maxlen = max_len, dtype='int32')\n",
        "test_X_pad = pad_sequences(testX, maxlen = max_len, dtype='int32')\n",
        "\n",
        "print(train_X_pad.shape)\n",
        "print(test_X_pad.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ePA_jmq1Ah-3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02678b51-f520-45ed-b246-6efd38042225"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11996"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "vocab_size\n",
        "#tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "luSRMsQ7AX-7"
      },
      "outputs": [],
      "source": [
        "# create the model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, LSTM, Dense\n",
        "\n",
        "def generate_model(vocab_size, max_len, embedding_size): #dropout):\n",
        "\n",
        "    _input = Input(max_len)\n",
        "\n",
        "    x = Embedding(input_dim = vocab_size, output_dim = embedding_size) (_input)\n",
        "\n",
        "    x = LSTM(50)(x)\n",
        "\n",
        "    output = Dense(7, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs= [_input], outputs = [output])  \n",
        "    #dropout = layers(Dropout(0.5))\n",
        "\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trainY\n",
        "#dropout sloj posle LSTM, moze da se smeni embedding size"
      ],
      "metadata": {
        "id": "RakgypQwtqr3"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "J3WapLTSAcxF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0631693f-ede7-47c6-ee75-b05bc1d84fd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 100)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 100, 80)           959680    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 50)                26200     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 7)                 357       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 986,237\n",
            "Trainable params: 986,237\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = generate_model(vocab_size , max_len , embedding_size=80) #dropout=dropout\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainX= np.array(trainX)\n",
        "trainY= np.array(trainY)\n",
        "testX= np.array(testX)\n",
        "testY= np.array(testY)"
      ],
      "metadata": {
        "id": "s3aWV_dmqeUw"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testY\n",
        "le = preprocessing.LabelEncoder()\n",
        "trainY= le.fit_transform(trainY)\n",
        "testY = le.fit_transform(testY)\n",
        "trainY.shape,testY.shape\n",
        "trainY[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMWWQ2IabD1W",
        "outputId": "cfdc8e21-59b9-4bc7-c7e6-799d2b261e7b"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "P9xrX7gwAmZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c1bb03e-5e0e-41e8-ed0c-32b51bfc6f02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "12/12 [==============================] - 6s 157ms/step - loss: 1.9389 - accuracy: 0.2303 - val_loss: 1.9324 - val_accuracy: 0.2200\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 1s 97ms/step - loss: 1.8873 - accuracy: 0.2446 - val_loss: 1.8950 - val_accuracy: 0.2167\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 1s 99ms/step - loss: 1.7435 - accuracy: 0.2518 - val_loss: 1.7655 - val_accuracy: 0.2300\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 1s 94ms/step - loss: 1.4894 - accuracy: 0.5179 - val_loss: 1.6528 - val_accuracy: 0.4100\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 1s 94ms/step - loss: 1.3233 - accuracy: 0.7353 - val_loss: 1.5853 - val_accuracy: 0.4600\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 1s 96ms/step - loss: 1.1004 - accuracy: 0.7639 - val_loss: 1.5597 - val_accuracy: 0.5333\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 1s 95ms/step - loss: 0.9788 - accuracy: 0.7811 - val_loss: 1.4527 - val_accuracy: 0.5500\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 1s 94ms/step - loss: 0.8229 - accuracy: 0.8798 - val_loss: 1.4343 - val_accuracy: 0.5567\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 1s 95ms/step - loss: 0.6934 - accuracy: 0.9056 - val_loss: 1.4449 - val_accuracy: 0.5967\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 1s 96ms/step - loss: 0.5192 - accuracy: 0.9428 - val_loss: 1.3749 - val_accuracy: 0.6200\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_X_pad, trainY, epochs=10, batch_size=60, validation_data=(test_X_pad, testY))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "wMmTww8hAqC0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea848c2d-0cd8-4672-c006-7bdb68e38079"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.17      0.27        30\n",
            "           1       0.43      0.67      0.52        39\n",
            "           2       0.64      0.45      0.53        31\n",
            "           3       0.82      0.69      0.75        65\n",
            "           4       0.70      0.67      0.69        46\n",
            "           5       0.46      0.73      0.56        48\n",
            "           6       0.86      0.73      0.79        41\n",
            "\n",
            "    accuracy                           0.62       300\n",
            "   macro avg       0.66      0.59      0.59       300\n",
            "weighted avg       0.67      0.62      0.62       300\n",
            "\n",
            "[[ 5 10  6  0  2  7  0]\n",
            " [ 0 26  1  1  5  4  2]\n",
            " [ 0  1 14  2  2 11  1]\n",
            " [ 0  5  0 45  0 15  0]\n",
            " [ 0  9  0  2 31  2  2]\n",
            " [ 2  5  0  3  3 35  0]\n",
            " [ 0  5  1  2  1  2 30]]\n",
            "Accuracy: 0.62\n"
          ]
        }
      ],
      "source": [
        "pred_test = model.predict(test_X_pad)\n",
        "pred_test = np.argmax(pred_test,axis=1)\n",
        "#pred_test = pred_test.round()\n",
        "\n",
        "#print evaluation metrics \n",
        "print(classification_report(testY,pred_test))\n",
        "print(confusion_matrix(testY,pred_test))\n",
        "print(\"Accuracy:\",accuracy_score(testY, pred_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = data['v2']\n",
        "label = data['v1']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test , y_train, y_test = train_test_split(text, label, test_size = 0.20)"
      ],
      "metadata": {
        "id": "avQQpilG9G0V"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "\n",
        "vocab_size = 11996\n",
        "\n",
        "X_train = [one_hot(d, vocab_size,filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~',lower=True, split=' ') for d in X_train]\n",
        "X_test = [one_hot(d, vocab_size,filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~',lower=True, split=' ') for d in X_test]"
      ],
      "metadata": {
        "id": "v6_pvAKd91Dk"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "max_length = 100\n",
        "X_train = pad_sequences(X_train, maxlen=max_length, padding='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_length, padding='post')\n"
      ],
      "metadata": {
        "id": "svNt_oB3-EOk"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "from tensorflow.keras.layers import Dense, Embedding,GlobalMaxPooling1D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D\n",
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "model_conv1 = Sequential([\n",
        "    Embedding(vocab_size, 7, input_length=max_length),\n",
        "  Conv1D(32, 3, activation='relu'),\n",
        "    GlobalMaxPooling1D(),\n",
        "  Dense(10, activation='relu'),\n",
        "  Dense(1, activation='sigmoid')\n",
        "])\n"
      ],
      "metadata": {
        "id": "g5N-xdPH-T2T"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_conv1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
      ],
      "metadata": {
        "id": "i9PL6FIU01-p"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "y_train= le.fit_transform(y_train)\n",
        "y_test = le.fit_transform(y_test)\n",
        "y_train.shape,y_test.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUBcFG2x1S0T",
        "outputId": "3691dacd-0dfe-4e4f-efca-0beacb79113e"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((799,), (200,))"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_conv1.fit(train_X_pad, trainY, epochs=20, validation_data=(test_X_pad, testY))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOl_1YJj0-H4",
        "outputId": "6e0ad339-7bb0-4ffe-d93f-836f9c38233c"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "22/22 [==============================] - 1s 17ms/step - loss: 0.7233 - acc: 0.1230 - val_loss: 0.6330 - val_acc: 0.1300\n",
            "Epoch 2/20\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.5593 - acc: 0.1488 - val_loss: 0.3946 - val_acc: 0.1300\n",
            "Epoch 3/20\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.2141 - acc: 0.1488 - val_loss: -0.0580 - val_acc: 0.1300\n",
            "Epoch 4/20\n",
            "22/22 [==============================] - 0s 8ms/step - loss: -0.3679 - acc: 0.1488 - val_loss: -0.9129 - val_acc: 0.1300\n",
            "Epoch 5/20\n",
            "22/22 [==============================] - 0s 8ms/step - loss: -1.6386 - acc: 0.1488 - val_loss: -2.7516 - val_acc: 0.1300\n",
            "Epoch 6/20\n",
            "22/22 [==============================] - 0s 8ms/step - loss: -4.0458 - acc: 0.1488 - val_loss: -6.1533 - val_acc: 0.1300\n",
            "Epoch 7/20\n",
            "22/22 [==============================] - 0s 8ms/step - loss: -8.5333 - acc: 0.1488 - val_loss: -12.8324 - val_acc: 0.1300\n",
            "Epoch 8/20\n",
            "22/22 [==============================] - 0s 8ms/step - loss: -17.2096 - acc: 0.1488 - val_loss: -25.9046 - val_acc: 0.1300\n",
            "Epoch 9/20\n",
            "22/22 [==============================] - 0s 9ms/step - loss: -33.4214 - acc: 0.1488 - val_loss: -49.0048 - val_acc: 0.1300\n",
            "Epoch 10/20\n",
            "22/22 [==============================] - 0s 8ms/step - loss: -61.5507 - acc: 0.1488 - val_loss: -87.2256 - val_acc: 0.1300\n",
            "Epoch 11/20\n",
            "22/22 [==============================] - 0s 8ms/step - loss: -105.8460 - acc: 0.1488 - val_loss: -146.9364 - val_acc: 0.1300\n",
            "Epoch 12/20\n",
            "22/22 [==============================] - 0s 8ms/step - loss: -172.8532 - acc: 0.1488 - val_loss: -234.1138 - val_acc: 0.1300\n",
            "Epoch 13/20\n",
            "22/22 [==============================] - 0s 8ms/step - loss: -270.4984 - acc: 0.1488 - val_loss: -355.0178 - val_acc: 0.1300\n",
            "Epoch 14/20\n",
            "22/22 [==============================] - 0s 8ms/step - loss: -400.8987 - acc: 0.1488 - val_loss: -520.6538 - val_acc: 0.1300\n",
            "Epoch 15/20\n",
            "22/22 [==============================] - 0s 8ms/step - loss: -577.6576 - acc: 0.1488 - val_loss: -735.5497 - val_acc: 0.1300\n",
            "Epoch 16/20\n",
            "22/22 [==============================] - 0s 11ms/step - loss: -806.9644 - acc: 0.1488 - val_loss: -1009.5228 - val_acc: 0.1300\n",
            "Epoch 17/20\n",
            "22/22 [==============================] - 0s 8ms/step - loss: -1096.1101 - acc: 0.1488 - val_loss: -1352.7872 - val_acc: 0.1300\n",
            "Epoch 18/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: -1453.5245 - acc: 0.1488 - val_loss: -1779.3204 - val_acc: 0.1300\n",
            "Epoch 19/20\n",
            "22/22 [==============================] - 0s 9ms/step - loss: -1886.1619 - acc: 0.1488 - val_loss: -2295.6479 - val_acc: 0.1300\n",
            "Epoch 20/20\n",
            "22/22 [==============================] - 0s 10ms/step - loss: -2421.2236 - acc: 0.1488 - val_loss: -2897.6267 - val_acc: 0.1300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test_conv1 = model_conv1.predict(test_X_pad)\n",
        "pred_test_conv1 = np.argmax(pred_test_conv1,axis=1)\n",
        "#pred_test = pred_test.round()\n",
        "\n",
        "#print evaluation metrics \n",
        "print(classification_report(testY,pred_test_conv1))\n",
        "print(confusion_matrix(testY,pred_test_conv1))\n",
        "print(\"Accuracy:\",accuracy_score(testY, pred_test_conv1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jli-aesD27b5",
        "outputId": "09579a82-33d3-4ef2-a72b-eab976808bfb"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.10      1.00      0.18        30\n",
            "           1       0.00      0.00      0.00        39\n",
            "           2       0.00      0.00      0.00        31\n",
            "           3       0.00      0.00      0.00        65\n",
            "           4       0.00      0.00      0.00        46\n",
            "           5       0.00      0.00      0.00        48\n",
            "           6       0.00      0.00      0.00        41\n",
            "\n",
            "    accuracy                           0.10       300\n",
            "   macro avg       0.01      0.14      0.03       300\n",
            "weighted avg       0.01      0.10      0.02       300\n",
            "\n",
            "[[30  0  0  0  0  0  0]\n",
            " [39  0  0  0  0  0  0]\n",
            " [31  0  0  0  0  0  0]\n",
            " [65  0  0  0  0  0  0]\n",
            " [46  0  0  0  0  0  0]\n",
            " [48  0  0  0  0  0  0]\n",
            " [41  0  0  0  0  0  0]]\n",
            "Accuracy: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ExplainerDashboard"
      ],
      "metadata": {
        "id": "fAL1HNus4Q67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_columns = list({k: v for k, v in sorted(count_vect.vocabulary_.items(), key=lambda item: item[1])}.keys())\n",
        "X_train_df = pd.DataFrame(trainX_vec.toarray(), columns = df_columns)\n",
        "X_test_df = pd.DataFrame(testX_vec.toarray(), columns = df_columns)"
      ],
      "metadata": {
        "id": "jCUSUJ2kqS4p"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "k_iwwSp7tK5Z",
        "outputId": "7dca133b-00fc-460b-f2a2-76f3758a728b"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     10  11  1862  1882  20  21st  25  30  abandon  abeyance  ...  yield  yo  \\\n",
              "0     0   0     0     0   0     0   0   0        0         0  ...      0   0   \n",
              "1     0   0     0     0   0     0   0   0        0         0  ...      0   0   \n",
              "2     0   0     0     0   0     0   0   0        0         0  ...      0   0   \n",
              "3     0   0     0     0   0     0   0   0        0         0  ...      0   0   \n",
              "4     0   0     0     0   0     0   0   0        0         0  ...      0   0   \n",
              "..   ..  ..   ...   ...  ..   ...  ..  ..      ...       ...  ...    ...  ..   \n",
              "694   0   0     0     0   0     0   0   0        0         0  ...      0   0   \n",
              "695   0   0     0     0   0     0   0   0        0         0  ...      0   0   \n",
              "696   0   0     0     0   0     0   0   0        0         0  ...      0   0   \n",
              "697   0   0     0     0   0     0   0   0        0         0  ...      1   0   \n",
              "698   0   0     0     0   0     0   0   0        0         0  ...      0   0   \n",
              "\n",
              "     yonder  york  you  young  yous  youth  youthful  zeal  \n",
              "0         0     0    0      0     0      0         0     0  \n",
              "1         0     0    0      0     0      0         0     0  \n",
              "2         0     0    0      0     0      0         0     0  \n",
              "3         0     0    0      0     0      0         0     0  \n",
              "4         0     0    0      0     0      0         0     0  \n",
              "..      ...   ...  ...    ...   ...    ...       ...   ...  \n",
              "694       0     0    0      0     0      0         0     0  \n",
              "695       0     0    0      0     0      0         0     0  \n",
              "696       0     0    0      0     0      0         0     0  \n",
              "697       0     0    0      1     0      0         0     0  \n",
              "698       0     0    0      0     0      0         0     0  \n",
              "\n",
              "[699 rows x 5000 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-179a8989-209e-4671-be31-72c9266fea74\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>1862</th>\n",
              "      <th>1882</th>\n",
              "      <th>20</th>\n",
              "      <th>21st</th>\n",
              "      <th>25</th>\n",
              "      <th>30</th>\n",
              "      <th>abandon</th>\n",
              "      <th>abeyance</th>\n",
              "      <th>...</th>\n",
              "      <th>yield</th>\n",
              "      <th>yo</th>\n",
              "      <th>yonder</th>\n",
              "      <th>york</th>\n",
              "      <th>you</th>\n",
              "      <th>young</th>\n",
              "      <th>yous</th>\n",
              "      <th>youth</th>\n",
              "      <th>youthful</th>\n",
              "      <th>zeal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>694</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>695</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>696</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>697</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>698</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>699 rows × 5000 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-179a8989-209e-4671-be31-72c9266fea74')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-179a8989-209e-4671-be31-72c9266fea74 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-179a8989-209e-4671-be31-72c9266fea74');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#X_train_df.value_counts()"
      ],
      "metadata": {
        "id": "Ji_5p0L78LJZ"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ex = LogisticRegression()\n",
        "model_ex.fit(X_train_df,trainY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SogoZIZhtLmG",
        "outputId": "5eba211e-bff0-4991-846d-f942b32b4f7d"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!! pip install explainerdashboard"
      ],
      "metadata": {
        "id": "im0YWjGswhe8"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from explainerdashboard import ClassifierExplainer, ExplainerDashboard\n",
        "\n",
        "explainer = ClassifierExplainer(model_ex, X_test_df, testY,\n",
        "  #labels=['v1'], # defaults to ['0', '1', etc]\n",
        ")\n",
        "\n",
        "db = ExplainerDashboard(explainer,title=\"Author Classifier Explainer\",\n",
        "    shap_interaction=False,\n",
        ")\n",
        "db.run(port=8050)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "ZBgwjEg3tQKi",
        "outputId": "f858dbbb-1f14-4880-d2ad-967dd5f04538"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: For shap='linear', shap interaction values can unfortunately not be calculated!\n",
            "Note: model_output='probability' is currently not supported for linear classifiers models with shap. So defaulting to model_output='logodds' If you really need probability outputs use shap='kernel' instead.\n",
            "Note: shap values for shap='linear' get calculated against X_background, but paramater X_background=None, so using X instead...\n",
            "Generating self.shap_explainer = shap.LinearExplainer(model, X)...\n",
            "Building ExplainerDashboard..\n",
            "Detected google colab environment, setting mode='external'\n",
            "The explainer object has no decision_trees property. so setting decision_trees=False...\n",
            "Generating layout...\n",
            "Calculating shap values...\n",
            "Calculating prediction probabilities...\n",
            "Calculating metrics...\n",
            "Calculating confusion matrices...\n",
            "Calculating classification_dfs...\n",
            "Calculating roc auc curves...\n",
            "Calculating pr auc curves...\n",
            "Calculating liftcurve_dfs...\n",
            "Calculating dependencies...\n",
            "Calculating permutation importances (if slow, try setting n_jobs parameter)...\n",
            "Calculating predictions...\n",
            "Calculating pred_percentiles...\n",
            "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
            "Registering callbacks...\n",
            "Starting ExplainerDashboard on http://172.28.0.2:8050\n",
            "You can terminate the dashboard with ExplainerDashboard.terminate(8050)\n",
            "Dash app running on:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, text, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port);\n",
              "    const anchor = document.createElement('a');\n",
              "    anchor.href = new URL(path, url).toString();\n",
              "    anchor.target = '_blank';\n",
              "    anchor.setAttribute('data-href', url + path);\n",
              "    anchor.textContent = text;\n",
              "    element.appendChild(anchor);\n",
              "  })(8050, \"/\", \"http://127.0.0.1:8050/\", window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bidirectional LSTM"
      ],
      "metadata": {
        "id": "Zsup8NShLNW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 20000\n",
        "maxlen = 200"
      ],
      "metadata": {
        "id": "nC_uiO2sLMsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
        "x = layers.Embedding(max_features, 128)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "xtezBzr9LiOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = keras.preprocessing.sequence.pad_sequences(trainX, maxlen=maxlen)\n",
        "x_val = keras.preprocessing.sequence.pad_sequences(testX, maxlen=maxlen)"
      ],
      "metadata": {
        "id": "VwYV1CuvMN_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=2, validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "id": "RNY7mOIkMDxI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Model_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}